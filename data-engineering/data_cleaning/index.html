<!DOCTYPE html><html  lang="en"><head><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Architecting Intelligence</title>
<meta name="twitter:card" content="summary_large_image">
<meta name="description" content="Learn and create with all things tech-related.">
<meta property="og:description" content="Learn and create with all things tech-related.">
<meta property="og:image" content="https://user-images.githubusercontent.com/904724/185365452-87b7ca7b-6030-4813-a2db-5e65c785bf88.png">
<meta property="og:title" content="Data Cleaning">
<link rel="preload" as="fetch" crossorigin="anonymous" href="/data-engineering/data_cleaning/_payload.json">
<link rel="stylesheet" href="/_nuxt/entry.B8aBeJvy.css">
<link rel="stylesheet" href="/_nuxt/DocumentDrivenNotFound.BRDfakKL.css">
<link rel="stylesheet" href="/_nuxt/ButtonLink.BcPyV5Fo.css">
<link rel="stylesheet" href="/_nuxt/DocsPageLayout.BXbIABds.css">
<link rel="stylesheet" href="/_nuxt/DocsAside.yGvrP2YV.css">
<link rel="stylesheet" href="/_nuxt/ProseCodeInline.Bril_6kD.css">
<link rel="stylesheet" href="/_nuxt/Alert.ks8StbO8.css">
<link rel="stylesheet" href="/_nuxt/DocsPageBottom.aIuXrYmW.css">
<link rel="stylesheet" href="/_nuxt/ProseA.B_9jSfDy.css">
<link rel="stylesheet" href="/_nuxt/DocsPrevNext.ByMsnGQP.css">
<link rel="stylesheet" href="/_nuxt/DocsToc.BhhHodRA.css">
<link rel="stylesheet" href="/_nuxt/DocsTocLinks.Cr8aui7G.css">
<link rel="stylesheet" href="/_nuxt/ProseH1.C1QHku3J.css">
<link rel="stylesheet" href="/_nuxt/ProseP.JZ9aYQx9.css">
<link rel="stylesheet" href="/_nuxt/ProseImg.nadtDK_b.css">
<link rel="stylesheet" href="/_nuxt/ProseH2.DFqHnP3U.css">
<link rel="stylesheet" href="/_nuxt/ProseOl.Zw1jGp1x.css">
<link rel="stylesheet" href="/_nuxt/ProseLi.oUMq_Oay.css">
<link rel="stylesheet" href="/_nuxt/ProseH3.BL6NEyca.css">
<link rel="stylesheet" href="/_nuxt/ProseStrong.kEZmG1pc.css">
<link rel="stylesheet" href="/_nuxt/ProseUl.ZPu7LyJp.css">
<link rel="stylesheet" href="/_nuxt/ProseBlockquote.BVZLnJ97.css">
<link rel="stylesheet" href="/_nuxt/ProseEm.KZi6TQVp.css">
<link rel="stylesheet" href="/_nuxt/ProsePre.CchFRBtv.css">
<link rel="stylesheet" href="/_nuxt/ProseCode.hGqjIeRz.css">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/CXJ2fdAB.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DnM6ckxY.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DiDlarbj.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/CWMOCUTq.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/prfrliGK.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/ClqCtrfb.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/WTkegDBA.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/BPr0oGOJ.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/2ETV-d1z.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DfwIlzWN.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/BHloeWX3.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/RlfkODSA.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/CBvHC7lm.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/Cnxcs8Ow.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/Bqg2AslK.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/oL9jraFH.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/C4N5kdK3.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DCnPNjGU.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/BpWXDgNL.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DDXj8gg1.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/HzHAgKX4.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DCOvvQA7.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/BivTU8sc.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/CgJas5qb.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/BEj21w-d.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/PVy2bvTw.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/BL0lifHx.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/1Io2kNHA.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/elmQM_bn.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/Bdwhfqcg.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/Bu-hPAU3.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/CFbYFV0i.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/Bib9wDje.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/O82UycJE.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/Wl01_9ot.js">
<link rel="prefetch" as="style" href="/_nuxt/page.Dmtwb7Hr.css">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/CWiUpT3k.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/D8gO8QcV.js">
<link rel="prefetch" as="style" href="/_nuxt/useStudio.KYzQV3Di.css">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/C6RYnNE5.js">
<link rel="prefetch" as="style" href="/_nuxt/error-404.D8uONj7L.css">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/Cjt5NVL5.js">
<link rel="prefetch" as="style" href="/_nuxt/error-500.p7T9h8Pv.css">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/D3cn8lx4.js">
<script type="module" src="/_nuxt/CXJ2fdAB.js" crossorigin></script><style id="pinceau-runtime-hydratable">@media{.phy[--]{--puid:rXDDID-v;}.pv-FwUXly{padding-left:var(--elements-container-padding-mobile);padding-right:var(--elements-container-padding-mobile);}@media (min-width: 475px){.pv-FwUXly{padding-left:var(--elements-container-padding-xs);padding-right:var(--elements-container-padding-xs);}}@media (min-width: 640px){.pv-FwUXly{padding-left:var(--elements-container-padding-sm);padding-right:var(--elements-container-padding-sm);}}@media (min-width: 768px){.pv-FwUXly{padding-left:var(--elements-container-padding-md);padding-right:var(--elements-container-padding-md);}}} </style><style id="pinceau-theme">@media { :root {--pinceau-mq: initial; --docus-search-results-highlight-color: white;--docus-search-results-window-maxHeight: 100%;--docus-search-results-window-maxWidth: 640px;--docus-search-results-window-marginTop: 0;--docus-search-input-borderStyle: solid;--docus-search-input-borderWidth: 1px;--docus-search-backdropFilter: blur(24px);--docus-loadingBar-gradientColorStop3: #0047e1;--docus-loadingBar-gradientColorStop2: #34cdfe;--docus-loadingBar-gradientColorStop1: #00dc82;--docus-loadingBar-height: 3px;--docus-readableLine: 78ch;--docus-footer-height: 145px;--docus-header-height: 64px;--prose-code-inline-padding: 0.2rem 0.375rem 0.2rem 0.375rem;--prose-code-block-backdropFilter: contrast(1);--prose-code-block-border-style: solid;--prose-code-block-border-width: 1px;--prose-tbody-tr-borderBottom-style: dashed;--prose-tbody-tr-borderBottom-width: 1px;--prose-th-textAlign: inherit;--prose-thead-borderBottom-style: solid;--prose-thead-borderBottom-width: 1px;--prose-thead-border-style: solid;--prose-thead-border-width: 0px;--prose-table-textAlign: start;--prose-hr-width: 1px;--prose-hr-style: solid;--prose-li-listStylePosition: outside;--prose-ol-li-markerColor: currentColor;--prose-ol-paddingInlineStart: 21px;--prose-ol-listStyleType: decimal;--prose-ul-li-markerColor: currentColor;--prose-ul-paddingInlineStart: 21px;--prose-ul-listStyleType: disc;--prose-blockquote-border-style: solid;--prose-blockquote-border-width: 4px;--prose-blockquote-quotes: '201C' '201D' '2018' '2019';--prose-blockquote-paddingInlineStart: 24px;--prose-a-code-color-hover: currentColor;--prose-a-code-color-static: currentColor;--prose-a-hasCode-borderBottom: none;--prose-a-border-distance: 2px;--prose-a-border-color-hover: currentColor;--prose-a-border-color-static: currentColor;--prose-a-border-style-hover: solid;--prose-a-border-style-static: dashed;--prose-a-border-width: 1px;--prose-a-color-static: inherit;--prose-a-textDecoration: none;--prose-h6-margin: 3rem 0 2rem;--prose-h5-margin: 3rem 0 2rem;--prose-h4-margin: 3rem 0 2rem;--prose-h3-margin: 3rem 0 2rem;--prose-h2-margin: 3rem 0 2rem;--prose-h1-margin: 0 0 2rem;--typography-lead-loose: 2;--typography-lead-relaxed: 1.625;--typography-lead-normal: 1.5;--typography-lead-snug: 1.375;--typography-lead-tight: 1.25;--typography-lead-none: 1;--typography-lead-10: 2.5rem;--typography-lead-9: 2.25rem;--typography-lead-8: 2rem;--typography-lead-7: 1.75rem;--typography-lead-6: 1.5rem;--typography-lead-5: 1.25rem;--typography-lead-4: 1rem;--typography-lead-3: .75rem;--typography-lead-2: .5rem;--typography-lead-1: .025rem;--typography-fontWeight-black: 900;--typography-fontWeight-extrabold: 800;--typography-fontWeight-bold: 700;--typography-fontWeight-semibold: 600;--typography-fontWeight-medium: 500;--typography-fontWeight-normal: 400;--typography-fontWeight-light: 300;--typography-fontWeight-extralight: 200;--typography-fontWeight-thin: 100;--typography-fontSize-9xl: 128px;--typography-fontSize-8xl: 96px;--typography-fontSize-7xl: 72px;--typography-fontSize-6xl: 60px;--typography-fontSize-5xl: 48px;--typography-fontSize-4xl: 36px;--typography-fontSize-3xl: 30px;--typography-fontSize-2xl: 24px;--typography-fontSize-xl: 20px;--typography-fontSize-lg: 18px;--typography-fontSize-base: 16px;--typography-fontSize-sm: 14px;--typography-fontSize-xs: 12px;--typography-letterSpacing-wide: 0.025em;--typography-letterSpacing-tight: -0.025em;--typography-verticalMargin-base: 24px;--typography-verticalMargin-sm: 16px;--elements-border-secondary-hover: [object Object];--elements-backdrop-background: #fffc;--elements-backdrop-filter: saturate(200%) blur(20px);--elements-container-maxWidth: 80rem;--lead-loose: 2;--lead-relaxed: 1.625;--lead-normal: 1.5;--lead-snug: 1.375;--lead-tight: 1.25;--lead-none: 1;--lead-10: 2.5rem;--lead-9: 2.25rem;--lead-8: 2rem;--lead-7: 1.75rem;--lead-6: 1.5rem;--lead-5: 1.25rem;--lead-4: 1rem;--lead-3: .75rem;--lead-2: .5rem;--lead-1: .025rem;--letterSpacing-widest: 0.1em;--letterSpacing-wider: 0.05em;--letterSpacing-wide: 0.025em;--letterSpacing-normal: 0em;--letterSpacing-tight: -0.025em;--letterSpacing-tighter: -0.05em;--fontSize-9xl: 8rem;--fontSize-8xl: 6rem;--fontSize-7xl: 4.5rem;--fontSize-6xl: 3.75rem;--fontSize-5xl: 3rem;--fontSize-4xl: 2.25rem;--fontSize-3xl: 1.875rem;--fontSize-2xl: 1.5rem;--fontSize-xl: 1.25rem;--fontSize-lg: 1.125rem;--fontSize-base: 1rem;--fontSize-sm: 0.875rem;--fontSize-xs: 0.75rem;--fontWeight-black: 900;--fontWeight-extrabold: 800;--fontWeight-bold: 700;--fontWeight-semibold: 600;--fontWeight-medium: 500;--fontWeight-normal: 400;--fontWeight-light: 300;--fontWeight-extralight: 200;--fontWeight-thin: 100;--font-mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, Liberation Mono, Courier New, monospace;--font-serif: ui-serif, Georgia, Cambria, Times New Roman, Times, serif;--font-sans: ui-sans-serif, system-ui, -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Helvetica Neue, Arial, Noto Sans, sans-serif, Apple Color Emoji, Segoe UI Emoji, Segoe UI Symbol, Noto Color Emoji;--opacity-total: 1;--opacity-high: 0.8;--opacity-medium: 0.5;--opacity-soft: 0.3;--opacity-light: 0.15;--opacity-bright: 0.1;--opacity-noOpacity: 0;--borderWidth-lg: 3px;--borderWidth-md: 2px;--borderWidth-sm: 1px;--borderWidth-noBorder: 0;--space-rem-875: 0.875rem;--space-rem-625: 0.625rem;--space-rem-375: 0.375rem;--space-rem-125: 0.125rem;--space-px: 1px;--space-128: 32rem;--space-96: 24rem;--space-80: 20rem;--space-72: 18rem;--space-64: 16rem;--space-60: 15rem;--space-56: 14rem;--space-52: 13rem;--space-48: 12rem;--space-44: 11rem;--space-40: 10rem;--space-36: 9rem;--space-32: 8rem;--space-28: 7rem;--space-24: 6rem;--space-20: 5rem;--space-16: 4rem;--space-14: 3.5rem;--space-12: 3rem;--space-11: 2.75rem;--space-10: 2.5rem;--space-9: 2.25rem;--space-8: 2rem;--space-7: 1.75rem;--space-6: 1.5rem;--space-5: 1.25rem;--space-4: 1rem;--space-3: 0.75rem;--space-2: 0.5rem;--space-1: 0.25rem;--space-0: 0px;--size-full: 100%;--size-7xl: 80rem;--size-6xl: 72rem;--size-5xl: 64rem;--size-4xl: 56rem;--size-3xl: 48rem;--size-2xl: 42rem;--size-xl: 36rem;--size-lg: 32rem;--size-md: 28rem;--size-sm: 24rem;--size-xs: 20rem;--size-200: 200px;--size-104: 104px;--size-80: 80px;--size-64: 64px;--size-56: 56px;--size-48: 48px;--size-40: 40px;--size-32: 32px;--size-24: 24px;--size-20: 20px;--size-16: 16px;--size-12: 12px;--size-8: 8px;--size-6: 6px;--size-4: 4px;--size-2: 2px;--size-0: 0px;--radii-full: 9999px;--radii-3xl: 1.75rem;--radii-2xl: 1.5rem;--radii-xl: 1rem;--radii-lg: 0.75rem;--radii-md: 0.5rem;--radii-sm: 0.375rem;--radii-xs: 0.25rem;--radii-2xs: 0.125rem;--radii-none: 0px;--shadow-none: 0px 0px 0px 0px transparent;--height-screen: 100vh;--width-screen: 100vw;--color-primary-900: #001A1F;--color-primary-800: #00232B;--color-primary-700: #024757;--color-primary-600: #09A0C1;--color-primary-500: #1AD6FF;--color-primary-400: #55E1FF;--color-primary-300: #82E3FF;--color-primary-200: #C5F2FF;--color-primary-100: #DCF7FF;--color-primary-50: #F1FCFF;--color-ruby-900: #380011;--color-ruby-800: #700021;--color-ruby-700: #a90032;--color-ruby-600: #e10043;--color-ruby-500: #ff1a5e;--color-ruby-400: #ff4079;--color-ruby-300: #ff6694;--color-ruby-200: #ff8dae;--color-ruby-100: #ffb3c9;--color-ruby-50: #ffd9e4;--color-pink-900: #380025;--color-pink-800: #70004b;--color-pink-700: #a90070;--color-pink-600: #e10095;--color-pink-500: #ff1ab2;--color-pink-400: #ff40bf;--color-pink-300: #ff66cc;--color-pink-200: #ff8dd8;--color-pink-100: #ffb3e5;--color-pink-50: #ffd9f2;--color-purple-900: #190038;--color-purple-800: #330070;--color-purple-700: #4c00a9;--color-purple-600: #6500e1;--color-purple-500: #811aff;--color-purple-400: #9640ff;--color-purple-300: #ab66ff;--color-purple-200: #c08dff;--color-purple-100: #d5b3ff;--color-purple-50: #ead9ff;--color-royalblue-900: #0b0531;--color-royalblue-800: #160a62;--color-royalblue-700: #211093;--color-royalblue-600: #2c15c4;--color-royalblue-500: #4127e8;--color-royalblue-400: #614bec;--color-royalblue-300: #806ff0;--color-royalblue-200: #a093f3;--color-royalblue-100: #c0b7f7;--color-royalblue-50: #dfdbfb;--color-indigoblue-900: #001238;--color-indigoblue-800: #002370;--color-indigoblue-700: #0035a9;--color-indigoblue-600: #0047e1;--color-indigoblue-500: #1a62ff;--color-indigoblue-400: #407cff;--color-indigoblue-300: #6696ff;--color-indigoblue-200: #8db0ff;--color-indigoblue-100: #b3cbff;--color-indigoblue-50: #d9e5ff;--color-blue-900: #00131D;--color-blue-800: #002235;--color-blue-700: #014267;--color-blue-600: #0069A6;--color-blue-500: #1AADFF;--color-blue-400: #64C7FF;--color-blue-300: #A1DDFF;--color-blue-200: #C6EAFF;--color-blue-100: #DFF3FF;--color-blue-50: #F2FAFF;--color-lightblue-900: #002e38;--color-lightblue-800: #005c70;--color-lightblue-700: #008aa9;--color-lightblue-600: #00b9e1;--color-lightblue-500: #1ad6ff;--color-lightblue-400: #40ddff;--color-lightblue-300: #66e4ff;--color-lightblue-200: #8deaff;--color-lightblue-100: #b3f1ff;--color-lightblue-50: #d9f8ff;--color-teal-900: #062a28;--color-teal-800: #0b544f;--color-teal-700: #117d77;--color-teal-600: #16a79e;--color-teal-500: #1cd1c6;--color-teal-400: #36e4da;--color-teal-300: #5fe9e1;--color-teal-200: #87efe9;--color-teal-100: #aff4f0;--color-teal-50: #d7faf8;--color-pear-900: #2a2b09;--color-pear-800: #545512;--color-pear-700: #7e801b;--color-pear-600: #a8aa24;--color-pear-500: #d0d32f;--color-pear-400: #d8da52;--color-pear-300: #e0e274;--color-pear-200: #e8e997;--color-pear-100: #eff0ba;--color-pear-50: #f7f8dc;--color-red-900: #1C0301;--color-red-800: #340A01;--color-red-700: #701704;--color-red-600: #BB2402;--color-red-500: #FF3B10;--color-red-400: #FF7353;--color-red-300: #FFA692;--color-red-200: #FFDED7;--color-red-100: #FFF3F0;--color-red-50: #FFF9F8;--color-orange-900: #381800;--color-orange-800: #702f00;--color-orange-700: #a94700;--color-orange-600: #e15e00;--color-orange-500: #ff7a1a;--color-orange-400: #ff9040;--color-orange-300: #ffa666;--color-orange-200: #ffbd8d;--color-orange-100: #ffd3b3;--color-orange-50: #ffe9d9;--color-yellow-900: #1B1500;--color-yellow-800: #292100;--color-yellow-700: #614E02;--color-yellow-600: #CBA408;--color-yellow-500: #FBCA05;--color-yellow-400: #FFDC4E;--color-yellow-300: #FFE372;--color-yellow-200: #FFF0B1;--color-yellow-100: #FFF6D3;--color-yellow-50: #FFFCEE;--color-green-900: #00190F;--color-green-800: #002817;--color-green-700: #006037;--color-green-600: #00B467;--color-green-500: #0DD885;--color-green-400: #3CEEA5;--color-green-300: #86FBCB;--color-green-200: #C3FFE6;--color-green-100: #DEFFF1;--color-green-50: #ECFFF7;--color-gray-900: #121110;--color-gray-800: #201E1B;--color-gray-700: #36332E;--color-gray-600: #67635D;--color-gray-500: #97948F;--color-gray-400: #ADA9A4;--color-gray-300: #DBD9D3;--color-gray-200: #ECEBE8;--color-gray-100: #F6F5F4;--color-gray-50: #FBFBFB;--color-black: #0B0A0A;--color-white: #ffffff;--media-portrait: only screen and (orientation: portrait);--media-landscape: only screen and (orientation: landscape);--media-rm: (prefers-reduced-motion: reduce);--media-2xl: (min-width: 1536px);--media-xl: (min-width: 1280px);--media-lg: (min-width: 1024px);--media-md: (min-width: 768px);--media-sm: (min-width: 640px);--media-xs: (min-width: 475px);--docus-search-results-highlight-backgroundColor: var(--color-primary-500);--docus-search-results-selected-backgroundColor: var(--color-gray-300);--docus-search-results-window-borderRadius: none;--docus-search-results-window-marginX: 0;--docus-search-input-backgroundColor: var(--color-gray-200);--docus-search-input-padding: var(--space-2) var(--space-4);--docus-search-input-gap: var(--space-2);--docus-search-input-fontSize: var(--fontSize-sm);--docus-search-input-borderColor: var(--color-gray-200);--docus-search-input-borderRadius: var(--radii-2xs);--docus-footer-padding: var(--space-4) 0;--docus-header-title-color-hover: var(--color-primary-500);--docus-header-title-color-static: var(--color-gray-900);--docus-header-title-fontWeight: var(--fontWeight-bold);--docus-header-title-fontSize: var(--fontSize-2xl);--docus-header-logo-height: var(--space-6);--docus-body-fontFamily: var(--font-sans);--docus-body-color: var(--color-gray-800);--docus-body-backgroundColor: var(--color-white);--prose-code-inline-fontWeight: var(--typography-fontWeight-normal);--prose-code-inline-fontSize: var(--typography-fontSize-sm);--prose-code-inline-borderRadius: var(--radii-xs);--prose-code-block-pre-padding: var(--typography-verticalMargin-sm);--prose-code-block-margin: var(--typography-verticalMargin-base) 0;--prose-code-block-fontSize: var(--typography-fontSize-sm);--prose-tbody-code-inline-fontSize: var(--typography-fontSize-sm);--prose-tbody-td-padding: var(--typography-verticalMargin-sm);--prose-th-fontWeight: var(--typography-fontWeight-semibold);--prose-th-padding: 0 var(--typography-verticalMargin-sm) var(--typography-verticalMargin-sm) var(--typography-verticalMargin-sm);--prose-table-lineHeight: var(--typography-lead-6);--prose-table-fontSize: var(--typography-fontSize-sm);--prose-table-margin: var(--typography-verticalMargin-base) 0;--prose-hr-margin: var(--typography-verticalMargin-base) 0;--prose-li-margin: var(--typography-verticalMargin-sm) 0;--prose-ol-margin: var(--typography-verticalMargin-base) 0;--prose-ul-margin: var(--typography-verticalMargin-base) 0;--prose-blockquote-margin: var(--typography-verticalMargin-base) 0;--prose-a-code-border-style: var(--prose-a-border-style-static);--prose-a-code-border-width: var(--prose-a-border-width);--prose-a-fontWeight: var(--typography-fontWeight-medium);--prose-img-margin: var(--typography-verticalMargin-base) 0;--prose-strong-fontWeight: var(--typography-fontWeight-semibold);--prose-h6-iconSize: var(--typography-fontSize-base);--prose-h6-fontWeight: var(--typography-fontWeight-semibold);--prose-h6-lineHeight: var(--typography-lead-normal);--prose-h6-fontSize: var(--typography-fontSize-lg);--prose-h5-iconSize: var(--typography-fontSize-lg);--prose-h5-fontWeight: var(--typography-fontWeight-semibold);--prose-h5-lineHeight: var(--typography-lead-snug);--prose-h5-fontSize: var(--typography-fontSize-xl);--prose-h4-iconSize: var(--typography-fontSize-lg);--prose-h4-letterSpacing: var(--typography-letterSpacing-tight);--prose-h4-fontWeight: var(--typography-fontWeight-semibold);--prose-h4-lineHeight: var(--typography-lead-snug);--prose-h4-fontSize: var(--typography-fontSize-2xl);--prose-h3-iconSize: var(--typography-fontSize-xl);--prose-h3-letterSpacing: var(--typography-letterSpacing-tight);--prose-h3-fontWeight: var(--typography-fontWeight-semibold);--prose-h3-lineHeight: var(--typography-lead-snug);--prose-h3-fontSize: var(--typography-fontSize-3xl);--prose-h2-iconSize: var(--typography-fontSize-2xl);--prose-h2-letterSpacing: var(--typography-letterSpacing-tight);--prose-h2-fontWeight: var(--typography-fontWeight-semibold);--prose-h2-lineHeight: var(--typography-lead-tight);--prose-h2-fontSize: var(--typography-fontSize-4xl);--prose-h1-iconSize: var(--typography-fontSize-3xl);--prose-h1-letterSpacing: var(--typography-letterSpacing-tight);--prose-h1-fontWeight: var(--typography-fontWeight-bold);--prose-h1-lineHeight: var(--typography-lead-tight);--prose-h1-fontSize: var(--typography-fontSize-5xl);--prose-p-br-margin: var(--typography-verticalMargin-base) 0 0 0;--prose-p-margin: var(--typography-verticalMargin-base) 0;--prose-p-lineHeight: var(--typography-lead-normal);--prose-p-fontSize: var(--typography-fontSize-base);--typography-color-secondary-900: var(--color-gray-900);--typography-color-secondary-800: var(--color-gray-800);--typography-color-secondary-700: var(--color-gray-700);--typography-color-secondary-600: var(--color-gray-600);--typography-color-secondary-500: var(--color-gray-500);--typography-color-secondary-400: var(--color-gray-400);--typography-color-secondary-300: var(--color-gray-300);--typography-color-secondary-200: var(--color-gray-200);--typography-color-secondary-100: var(--color-gray-100);--typography-color-secondary-50: var(--color-gray-50);--typography-color-primary-900: var(--color-primary-900);--typography-color-primary-800: var(--color-primary-800);--typography-color-primary-700: var(--color-primary-700);--typography-color-primary-600: var(--color-primary-600);--typography-color-primary-500: var(--color-primary-500);--typography-color-primary-400: var(--color-primary-400);--typography-color-primary-300: var(--color-primary-300);--typography-color-primary-200: var(--color-primary-200);--typography-color-primary-100: var(--color-primary-100);--typography-color-primary-50: var(--color-primary-50);--typography-font-code: var(--font-mono);--typography-font-body: var(--font-sans);--typography-font-display: var(--font-sans);--typography-body-backgroundColor: var(--color-white);--typography-body-color: var(--color-black);--elements-state-danger-borderColor-secondary: var(--color-red-200);--elements-state-danger-borderColor-primary: var(--color-red-100);--elements-state-danger-backgroundColor-secondary: var(--color-red-100);--elements-state-danger-backgroundColor-primary: var(--color-red-50);--elements-state-danger-color-secondary: var(--color-red-600);--elements-state-danger-color-primary: var(--color-red-500);--elements-state-warning-borderColor-secondary: var(--color-yellow-200);--elements-state-warning-borderColor-primary: var(--color-yellow-100);--elements-state-warning-backgroundColor-secondary: var(--color-yellow-100);--elements-state-warning-backgroundColor-primary: var(--color-yellow-50);--elements-state-warning-color-secondary: var(--color-yellow-700);--elements-state-warning-color-primary: var(--color-yellow-600);--elements-state-success-borderColor-secondary: var(--color-green-200);--elements-state-success-borderColor-primary: var(--color-green-100);--elements-state-success-backgroundColor-secondary: var(--color-green-100);--elements-state-success-backgroundColor-primary: var(--color-green-50);--elements-state-success-color-secondary: var(--color-green-600);--elements-state-success-color-primary: var(--color-green-500);--elements-state-info-borderColor-secondary: var(--color-blue-200);--elements-state-info-borderColor-primary: var(--color-blue-100);--elements-state-info-backgroundColor-secondary: var(--color-blue-100);--elements-state-info-backgroundColor-primary: var(--color-blue-50);--elements-state-info-color-secondary: var(--color-blue-600);--elements-state-info-color-primary: var(--color-blue-500);--elements-state-primary-borderColor-secondary: var(--color-primary-200);--elements-state-primary-borderColor-primary: var(--color-primary-100);--elements-state-primary-backgroundColor-secondary: var(--color-primary-100);--elements-state-primary-backgroundColor-primary: var(--color-primary-50);--elements-state-primary-color-secondary: var(--color-primary-700);--elements-state-primary-color-primary: var(--color-primary-600);--elements-surface-secondary-backgroundColor: var(--color-gray-200);--elements-surface-primary-backgroundColor: var(--color-gray-100);--elements-surface-background-base: var(--color-gray-100);--elements-border-secondary-static: var(--color-gray-200);--elements-border-primary-hover: var(--color-gray-200);--elements-border-primary-static: var(--color-gray-100);--elements-container-padding-md: var(--space-6);--elements-container-padding-sm: var(--space-6);--elements-container-padding-xs: var(--space-4);--elements-container-padding-mobile: var(--space-4);--elements-text-secondary-color-hover: var(--color-gray-700);--elements-text-secondary-color-static: var(--color-gray-500);--elements-text-primary-color-static: var(--color-gray-900);--text-6xl-lineHeight: var(--lead-none);--text-6xl-fontSize: var(--fontSize-6xl);--text-5xl-lineHeight: var(--lead-none);--text-5xl-fontSize: var(--fontSize-5xl);--text-4xl-lineHeight: var(--lead-10);--text-4xl-fontSize: var(--fontSize-4xl);--text-3xl-lineHeight: var(--lead-9);--text-3xl-fontSize: var(--fontSize-3xl);--text-2xl-lineHeight: var(--lead-8);--text-2xl-fontSize: var(--fontSize-2xl);--text-xl-lineHeight: var(--lead-7);--text-xl-fontSize: var(--fontSize-xl);--text-lg-lineHeight: var(--lead-7);--text-lg-fontSize: var(--fontSize-lg);--text-base-lineHeight: var(--lead-6);--text-base-fontSize: var(--fontSize-base);--text-sm-lineHeight: var(--lead-5);--text-sm-fontSize: var(--fontSize-sm);--text-xs-lineHeight: var(--lead-4);--text-xs-fontSize: var(--fontSize-xs);--color-shadow: var(--color-gray-400);--color-secondary-900: var(--color-gray-900);--color-secondary-800: var(--color-gray-800);--color-secondary-700: var(--color-gray-700);--color-secondary-600: var(--color-gray-600);--color-secondary-500: var(--color-gray-500);--color-secondary-400: var(--color-gray-400);--color-secondary-300: var(--color-gray-300);--color-secondary-200: var(--color-gray-200);--color-secondary-100: var(--color-gray-100);--color-secondary-50: var(--color-gray-50);--prose-code-inline-backgroundColor: var(--typography-color-secondary-100);--prose-code-inline-color: var(--typography-color-secondary-700);--prose-code-block-backgroundColor: var(--typography-color-secondary-100);--prose-code-block-color: var(--typography-color-secondary-700);--prose-code-block-border-color: var(--typography-color-secondary-200);--prose-tbody-tr-borderBottom-color: var(--typography-color-secondary-200);--prose-th-color: var(--typography-color-secondary-600);--prose-thead-borderBottom-color: var(--typography-color-secondary-200);--prose-thead-border-color: var(--typography-color-secondary-300);--prose-hr-color: var(--typography-color-secondary-200);--prose-blockquote-border-color: var(--typography-color-secondary-200);--prose-blockquote-color: var(--typography-color-secondary-500);--prose-a-code-background-hover: var(--typography-color-primary-50);--prose-a-code-border-color-hover: var(--typography-color-primary-500);--prose-a-code-border-color-static: var(--typography-color-secondary-400);--prose-a-color-hover: var(--typography-color-primary-500);--shadow-2xl: 0px 25px 50px -12px var(--color-shadow);--shadow-xl: 0px 20px 25px -5px var(--color-shadow), 0px 8px 10px -6px var(--color-shadow);--shadow-lg: 0px 10px 15px -3px var(--color-shadow), 0px 4px 6px -4px var(--color-shadow);--shadow-md: 0px 4px 6px -1px var(--color-shadow), 0px 2px 4px -2px var(--color-shadow);--shadow-sm: 0px 1px 3px 0px var(--color-shadow), 0px 1px 2px -1px var(--color-shadow);--shadow-xs: 0px 1px 2px 0px var(--color-shadow); } }@media { :root.dark {--pinceau-mq: dark; --prose-code-block-backdropFilter: contrast(1);--prose-ol-li-markerColor: currentColor;--prose-ul-li-markerColor: currentColor;--prose-a-code-color-hover: currentColor;--prose-a-code-color-static: currentColor;--prose-a-border-color-hover: currentColor;--prose-a-border-color-static: currentColor;--prose-a-color-static: inherit;--elements-backdrop-background: #0c0d0ccc;--docus-search-results-selected-backgroundColor: var(--color-gray-700);--docus-search-input-backgroundColor: var(--color-gray-800);--docus-search-input-borderColor: transparent;--docus-header-title-color-static: var(--color-gray-100);--docus-body-color: var(--color-gray-200);--docus-body-backgroundColor: var(--color-black);--typography-body-backgroundColor: var(--color-black);--typography-body-color: var(--color-white);--elements-state-danger-borderColor-secondary: var(--color-red-700);--elements-state-danger-borderColor-primary: var(--color-red-800);--elements-state-danger-backgroundColor-secondary: var(--color-red-800);--elements-state-danger-backgroundColor-primary: var(--color-red-900);--elements-state-danger-color-secondary: var(--color-red-200);--elements-state-danger-color-primary: var(--color-red-300);--elements-state-warning-borderColor-secondary: var(--color-yellow-700);--elements-state-warning-borderColor-primary: var(--color-yellow-800);--elements-state-warning-backgroundColor-secondary: var(--color-yellow-800);--elements-state-warning-backgroundColor-primary: var(--color-yellow-900);--elements-state-warning-color-secondary: var(--color-yellow-200);--elements-state-warning-color-primary: var(--color-yellow-400);--elements-state-success-borderColor-secondary: var(--color-green-700);--elements-state-success-borderColor-primary: var(--color-green-800);--elements-state-success-backgroundColor-secondary: var(--color-green-800);--elements-state-success-backgroundColor-primary: var(--color-green-900);--elements-state-success-color-secondary: var(--color-green-200);--elements-state-success-color-primary: var(--color-green-400);--elements-state-info-borderColor-secondary: var(--color-blue-700);--elements-state-info-borderColor-primary: var(--color-blue-800);--elements-state-info-backgroundColor-secondary: var(--color-blue-800);--elements-state-info-backgroundColor-primary: var(--color-blue-900);--elements-state-info-color-secondary: var(--color-blue-200);--elements-state-info-color-primary: var(--color-blue-400);--elements-state-primary-borderColor-secondary: var(--color-primary-700);--elements-state-primary-borderColor-primary: var(--color-primary-800);--elements-state-primary-backgroundColor-secondary: var(--color-primary-800);--elements-state-primary-backgroundColor-primary: var(--color-primary-900);--elements-state-primary-color-secondary: var(--color-primary-200);--elements-state-primary-color-primary: var(--color-primary-400);--elements-surface-secondary-backgroundColor: var(--color-gray-800);--elements-surface-primary-backgroundColor: var(--color-gray-900);--elements-surface-background-base: var(--color-gray-900);--elements-border-secondary-static: var(--color-gray-800);--elements-border-primary-hover: var(--color-gray-800);--elements-border-primary-static: var(--color-gray-900);--elements-text-secondary-color-hover: var(--color-gray-200);--elements-text-secondary-color-static: var(--color-gray-400);--elements-text-primary-color-static: var(--color-gray-50);--color-shadow: var(--color-gray-800);--prose-code-inline-backgroundColor: var(--typography-color-secondary-800);--prose-code-inline-color: var(--typography-color-secondary-200);--prose-code-block-backgroundColor: var(--typography-color-secondary-900);--prose-code-block-color: var(--typography-color-secondary-200);--prose-code-block-border-color: var(--typography-color-secondary-800);--prose-tbody-tr-borderBottom-color: var(--typography-color-secondary-800);--prose-th-color: var(--typography-color-secondary-400);--prose-thead-borderBottom-color: var(--typography-color-secondary-800);--prose-thead-border-color: var(--typography-color-secondary-600);--prose-hr-color: var(--typography-color-secondary-800);--prose-blockquote-border-color: var(--typography-color-secondary-700);--prose-blockquote-color: var(--typography-color-secondary-400);--prose-a-code-background-hover: var(--typography-color-primary-900);--prose-a-code-border-color-hover: var(--typography-color-primary-600);--prose-a-code-border-color-static: var(--typography-color-secondary-600);--prose-a-color-hover: var(--typography-color-primary-400); } }@media (min-width: 640px) { :root {--pinceau-mq: sm; --docus-search-results-window-maxHeight: 320px;--docus-search-results-window-marginTop: 20vh;--docus-footer-height: 100px;--docus-search-results-window-borderRadius: var(--radii-xs);--docus-search-results-window-marginX: var(--space-4);--docus-header-logo-height: var(--space-7); } }</style><script>"use strict";(()=>{const a=window,e=document.documentElement,c=window.localStorage,d=["dark","light"],n=c&&c.getItem&&c.getItem("nuxt-color-mode")||"system";let l=n==="system"?f():n;const i=e.getAttribute("data-color-mode-forced");i&&(l=i),r(l),a["__NUXT_COLOR_MODE__"]={preference:n,value:l,getColorScheme:f,addColorScheme:r,removeColorScheme:u};function r(o){const t=""+o+"",s="theme";e.classList?e.classList.add(t):e.className+=" "+t,s&&e.setAttribute("data-"+s,o)}function u(o){const t=""+o+"",s="theme";e.classList?e.classList.remove(t):e.className=e.className.replace(new RegExp(t,"g"),""),s&&e.removeAttribute("data-"+s)}function m(o){return a.matchMedia("(prefers-color-scheme"+o+")")}function f(){if(a.matchMedia&&m("").media!=="not all"){for(const o of d)if(m(":"+o).matches)return o}return"light"}})();
</script></head><body><!----><!--teleport anchor--><!----><!--teleport anchor--><div id="__nuxt"><div class="app-layout" data-v-5518b344><div class="nuxt-progress" style="width:0%;opacity:0;background-size:Infinity% auto;" data-v-5518b344></div><header class="has-dialog" data-v-5518b344 data-v-1fce2464><div class="container pv-FwUXly pc-rXDDID" data-v-1fce2464 data-v-f95e3fe1><!--[--><div class="section left" data-v-1fce2464><!--[--><button aria-label="Menu" data-v-d3d82abf><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" role="img" class="icon" data-v-d3d82abf style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"/></svg></button><!--teleport start--><!--teleport end--><!--]--><a href="/" class="navbar-logo" aria-label="Up4 Tech" data-v-1fce2464 data-v-2c39ff13><span class="title" data-v-2c39ff13>Up4 Tech</span></a></div><div class="section center" data-v-1fce2464><a href="/" class="navbar-logo" aria-label="Up4 Tech" data-v-1fce2464 data-v-2c39ff13><span class="title" data-v-2c39ff13>Up4 Tech</span></a><!----></div><div class="section right" data-v-1fce2464><!--[--><button type="button" aria-label="Search" data-v-639005c9><span class="content" data-v-639005c9><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-639005c9 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m21 21l-6-6m2-5a7 7 0 1 1-14 0a7 7 0 0 1 14 0"/></svg><span data-v-639005c9>Search</span><span data-v-639005c9><kbd data-v-639005c9>âŒ˜</kbd><kbd data-v-639005c9>K</kbd></span></span></button><!--teleport start--><!--teleport end--><!--]--><button aria-label="Color Mode" data-v-1fce2464 data-v-58532cb3><span data-v-58532cb3>...</span></button><div class="social-icons" data-v-1fce2464><!--[--><a href="https://github.com/ramonpzg/edu_content" rel="noopener noreferrer" target="_blank" title="ramonpzg/edu_content" aria-label="ramonpzg/edu_content" data-v-ab03fb65><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-ab03fb65 style="" width="1em" height="1em" viewBox="0 0 496 512" data-v-a6937c2d><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6c-3.3.3-5.6-1.3-5.6-3.6c0-2 2.3-3.6 5.2-3.6c3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9c2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9c.3 2 2.9 3.3 5.9 2.6c2.9-.7 4.9-2.6 4.6-4.6c-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2c12.8 2.3 17.3-5.6 17.3-12.1c0-6.2-.3-40.4-.3-61.4c0 0-70 15-84.7-29.8c0 0-11.4-29.1-27.8-36.6c0 0-22.9-15.7 1.6-15.4c0 0 24.9 2 38.6 25.8c21.9 38.6 58.6 27.5 72.9 20.9c2.3-16 8.8-27.1 16-33.7c-55.9-6.2-112.3-14.3-112.3-110.5c0-27.5 7.6-41.3 23.6-58.9c-2.6-6.5-11.1-33.3 2.6-67.9c20.9-6.5 69 27 69 27c20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27c13.7 34.7 5.2 61.4 2.6 67.9c16 17.7 25.8 31.5 25.8 58.9c0 96.5-58.9 104.2-114.8 110.5c9.2 7.9 17 22.9 17 46.4c0 33.7-.3 75.4-.3 83.6c0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252C496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2c1.6 1.6 3.9 2.3 5.2 1c1.3-1 1-3.3-.7-5.2c-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9c1.6 1 3.6.7 4.3-.7c.7-1.3-.3-2.9-2.3-3.9c-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2c2.3 2.3 5.2 2.6 6.5 1c1.3-1.3.7-4.3-1.3-6.2c-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2c-1.4-2.3-4-3.3-5.6-2"/></svg></a><a href="https://nuxt.com" rel="noopener noreferrer" target="_blank" title="Nuxt" aria-label="Nuxt" data-v-ab03fb65><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-ab03fb65 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="M13.464 19.83h8.922c.283 0 .562-.073.807-.21a1.6 1.6 0 0 0 .591-.574a1.53 1.53 0 0 0 .216-.783a1.53 1.53 0 0 0-.217-.782L17.792 7.414a1.6 1.6 0 0 0-.591-.573a1.65 1.65 0 0 0-.807-.21c-.283 0-.562.073-.807.21a1.6 1.6 0 0 0-.59.573L13.463 9.99L10.47 4.953a1.6 1.6 0 0 0-.591-.573a1.65 1.65 0 0 0-.807-.21c-.284 0-.562.073-.807.21a1.6 1.6 0 0 0-.591.573L.216 17.481a1.53 1.53 0 0 0-.217.782c0 .275.074.545.216.783a1.6 1.6 0 0 0 .59.574c.246.137.525.21.808.21h5.6c2.22 0 3.856-.946 4.982-2.79l2.733-4.593l1.464-2.457l4.395 7.382h-5.859Zm-6.341-2.46l-3.908-.002l5.858-9.842l2.923 4.921l-1.957 3.29c-.748 1.196-1.597 1.632-2.916 1.632"/></svg></a><!--]--></div></div><!--]--></div></header><main data-v-5518b344><!--[--><div class="document-driven-page"><div class="container pv-FwUXly pc-xqu5lC docs-page-content fluid has-toc has-aside" data-v-ba22cf1e data-v-f95e3fe1><!--[--><aside class="aside-nav" data-v-ba22cf1e><nav class="app-aside" data-v-ba22cf1e data-v-47381d57><ul class="docs-aside-tree" data-v-47381d57 data-v-246a485b><!--[--><li class="" data-v-246a485b><button class="title-collapsible-button" data-v-246a485b><span class="content" data-v-246a485b><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-246a485b style="" width="1em" height="1em" viewBox="0 0 256 256" data-v-a6937c2d><g fill="currentColor"><path d="m229.06 108.79l-48.7 42l14.88 62.79a8.4 8.4 0 0 1-12.52 9.17L128 189.09l-54.72 33.65a8.4 8.4 0 0 1-12.52-9.17l14.88-62.79l-48.7-42A8.46 8.46 0 0 1 31.73 94l63.91-5.2l24.62-59.6a8.36 8.36 0 0 1 15.48 0l24.62 59.6l63.91 5.2a8.46 8.46 0 0 1 4.79 14.79" opacity=".2"/><path d="M239.18 97.26A16.38 16.38 0 0 0 224.92 86l-59-4.76l-22.78-55.09a16.36 16.36 0 0 0-30.27 0L90.11 81.23L31.08 86a16.46 16.46 0 0 0-9.37 28.86l45 38.83L53 211.75a16.38 16.38 0 0 0 24.5 17.82l50.5-31.08l50.53 31.08A16.4 16.4 0 0 0 203 211.75l-13.76-58.07l45-38.83a16.43 16.43 0 0 0 4.94-17.59m-15.34 5.47l-48.7 42a8 8 0 0 0-2.56 7.91l14.88 62.8a.37.37 0 0 1-.17.48c-.18.14-.23.11-.38 0l-54.72-33.65a8 8 0 0 0-8.38 0l-54.72 33.67c-.15.09-.19.12-.38 0a.37.37 0 0 1-.17-.48l14.88-62.8a8 8 0 0 0-2.56-7.91l-48.7-42c-.12-.1-.23-.19-.13-.5s.18-.27.33-.29l63.92-5.16a8 8 0 0 0 6.72-4.94l24.62-59.61c.08-.17.11-.25.35-.25s.27.08.35.25L153 91.86a8 8 0 0 0 6.75 4.92l63.92 5.16c.15 0 .24 0 .33.29s0 .4-.16.5"/></g></svg><span data-v-246a485b>Set Up</span></span><span data-v-246a485b><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon collapsible-icon" data-v-246a485b style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m7 20l5-5l5 5M7 4l5 5l5-5"/></svg></span></button><ul class="docs-aside-tree recursive" style="" data-v-246a485b data-v-246a485b><!--[--><li class="has-parent-icon bordered" data-v-246a485b><a href="/introduction" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Introduction</span></span></a><!----></li><li class="has-parent-icon bordered" data-v-246a485b><a href="/introduction/python_installation" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Python Installation</span></span></a><!----></li><li class="has-parent-icon bordered" data-v-246a485b><a href="/introduction/git_installation" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Git Installation</span></span></a><!----></li><li class="has-parent-icon bordered" data-v-246a485b><a href="/introduction/jupyter_intro" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Jupyter Lab &amp; Notebooks Intro</span></span></a><!----></li><!--]--></ul></li><li class="" data-v-246a485b><button class="title-collapsible-button" data-v-246a485b><span class="content" data-v-246a485b><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-246a485b style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 4v12l-4-2l-4 2V4M6 20h12a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2H6a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2"/></svg><span data-v-246a485b>Programming</span></span><span data-v-246a485b><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon collapsible-icon" data-v-246a485b style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m7 20l5-5l5 5M7 4l5 5l5-5"/></svg></span></button><ul class="docs-aside-tree recursive" style="" data-v-246a485b data-v-246a485b><!--[--><li class="has-parent-icon bordered" data-v-246a485b><a href="/programming" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Programming Tutorials</span></span></a><!----></li><li class="has-parent-icon has-children bordered" data-v-246a485b><button class="title-collapsible-button" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Terminal</span></span><span data-v-246a485b><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon collapsible-icon" data-v-246a485b style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m7 15l5 5l5-5M7 9l5-5l5 5"/></svg></span></button><ul class="docs-aside-tree recursive" style="display:none;" data-v-246a485b data-v-246a485b><!--[--><li class="bordered" data-v-246a485b><a href="/programming/terminal/shell_intro" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Intro to the Terminal</span></span></a><!----></li><!--]--></ul></li><!--]--></ul></li><li class="" data-v-246a485b><button class="title-collapsible-button" data-v-246a485b><span class="content" data-v-246a485b><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-246a485b style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="M5 3v16h16v2H3V3zm15.293 3.293l1.414 1.414L16 13.414l-3-2.999l-4.293 4.292l-1.414-1.414L13 7.586l3 2.999z"/></svg><span data-v-246a485b>Analytics</span></span><span data-v-246a485b><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon collapsible-icon" data-v-246a485b style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m7 20l5-5l5 5M7 4l5 5l5-5"/></svg></span></button><ul class="docs-aside-tree recursive" style="" data-v-246a485b data-v-246a485b><!--[--><li class="has-parent-icon bordered" data-v-246a485b><a href="/analytics" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Data Analytics</span></span></a><!----></li><li class="has-parent-icon bordered" data-v-246a485b><a href="/analytics/numerical_computing" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Numerical Computing</span></span></a><!----></li><li class="has-parent-icon bordered" data-v-246a485b><a href="/analytics/structured_data" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Intro to pandas</span></span></a><!----></li><li class="has-parent-icon bordered" data-v-246a485b><a href="/analytics/stats_intro" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Intro to Statistics</span></span></a><!----></li><li class="has-parent-icon bordered" data-v-246a485b><a href="/analytics/describing_data" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Describing Data</span></span></a><!----></li><li class="has-parent-icon bordered" data-v-246a485b><a href="/analytics/eda" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Exploratory Data Analysis</span></span></a><!----></li><!--]--></ul></li><li class="" data-v-246a485b><button class="title-collapsible-button" data-v-246a485b><span class="content" data-v-246a485b><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-246a485b style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m8.686 4l2.607-2.607a1 1 0 0 1 1.414 0L15.314 4H19a1 1 0 0 1 1 1v3.686l2.607 2.607a1 1 0 0 1 0 1.414L20 15.314V19a1 1 0 0 1-1 1h-3.686l-2.607 2.607a1 1 0 0 1-1.414 0L8.686 20H5a1 1 0 0 1-1-1v-3.686l-2.607-2.607a1 1 0 0 1 0-1.414L4 8.686V5a1 1 0 0 1 1-1zM6 6v3.515L3.515 12L6 14.485V18h3.515L12 20.485L14.485 18H18v-3.515L20.485 12L18 9.515V6h-3.515L12 3.515L9.515 6zm6 10a4 4 0 1 1 0-8a4 4 0 0 1 0 8m0-2a2 2 0 1 0 0-4a2 2 0 0 0 0 4"/></svg><span data-v-246a485b>Data Engineering</span></span><span data-v-246a485b><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon collapsible-icon" data-v-246a485b style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m7 20l5-5l5 5M7 4l5 5l5-5"/></svg></span></button><ul class="docs-aside-tree recursive" style="" data-v-246a485b data-v-246a485b><!--[--><li class="has-parent-icon bordered" data-v-246a485b><a href="/data-engineering/data_pipelines_getting_started" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Data Pipelines From Scratch</span></span></a><!----></li><li class="has-parent-icon bordered" data-v-246a485b><a href="/data-engineering/getting_data" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Getting Data as DataFrames</span></span></a><!----></li><li class="has-parent-icon bordered active" data-v-246a485b><a aria-current="page" href="/data-engineering/data_cleaning" class="router-link-active router-link-exact-active link padded active" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Data Cleaning</span></span></a><!----></li><li class="has-parent-icon bordered" data-v-246a485b><a href="/data-engineering/etl_pipes" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>01 ETL Pipelines</span></span></a><!----></li><li class="has-parent-icon bordered" data-v-246a485b><a href="/data-engineering/data_pipelines_getting_started" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Data Pipelines From Scratch</span></span></a><!----></li><!--]--></ul></li><li class="" data-v-246a485b><button class="title-collapsible-button" data-v-246a485b><span class="content" data-v-246a485b><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-246a485b style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="M15.199 9.944a2.6 2.6 0 0 1-.79-1.55l-.403-3.083l-2.731 1.486a2.6 2.6 0 0 1-1.719.272L6.5 6.5l.57 3.056a2.6 2.6 0 0 1-.273 1.72l-1.486 2.73l3.083.403a2.6 2.6 0 0 1 1.55.79l2.138 2.257l1.336-2.807a2.6 2.6 0 0 1 1.23-1.231l2.808-1.336zm.025 5.564l-2.213 4.65a.6.6 0 0 1-.977.155l-3.542-3.739a.6.6 0 0 0-.358-.182l-5.106-.668a.6.6 0 0 1-.45-.881l2.462-4.524a.6.6 0 0 0 .063-.396L4.16 4.86a.6.6 0 0 1 .7-.7l5.062.943a.6.6 0 0 0 .397-.063l4.523-2.46a.6.6 0 0 1 .882.448l.668 5.107a.6.6 0 0 0 .182.357l3.739 3.542a.6.6 0 0 1-.155.977l-4.65 2.213a.6.6 0 0 0-.284.284m.797 1.927l1.414-1.414l4.243 4.242l-1.415 1.415z"/></svg><span data-v-246a485b>Data Science</span></span><span data-v-246a485b><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon collapsible-icon" data-v-246a485b style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m7 20l5-5l5 5M7 4l5 5l5-5"/></svg></span></button><ul class="docs-aside-tree recursive" style="" data-v-246a485b data-v-246a485b><!--[--><li class="has-parent-icon bordered" data-v-246a485b><a href="/data-science" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Intro to DS</span></span></a><!----></li><!--]--></ul></li><li class="" data-v-246a485b><button class="title-collapsible-button" data-v-246a485b><span class="content" data-v-246a485b><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-246a485b style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="M13.5 2c0 .444-.193.843-.5 1.118V5h5a3 3 0 0 1 3 3v10a3 3 0 0 1-3 3H6a3 3 0 0 1-3-3V8a3 3 0 0 1 3-3h5V3.118A1.5 1.5 0 1 1 13.5 2M6 7a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V8a1 1 0 0 0-1-1zm-4 3H0v6h2zm20 0h2v6h-2zM9 14.5a1.5 1.5 0 1 0 0-3a1.5 1.5 0 0 0 0 3m6 0a1.5 1.5 0 1 0 0-3a1.5 1.5 0 0 0 0 3"/></svg><span data-v-246a485b>Machine Learning Engineering</span></span><span data-v-246a485b><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon collapsible-icon" data-v-246a485b style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m7 20l5-5l5 5M7 4l5 5l5-5"/></svg></span></button><ul class="docs-aside-tree recursive" style="" data-v-246a485b data-v-246a485b><!--[--><li class="has-parent-icon bordered" data-v-246a485b><a href="/ml-engineering" class="link padded" data-v-246a485b><span class="content" data-v-246a485b><!----><span data-v-246a485b>Intro to MLE</span></span></a><!----></li><!--]--></ul></li><!--]--></ul></nav></aside><article class="page-body" data-v-ba22cf1e><!--[--><!--[--><div><h1 id="data-cleaning" data-v-b293a8e3><a aria-current="page" href="/data-engineering/data_cleaning#data-cleaning" class="router-link-active router-link-exact-active" data-v-b293a8e3><!--[-->Data Cleaning<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-b293a8e3 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m13.172 12l-4.95-4.95l1.414-1.413L16 12l-6.364 6.364l-1.414-1.415z"/></svg></a></h1><blockquote data-v-7aaedb56><!--[--><p data-v-3dd08768><!--[-->&quot;There are only two forces in the world, the sword dirty data and the spirit clean data. In the long run the sword dirty data will (not) always be conquered by the spirit clean data.&quot; ~ Napoleon CleanYourData<!--]--></p><!--]--></blockquote><blockquote data-v-7aaedb56><!--[--><p data-v-3dd08768><!--[-->â€œErrors using inadequate data are much less than those using no data at all.â€ ~ Charles Babbage<!--]--></p><!--]--></blockquote><p data-v-3dd08768><!--[--><img src="https://mir-s3-cdn-cf.behance.net/project_modules/2800_opt_1/26735b30602051.562a428b6a89f.jpg" alt="cleaning" data-v-2da0c6e8><br><strong data-v-b1d4d84a><!--[-->Source:<!--]--></strong> <a href="https://www.behance.net/Tchiniss" rel="nofollow" data-v-d1c581be><!--[-->Matthieu Bogaert<!--]--></a><!--]--></p><h2 id="notebook-structure" data-v-3a00cd39><a aria-current="page" href="/data-engineering/data_cleaning#notebook-structure" class="router-link-active router-link-exact-active" data-v-3a00cd39><!--[-->Notebook Structure<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-3a00cd39 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z"/></svg></a></h2><ol data-v-18730953><!--[--><li data-v-f93bd10c><!--[-->Structure vs Unstructured Data<!--]--></li><li data-v-f93bd10c><!--[-->What is Data Cleaning?<!--]--></li><li data-v-f93bd10c><!--[-->The Data<!--]--></li><li data-v-f93bd10c><!--[-->Data Loading<!--]--></li><li data-v-f93bd10c><!--[-->Data Inspection<!--]--></li><li data-v-f93bd10c><!--[-->Cleaning &amp; Preparation<!--]--></li><li data-v-f93bd10c><!--[-->Save your work<!--]--></li><li data-v-f93bd10c><!--[-->Summary<!--]--></li><!--]--></ol><h2 id="_1-structured-vs-unstructured-data" data-v-3a00cd39><a aria-current="page" href="/data-engineering/data_cleaning#_1-structured-vs-unstructured-data" class="router-link-active router-link-exact-active" data-v-3a00cd39><!--[-->1. Structured vs Unstructured Data<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-3a00cd39 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z"/></svg></a></h2><p data-v-3dd08768><!--[-->Data can be found in mainly two ways in this day and age, as <strong data-v-b1d4d84a><!--[-->structured<!--]--></strong> and <strong data-v-b1d4d84a><!--[-->unstructured<!--]--></strong>.<!--]--></p><p data-v-3dd08768><!--[--><strong data-v-b1d4d84a><!--[-->Structured data<!--]--></strong> is the one we find &quot;neatly&quot; organized in databases as rows and columns. Data in databases are organized in a two-dimensional, tabular format (think of it as the data you see on a grid or matrix-like spreadsheet) where every data point, unit of measure or observation can be found in the rows with a unique identifier attached to it, and where the characteristics (also called variables or features) of each one of these observations can be found in the columns.<!--]--></p><p data-v-3dd08768><!--[--><img src="https://cdn.architecturendesign.net/wp-content/uploads/2015/09/AD-The-Coolest-New-Buildings-On-The-Planet-23.jpg" alt="structure" data-v-2da0c6e8><!--]--></p><p data-v-3dd08768><!--[--><strong data-v-b1d4d84a><!--[-->Unstructured data<!--]--></strong>, on the other hand, is more difficult to acquire, format, and manipulate as it is not often found neatly organized in a database. Unstructured data is often heavily composed of an entangled combination of text, numbers, dates, and other formats of data that are found in the wild (e.g. documents, emails, pictures, etc.).<!--]--></p><p data-v-3dd08768><!--[--><img src="https://ghotchkiss.files.wordpress.com/2015/04/messymarketing.jpeg" alt="unstructure" data-v-2da0c6e8><!--]--></p><h2 id="_2-what-is-a-data-cleaning" data-v-3a00cd39><a aria-current="page" href="/data-engineering/data_cleaning#_2-what-is-a-data-cleaning" class="router-link-active router-link-exact-active" data-v-3a00cd39><!--[-->2. What is a Data Cleaning?<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-3a00cd39 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z"/></svg></a></h2><p data-v-3dd08768><!--[--><img src="http://brewminate.com/wp-content/uploads/2018/02/022518-32-Information-Philosophy.png" alt="data_mess" data-v-2da0c6e8><br><strong data-v-b1d4d84a><!--[-->Source:<!--]--></strong> <a href="https://brewminate.com/" rel="nofollow" data-v-d1c581be><!--[-->https://brewminate.com/<!--]--></a><!--]--></p><p data-v-3dd08768><!--[-->Wikipedia has a beatiful definition of data cleaning, which was in turned modified from a paper from Shaomin Wu titled, <em data-v-101ea33c><!--[-->&quot;A Review on Coarse Warranty Data and Analysis&quot;<!--]--></em> (see citation below).<!--]--></p><blockquote data-v-7aaedb56><!--[--><p data-v-3dd08768><!--[--><em data-v-101ea33c><!--[-->&quot;Data cleansing or data cleaning is the process of detecting and correcting (or removing) corrupt or inaccurate records from a record set, table, or database and refers to identifying incomplete, incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying, or deleting the dirty or coarse data.&quot;<!--]--></em> ~ Wikipedia &amp; Shaomin Wu<!--]--></p><!--]--></blockquote><p data-v-3dd08768><!--[-->When we first encounter messy data, we usually start by going through a non-exhaustive checklist and/or use some rules of thumbs to identify, tackle, and repeat, each mess from the messy pile of data we have. Some of the items in our checklist might be:<!--]--></p><ul data-v-b0218224><!--[--><li data-v-f93bd10c><!--[-->Do we have column names? If so,<!--]--></li><li data-v-f93bd10c><!--[-->Are the column names normalised? (e.g. lower case, spaces or no spaces, numbers only as names)<!--]--></li><li data-v-f93bd10c><!--[-->Do we have dates? If so,
<ul data-v-b0218224><!--[--><li data-v-f93bd10c><!--[-->how are these represented?<!--]--></li><li data-v-f93bd10c><!--[-->Do we have different formats in different rows? (e.g. 31-Oct-2020, October 31st 2020, ...)<!--]--></li><li data-v-f93bd10c><!--[-->Do they have the time in them or is this in a separate column?<!--]--></li><!--]--></ul><!--]--></li><li data-v-f93bd10c><!--[-->Are there different data structures within an element of an observation? (e.g. do we have lists with lists in them inside the value of a row and column combinantion)<!--]--></li><li data-v-f93bd10c><!--[-->If we have numerical data points representing a monetary value, which denomination are these in?<!--]--></li><li data-v-f93bd10c><!--[-->How was the data generated?<!--]--></li><li data-v-f93bd10c><!--[-->Do we have any missing values? if so,
<ul data-v-b0218224><!--[--><li data-v-f93bd10c><!--[-->Are they missing at random?<!--]--></li><li data-v-f93bd10c><!--[-->Are they missing by accident? (e.g. was it due to an error during the data collection process)<!--]--></li><li data-v-f93bd10c><!--[-->Are they intentionally empty? (e.g. think of a conditional question in a survey, if the participant answered yes to the previous question, use this one next, if not, skip the next 3 questions)<!--]--></li><!--]--></ul><!--]--></li><li data-v-f93bd10c><!--[-->Are there any outliers in our dataset? if so,
<ul data-v-b0218224><!--[--><li data-v-f93bd10c><!--[-->Are these true outliers? (e.g. finding the salary of Jeff Bezos in a list with the income of all of the people from the state of Washington)<!--]--></li><li data-v-f93bd10c><!--[-->Are these mistakes we need to take care of? (e.g. finding negative prices for the price of bread, that doesn&#39;t sound right)<!--]--></li><!--]--></ul><!--]--></li><li data-v-f93bd10c><!--[-->Are there any duplicate observations/samples in our dataset?<!--]--></li><li data-v-f93bd10c><!--[-->Is the format in which the data is stored the best one available or should we use a different one?<!--]--></li><!--]--></ul><p data-v-3dd08768><!--[-->All of this questions get tackled in a data format described by Hadley Wickham in a paper by the same name as the data format called, <em data-v-101ea33c><!--[-->&quot;Tidy Data&quot;<!--]--></em>. In his paper, Hadley describes <em data-v-101ea33c><!--[-->Tidy Data<!--]--></em> as:<!--]--></p><blockquote data-v-7aaedb56><!--[--><p data-v-3dd08768><!--[--><em data-v-101ea33c><!--[-->&quot;Tidy datasets are easy to manipulate, model and visualise, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table.&quot;<!--]--></em> ~ Hadley Wickham<!--]--></p><!--]--></blockquote><p data-v-3dd08768><!--[-->While our datasets might not contain all of the issues described in Tidy Data that might come un in messy datasets, the strategies and concepts outlined in it will prove useful in many cases you might encounter throughout your career, so I highly recommend that you read it at some point.<!--]--></p><p data-v-3dd08768><!--[-->One last thing about data cleaning, it is not a one time thing inside the data analytics cycle but quite the opposite, you might find yourself going back to the data cleaning process 2 or more times as your understanding of the data increases during the same project.<!--]--></p><p data-v-3dd08768><!--[--><strong data-v-b1d4d84a><!--[-->Sources<!--]--></strong><!--]--></p><ul data-v-b0218224><!--[--><li data-v-f93bd10c><!--[-->Wu, Shaomin (2013) A Review on Coarse Warranty Data and Analysis. Reliability Engineering and System Safety, 114 . pp. 1-11. ISSN 0951-8320.<!--]--></li><li data-v-f93bd10c><!--[-->Wickham, Hadley (2014) Tidy data. The Journal of Statistical Software, vol. 59, 2014. 10. <a href="http://www.jstatsoft.org/v59/i10/" rel="nofollow" data-v-d1c581be><!--[-->http://www.jstatsoft.org/v59/i10/<!--]--></a><!--]--></li><!--]--></ul><h2 id="_3-the-data" data-v-3a00cd39><a aria-current="page" href="/data-engineering/data_cleaning#_3-the-data" class="router-link-active router-link-exact-active" data-v-3a00cd39><!--[-->3. The Data<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-3a00cd39 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z"/></svg></a></h2><p data-v-3dd08768><!--[-->For this lesson, we will be working with a dataset containing weather data for Australia from 2007 to 2017. The nice thing about this dataset is that, although it has been pre-processed and it is quite clean, there is still a fair amount work to do regarding missing values, outliers and the like. Once you are out in the real world, you will encounter a plethora of datasets with different data types per column, incomprehensible data structures and, not to scare you, many other issues such as different formats within different elements inside different structures. In other words, data that might look like this:<!--]--></p><p data-v-3dd08768><!--[--><img src="https://media.giphy.com/media/dZRlFW1sbFEpG/giphy.gif" alt="spaghetti" data-v-2da0c6e8><br><strong data-v-b1d4d84a><!--[-->Source:<!--]--></strong> <a href="https://foodbinge.tumblr.com/post/26122779310" rel="nofollow" data-v-d1c581be><!--[-->https://foodbinge.tumblr.com/post/26122779310<!--]--></a><!--]--></p><p data-v-3dd08768><!--[--><strong data-v-b1d4d84a><!--[-->About the data:<!--]--></strong><br>
This dataset contains weather information from many of the weather stations around Australia. For most weather stations, we have about 365 observations for the years 2007 to 2017. More information about the dataset can be found in the <a href="http://www.bom.gov.au/climate/dwo/" rel="nofollow" data-v-d1c581be><!--[-->Australian Bureau of Meteorology website<!--]--></a>, and below you can find a short description of the variables in the dataset.<!--]--></p><p data-v-3dd08768><!--[--><strong data-v-b1d4d84a><!--[-->Variables info:<!--]--></strong><!--]--></p><ul data-v-b0218224><!--[--><li data-v-f93bd10c><!--[-->Date --&gt; day, month, and year of the observation, each weather station has its own<!--]--></li><li data-v-f93bd10c><!--[-->Location --&gt; location of the weather station<!--]--></li><li data-v-f93bd10c><!--[-->MinTemp --&gt; minimum temperature for that day<!--]--></li><li data-v-f93bd10c><!--[-->MaxTemp --&gt; maximum temperature for that day<!--]--></li><li data-v-f93bd10c><!--[-->Rainfall --&gt; the amount of rainfall recorded for the day in mm<!--]--></li><li data-v-f93bd10c><!--[-->Evaporation --&gt; the so-called Class A pan evaporation (mm) in the 24 hours to 9am<!--]--></li><li data-v-f93bd10c><!--[-->Sunshine --&gt; the number of hours of bright sunshine in the day<!--]--></li><li data-v-f93bd10c><!--[-->WindGustDir --&gt; the direction of the strongest wind gust in the 24 hours to midnight<!--]--></li><li data-v-f93bd10c><!--[-->WindGustSpeed --&gt; the speed (km/h) of the strongest wind gust in the 24 hours to midnight<!--]--></li><li data-v-f93bd10c><!--[-->WindDir9am --&gt; direction of the wind at 9am<!--]--></li><li data-v-f93bd10c><!--[-->WindDir3pm --&gt; direction of the wind at 3pm<!--]--></li><li data-v-f93bd10c><!--[-->WindSpeed9am --&gt; wind speed (km/hr) averaged over 10 minutes prior to 9am<!--]--></li><li data-v-f93bd10c><!--[-->WindSpeed3pm --&gt; wind speed (km/hr) averaged over 10 minutes prior to 3pm<!--]--></li><li data-v-f93bd10c><!--[-->Humidity9am --&gt; humidity (percent) at 9am<!--]--></li><li data-v-f93bd10c><!--[-->Humidity3pm --&gt; humidity (percent) at 3pm<!--]--></li><li data-v-f93bd10c><!--[-->Pressure9am --&gt; atmospheric pressure (hpa) reduced to mean sea level at 9am<!--]--></li><li data-v-f93bd10c><!--[-->Pressure3pm --&gt; atmospheric pressure (hpa) reduced to mean sea level at 3pm<!--]--></li><li data-v-f93bd10c><!--[-->Cloud9am --&gt; fraction of sky obscured by cloud at 9am. This is measured in &quot;oktas&quot;, which are a unit of eigths. It records how many<!--]--></li><li data-v-f93bd10c><!--[-->Cloud3pm --&gt; fraction of sky obscured by cloud (in &quot;oktas&quot;: eighths) at 3pm. See Cload9am for a description of the values<!--]--></li><li data-v-f93bd10c><!--[-->Temp9am --&gt; temperature (degrees C) at 9am<!--]--></li><li data-v-f93bd10c><!--[-->Temp3pm --&gt; temperature (degrees C) at 3pm<!--]--></li><li data-v-f93bd10c><!--[-->RainToday --&gt; boolean: 1 if precipitation (mm) in the 24 hours to 9am exceeds 1mm, otherwise 0<!--]--></li><li data-v-f93bd10c><!--[-->RISK_MM --&gt; the amount of next day rain in mm. Used to create response variable RainTomorrow. A kind of measure of the &quot;risk&quot;.<!--]--></li><li data-v-f93bd10c><!--[-->RainTomorrow --&gt; did it rain the following day?<!--]--></li><!--]--></ul><p data-v-3dd08768><!--[-->The dataset and the information for the variables was taken from Kaggle, and you can find out more about the dataset either using the link above or the one below, and about Kaggle using the link below as well.<!--]--></p><p data-v-3dd08768><!--[-->Link --&gt; <a href="https://www.kaggle.com/jsphyg/weather-dataset-rattle-package" rel="nofollow" data-v-d1c581be><!--[-->https://www.kaggle.com/jsphyg/weather-dataset-rattle-package<!--]--></a><!--]--></p><p data-v-3dd08768><!--[-->Now, let&#39;s get to loading, inspecting, and preparing our dataset.<!--]--></p><h2 id="_4-data-loading" data-v-3a00cd39><a aria-current="page" href="/data-engineering/data_cleaning#_4-data-loading" class="router-link-active router-link-exact-active" data-v-3a00cd39><!--[-->4. Data Loading<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-3a00cd39 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z"/></svg></a></h2><p data-v-3dd08768><!--[-->We will be loading the dataset using the <code class="" data-v-d83432f1><!--[-->pd.read_csv()<!--]--></code> method we learned about during the last lesson, but before we load the data, we will see if we can figure inspect the first few rows of it with a helpful command line script called <code class="" data-v-d83432f1><!--[-->head<!--]--></code> (*nix users) or <code class="" data-v-d83432f1><!--[-->type<!--]--></code> (Windows users). You might be wondering if these method resemble the <code class="" data-v-d83432f1><!--[-->df.head()<!--]--></code> method we learned in the last lesson, and the answer is yes. By passing a second parameter <code class="" data-v-d83432f1><!--[-->-n<!--]--></code>, then a number <code class="" data-v-d83432f1><!--[-->-n 5<!--]--></code>, and then the path to the file, we can print the amount of rows we specified to the console. This same command will run smoothly in Git Bash or with the <code class="" data-v-d83432f1><!--[-->type<!--]--></code> command below for Windows users.<!--]--></p><p data-v-3dd08768><!--[-->Let&#39;s try it out.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span># for windows users
</span></span><span class="line" line="2"><span>!type datasets\files\weatherAUS.csv -Head 5
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span># for mac users or windows users with Git Bash
</span></span><span class="line" line="2"><span>!head -n 5 ../datasets/files/weatherAUS.csv
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->Although we described the variables above, we can see that we have a date variable that we can parse as date type while reading the data into memory to save us some time. Let&#39;s go ahead and read in the data after we import our packages. We will assign our data to the variable <code class="" data-v-d83432f1><!--[-->df<!--]--></code>.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>import pandas as pd
</span></span><span class="line" line="2"><span>import numpy as np
</span></span><span class="line" line="3"><span emptylineplaceholder="true">
</span></span><span class="line" line="4"><span>pd.set_option(&#39;display.max_columns&#39;, None)
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->Note that we changed a global option of pandas so that if we print our dataframe, examine its head or tail, we can see all columns printed and not just the first and last 5, which is pandas default.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span># Should you need a quick refresher on pd.read_csv(), run this cell : )
</span></span><span class="line" line="2"><span>pd.read_csv??
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->If you are a windows user, please don&#39;t forget to to use back slashes <code class="" data-v-d83432f1><!--[-->\<!--]--></code> as opposed to forward ones <code class="" data-v-d83432f1><!--[-->/<!--]--></code> when raeding or saving the data.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df = pd.read_csv(&quot;../datasets/files/weatherAUS.csv&quot;, parse_dates=[&#39;Date&#39;])
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span># we have a dataframe
</span></span><span class="line" line="2"><span>type(df)
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df.head()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><h2 id="_5-data-inspection" data-v-3a00cd39><a aria-current="page" href="/data-engineering/data_cleaning#_5-data-inspection" class="router-link-active router-link-exact-active" data-v-3a00cd39><!--[-->5. Data Inspection<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-3a00cd39 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z"/></svg></a></h2><p data-v-3dd08768><!--[-->The first thing we want to do as soon as we get the data is to examine its content not only to see the kind of data we have but also to see if we can spot any inconsistencies that need to be dealt with from the start. Here are a few very useful methods available in pandas.<!--]--></p><ul data-v-b0218224><!--[--><li data-v-f93bd10c><!--[--><code class="" data-v-d83432f1><!--[-->df.head()<!--]--></code> --&gt; shows the first 5 rows of a DataFrame or Series<!--]--></li><li data-v-f93bd10c><!--[--><code class="" data-v-d83432f1><!--[-->df.tail()<!--]--></code> --&gt; shows the last 5 rows of a DataFrame or Series<!--]--></li><li data-v-f93bd10c><!--[--><code class="" data-v-d83432f1><!--[-->df.info()<!--]--></code> --&gt; provides information about the DataFrame or Series<!--]--></li><li data-v-f93bd10c><!--[--><code class="" data-v-d83432f1><!--[-->df.describe()<!--]--></code> --&gt; provides descriptive statistics of the numerical variables in a DataFrame<!--]--></li><li data-v-f93bd10c><!--[--><code class="" data-v-d83432f1><!--[-->df.isna()<!--]--></code> --&gt; returns True for every element that is NaN and False for every element that isn&#39;t<!--]--></li><li data-v-f93bd10c><!--[--><code class="" data-v-d83432f1><!--[-->df.notna()<!--]--></code> --&gt; does the opposite of <code class="" data-v-d83432f1><!--[-->.isna()<!--]--></code><!--]--></li><!--]--></ul><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span># Let&#39;s look at the number of rows and columns we have in our dataset
</span></span><span class="line" line="2"><span>df.shape
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span># let&#39;s now see how our columns are represented
</span></span><span class="line" line="2"><span>df.columns
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span># let&#39;s look at some of the rows at the begining of our dataset
</span></span><span class="line" line="2"><span>df.head()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span># let&#39;s look at some of the rows at the end of our dataset
</span></span><span class="line" line="2"><span>df.tail()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->The <code class="" data-v-d83432f1><!--[-->.info()<!--]--></code> method is a very useful method of pandas that gives use all of the information available in the dataset, plus the memory our dataset is occupying in our computers. To get the size of the dataset we can use the argument <code class="" data-v-d83432f1><!--[-->memory_usage=&#39;deep&#39;<!--]--></code>. Keep in mind though that this parameter can take quite a while to run if it the dataset is too large.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df.info()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df.info(memory_usage=&#39;deep&#39;)
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->Nice, we have a lot of numerical values and also know that our dataset takes up about 70MB of memory in our computer. Let&#39;s examine the unique weather locations for which we have data.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>len(df[&#39;Location&#39;].unique()), df[&#39;Location&#39;].unique()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->Australia collects, or the dataset contains, information from 49 weather stations around the country. Let&#39;s see how many missing values do we have in this dataset. To do this, we can chain the <code class="" data-v-d83432f1><!--[-->.isna()<!--]--></code> method with the <code class="" data-v-d83432f1><!--[-->.sum()<!--]--></code> method, to get the total count of the instances where a value is missing, for each of the columns.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df.isna().sum()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->If we would like to see the percentage of missing values per column, we could divide each column by the total amount of rows in the dataset, and then multiply by 100.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span># if we would like to see the percentage of missing values per row, we could use
</span></span><span class="line" line="2"><span>missing_values = (df.isna().sum() / df.shape[0]) * 100
</span></span><span class="line" line="3"><span>missing_values
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df.describe() # describe excludes all missing data by default and shows us the descriptive stats of our numerical variables
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df.describe().T # remember the .T method to transpose arrays?
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->Let&#39;s double check the years we have data for, and how many values do we have per year.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df[&#39;Date&#39;].dt.year.value_counts()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->We could also look at how much data do we have per city for all of the years. For this we can select the specific location we want, say Sydney, pass this selection as a boolean condition to our dataframe while selecting the Date column, and the use a very covenient pandas method called <code class="" data-v-d83432f1><!--[-->.value_counts()<!--]--></code>. This method counts the instances of every category selected and returns the total number in descending order.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>melbourne = df[&#39;Location&#39;] == &#39;Melbourne&#39;
</span></span><span class="line" line="2"><span>melbourne.head()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>sorted(df.loc[df[&#39;Location&#39;] == &#39;Sydney&#39;, &#39;Date&#39;].dt.year.value_counts())
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->Some of the things we found were:<!--]--></p><ul data-v-b0218224><!--[--><li data-v-f93bd10c><!--[-->Most variables have missing data below 10% of the sample and only a handful have more than 35% of missing values<!--]--></li><li data-v-f93bd10c><!--[-->Most variables are numerical<!--]--></li><li data-v-f93bd10c><!--[-->The columns could be made to lower case<!--]--></li><li data-v-f93bd10c><!--[-->We need to figure out why the data is missing where it is missing<!--]--></li><!--]--></ul><h2 id="_6-cleaning-preparation" data-v-3a00cd39><a aria-current="page" href="/data-engineering/data_cleaning#_6-cleaning-preparation" class="router-link-active router-link-exact-active" data-v-3a00cd39><!--[-->6. Cleaning &amp; Preparation<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-3a00cd39 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z"/></svg></a></h2><p data-v-3dd08768><!--[-->Cleaning and prepraring our data for analysis is one of the most crucial step of the data analytics cycle, and a non-perfect one as well. You will often find yourself coming up with different ways of reshaping and structuring the data, and thus, coming back to the <strong data-v-b1d4d84a><!--[-->Clean &amp; Prepare<!--]--></strong> stage of the process. This is completely normal and somewhat rewarding, especially since a lot of the times, insights come out when you least expect them, and even while you are working with different data.<!--]--></p><p data-v-3dd08768><!--[-->Let&#39;s begin by normalising our columns so that they have no spaces and are all lowercase. This is never a necessity but rather a preference.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df.columns
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>[col.lower() for col in df.columns]
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span># Let&#39;s normalise the columns
</span></span><span class="line" line="2"><span>df.columns = [col.lower() for col in df.columns]
</span></span><span class="line" line="3"><span>df.columns
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><h3 id="_61-dealing-with-missing-values" data-v-4d9f06da><a aria-current="page" href="/data-engineering/data_cleaning#_61-dealing-with-missing-values" class="router-link-active router-link-exact-active" data-v-4d9f06da><!--[-->6.1 Dealing with Missing Values<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-4d9f06da style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m16 12l-6 6V6z"/></svg></a></h3><p data-v-3dd08768><!--[--><img src="https://media.giphy.com/media/26n6WywJyh39n1pBu/giphy.gif" alt="missing" data-v-2da0c6e8><!--]--></p><p data-v-3dd08768><!--[-->In the last section we realised that we have quite a few missing values in some of the columns, and we should deal with them carefully. pandas provides a couple of great tools for dealing with missing values, and here are some of the most important ones dropping and detecting missing values.<!--]--></p><ul data-v-b0218224><!--[--><li data-v-f93bd10c><!--[--><code class="" data-v-d83432f1><!--[-->.dropna()<!--]--></code> --&gt; drops all or some missing values by column or row. Default is row<!--]--></li><li data-v-f93bd10c><!--[--><code class="" data-v-d83432f1><!--[-->.isna()<!--]--></code> --&gt; returns a boolean Series or DataFrame with a True for NaN values<!--]--></li><li data-v-f93bd10c><!--[--><code class="" data-v-d83432f1><!--[-->.notna()<!--]--></code> --&gt; does the opposite of <code class="" data-v-d83432f1><!--[-->.isna()<!--]--></code><!--]--></li><li data-v-f93bd10c><!--[--><code class="" data-v-d83432f1><!--[-->.isnull()<!--]--></code> --&gt; same as <code class="" data-v-d83432f1><!--[-->.isna()<!--]--></code><!--]--></li><li data-v-f93bd10c><!--[--><code class="" data-v-d83432f1><!--[-->.notnull()<!--]--></code> --&gt; same as <code class="" data-v-d83432f1><!--[-->.notna()<!--]--></code><!--]--></li><li data-v-f93bd10c><!--[--><code class="" data-v-d83432f1><!--[-->.fillna()<!--]--></code> --&gt; allows you to fill missing values given a criterion<!--]--></li><!--]--></ul><p data-v-3dd08768><!--[-->When we encounter NaN values, our default action should never be to drop them immediate. We should first figure out why these values might be missing by thoroughly inspecting the data, and by looking at the documentation of how the data was gathered/acquired, should one exist and have enough details of the data collection process, of course. If you come up with a project where you scraped the data you needed, documentation might be a bit trickier.<!--]--></p><p data-v-3dd08768><!--[-->One of the reasons we don&#39;t want to get rid of missing data immediately is that we might not be able to tell, upon first inspection, whether the missing values are due to an error with data collection or simply an instance that doesn&#39;t exist. For example, imagine you own a retail store that sells clothes for all kinds of weather and that you have a general survey that you send out to all of your customers. If you were to ask a customer in Latin America about whether they like to wear fluffy coats or regular coats whenever is winter season, they will probably leave that section blank because they don&#39;t experience a change of weather significant enough to buy that type of clothing. Hence, the missing value is not due to an error but rather an accurate representation of the answers provided by the respondents.<!--]--></p><p data-v-3dd08768><!--[-->We do, however, might want to get rid of columns with too many missing values and/or rows with too few. And this is, in fact, what we will do first by dropping the rows with less than 10% of missing values.<!--]--></p><p data-v-3dd08768><!--[-->We can accomplish this by first creating a condition with our <code class="" data-v-d83432f1><!--[-->missing_values<!--]--></code> values var where we filter out the columns with 10% or more missing values, and leave the ones with less so that we can remove the missing rows from them using the method <code class="" data-v-d83432f1><!--[-->.dropna()<!--]--></code> of pandas. Before getting rid of the missing values though, we will first check if there are any duplicate rows in our dataset that might be inflating the number of missing values.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df.duplicated().head()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span># We use the .sum() method to add up the instances where the values are indeed duplicated
</span></span><span class="line" line="2"><span>df.duplicated().sum()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->Since we detected no duplicates, we will do one last step before removing rows with missing values, and that is to fill in any of the categorical variables with the word <code class="" data-v-d83432f1><!--[-->Unkown<!--]--></code> as a placeholder. We will do so by first creating a dictionary and then passing that dictionary into the <code class="" data-v-d83432f1><!--[-->.fillna()<!--]--></code> pandas method.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df.head()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>categorical_vars = {
</span></span><span class="line" line="2"><span>    &#39;windgustdir&#39;: &#39;Unknown&#39;,
</span></span><span class="line" line="3"><span>    &#39;windgustspeed&#39;: &#39;Unknown&#39;,
</span></span><span class="line" line="4"><span>    &#39;winddir9am&#39;: &#39;Unknown&#39;,
</span></span><span class="line" line="5"><span>    &#39;winddir3pm&#39;: &#39;Unknown&#39;
</span></span><span class="line" line="6"><span>}
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df[categorical_vars.keys()].head()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df.fillna(categorical_vars, inplace=True)
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>missing_values = (df.isna().sum() / df.shape[0]) * 100
</span></span><span class="line" line="2"><span>missing_values
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>type(missing_values)
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>missing_values[(missing_values &lt;= 10) &amp; (missing_values &gt; 0)].index
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>mask_of_rows_to_drop = (missing_values &lt;= 10) &amp; (missing_values &gt; 0)
</span></span><span class="line" line="2"><span emptylineplaceholder="true">
</span></span><span class="line" line="3"><span>rows_to_drop = list(missing_values[mask_of_rows_to_drop].index)
</span></span><span class="line" line="4"><span>rows_to_drop
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span># we will assign the new dataframe to a new variable
</span></span><span class="line" line="2"><span emptylineplaceholder="true">
</span></span><span class="line" line="3"><span>df_clean1 = df.dropna(subset=rows_to_drop, axis=0).copy()
</span></span><span class="line" line="4"><span emptylineplaceholder="true">
</span></span><span class="line" line="5"><span># and then check if there was a significant change
</span></span><span class="line" line="6"><span>(df_clean1.isna().sum() / df_clean1.shape[0]) * 100
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->The following subtraction will tell us how many rows were deleted by the previous action. Remember that shape gives us back a tuple with <code class="" data-v-d83432f1><!--[-->(rows_length, col_lenght)<!--]--></code>.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df.shape[0] - df_clean1.shape[0]
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->It is important to note that we not always want to pick such a high number like 10 to drop rows with missing values since we might be sacrificing way too much information. We instead, should work with stakeholders to figure out reasons and/or solutions for missing values. Ideally, dropping rows with 5% or less would be okay for any given dataset but again, it is best to deal with them alongside the subject-matter experts to tackle the issue as best as possible.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df_clean1.info()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->Our next step would be to either drop the columns that have more than a third of their values missing or, to pick a value that makes sense to fill in the missing values. For example, we might want to use the mean or the median of the values of a column to fill in the missing values. If our data was orderd, i.e. time series, we might use methods such as forward and backward fill which take the previous and following available value, respectively, and fill in the missing ones with these.<!--]--></p><p data-v-3dd08768><!--[-->We also need to keep in mind that there may be a few outliers in our columns with missing values, and if so, the mean would give us an unrealistic representation of the missing values. We could deal with these missing values in two ways, for the numerical values we will use the median, which is robust against outliers, and for the categorical variables we will use forward or backward fill or we could fill in the missing instance with the word <code class="" data-v-d83432f1><!--[-->Unknown<!--]--></code> as a placeholder, as done previously, and carry on with cleaning and analysing the data.<!--]--></p><p data-v-3dd08768><!--[-->Let&#39;s examine the columns we have left with missing values.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df_clean1[[&#39;evaporation&#39;, &#39;sunshine&#39;, &#39;cloud9am&#39;, &#39;cloud3pm&#39;]].describe()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->Notice that the minimum value for <code class="" data-v-d83432f1><!--[-->cloud9am<!--]--></code> and <code class="" data-v-d83432f1><!--[-->cloud3pm<!--]--></code> is <code class="" data-v-d83432f1><!--[-->0<!--]--></code>. This means that it could be that there are days with no clouds in the sky. Hence, it might be more realistic to fill in the missing value of our cloudy days with a 0 rather than the mean or the median. Let&#39;s do this with the <code class="" data-v-d83432f1><!--[-->.fillna()<!--]--></code> method.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df_clean1[[&#39;cloud9am&#39;, &#39;cloud3pm&#39;]] = df_clean1[[&#39;cloud9am&#39;, &#39;cloud3pm&#39;]].fillna(0)
</span></span><span class="line" line="2"><span>df_clean1.isna().sum()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->Lastly, evaporation and sunshine both have their mean and medians quite close to each other so we could, potentially, favor either option but there is one more caveat, the standard deviation. The standard deviation is a measure of dispertion that tells us how far, up or down, the fluctuations from the mean might be. To err on the safer side, let&#39;s use the median to fill in our missing values.<!--]--></p><p data-v-3dd08768><!--[-->We will use a loop to do this.<!--]--></p><ol data-v-18730953><!--[--><li data-v-f93bd10c><!--[-->we will iterate over the columns<!--]--></li><li data-v-f93bd10c><!--[-->use the column name to iterate over the dataframe<!--]--></li><li data-v-f93bd10c><!--[-->check for whether a column has missing values<!--]--></li><li data-v-f93bd10c><!--[-->if so, we will use the median of that same column to fill in its missing values<!--]--></li><!--]--></ol><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>for col in df_clean1.columns:
</span></span><span class="line" line="2"><span>    if df_clean1[col].isna().any():
</span></span><span class="line" line="3"><span>        df_clean1[col].fillna(value=df_clean1[col].median(), axis=0, inplace=True)
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->Let&#39;s check if there are any remaining missing values.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df_clean1.isna().sum()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->Nice work! Let&#39;s now get a few additional variables before we move on to saving our cleaned dataset.<!--]--></p><p data-v-3dd08768><!--[-->Since the weather is time series data (e.g. data gathered over time), we will create additional date variables for visualisation purposes. When we have a date column of data type <code class="" data-v-d83432f1><!--[-->datetime<!--]--></code>, we can access all of the attributes available in our date column using the <code class="" data-v-d83432f1><!--[-->dt<!--]--></code> attribute followed by the subattribute we would like to access. You can find out more about the additional subattributes in the <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.html" rel="nofollow" data-v-d1c581be><!--[-->documentation of pandas here<!--]--></a>.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df_clean1[&#39;date&#39;].dt.weekday.head(15)
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df_clean1[&#39;month&#39;] = df_clean1[&#39;date&#39;].dt.month
</span></span><span class="line" line="2"><span>df_clean1[&#39;year&#39;] = df_clean1[&#39;date&#39;].dt.year
</span></span><span class="line" line="3"><span>df_clean1.head()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><h2 id="exercise-1" data-v-3a00cd39><a aria-current="page" href="/data-engineering/data_cleaning#exercise-1" class="router-link-active router-link-exact-active" data-v-3a00cd39><!--[-->Exercise 1<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-3a00cd39 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z"/></svg></a></h2><p data-v-3dd08768><!--[-->Add a new column to the dataset that contains the week of the year. Call the new column, <code class="" data-v-d83432f1><!--[-->week<!--]--></code>.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span></span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><h2 id="exercise-2" data-v-3a00cd39><a aria-current="page" href="/data-engineering/data_cleaning#exercise-2" class="router-link-active router-link-exact-active" data-v-3a00cd39><!--[-->Exercise 2<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-3a00cd39 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z"/></svg></a></h2><p data-v-3dd08768><!--[-->Add a new column to the dataset that contains the weekday in numbers (e.g. 0 == Monday, 1==Tuesday, or something similar). Call the new column, <code class="" data-v-d83432f1><!--[-->weekday<!--]--></code>.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span></span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><h2 id="exercise-3" data-v-3a00cd39><a aria-current="page" href="/data-engineering/data_cleaning#exercise-3" class="router-link-active router-link-exact-active" data-v-3a00cd39><!--[-->Exercise 3<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-3a00cd39 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z"/></svg></a></h2><p data-v-3dd08768><!--[-->Add a new column to the dataset that contains the quarter of the year. Call the new column, <code class="" data-v-d83432f1><!--[-->quarter<!--]--></code>.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span></span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><h2 id="exercise-4" data-v-3a00cd39><a aria-current="page" href="/data-engineering/data_cleaning#exercise-4" class="router-link-active router-link-exact-active" data-v-3a00cd39><!--[-->Exercise 4<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-3a00cd39 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z"/></svg></a></h2><p data-v-3dd08768><!--[-->Add a new column to the dataset that contains the name of the day of a week (e.g. Monday, Tuesday, etc.). Call the new column, <code class="" data-v-d83432f1><!--[-->day_of_week<!--]--></code>.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span></span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><h2 id="exercise-5" data-v-3a00cd39><a aria-current="page" href="/data-engineering/data_cleaning#exercise-5" class="router-link-active router-link-exact-active" data-v-3a00cd39><!--[-->Exercise 5<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-3a00cd39 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z"/></svg></a></h2><p data-v-3dd08768><!--[-->Add a new column to the dataset that says whether it is a weekday or the weekend. Call the new column, <code class="" data-v-d83432f1><!--[-->week_or_end<!--]--></code>.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span></span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span></span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[-->We might want to represent the quarter variable as a category later on, so we will create a dictionary with the values we would like to change, and pass it to our Python&#39;s <code class="" data-v-d83432f1><!--[-->.map()<!--]--></code> function. A very useful fuction to map a function to an array of values, to a column or other data structure. We will assign the result to a new column called <code class="" data-v-d83432f1><!--[-->qrt_cate<!--]--></code>.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span># for more info on how map works, please run this cell
</span></span><span class="line" line="2"><span>map?
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>mapping = {1:&#39;first_Q&#39;,
</span></span><span class="line" line="2"><span>           2:&#39;second_Q&#39;,
</span></span><span class="line" line="3"><span>           3:&#39;third_Q&#39;,
</span></span><span class="line" line="4"><span>           4:&#39;fourth_Q&#39;}
</span></span><span class="line" line="5"><span emptylineplaceholder="true">
</span></span><span class="line" line="6"><span emptylineplaceholder="true">
</span></span><span class="line" line="7"><span>df_clean1[&#39;qtr_cate&#39;] = df_clean1[&#39;quarter&#39;].map(mapping)
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><h2 id="_7-save-your-work" data-v-3a00cd39><a aria-current="page" href="/data-engineering/data_cleaning#_7-save-your-work" class="router-link-active router-link-exact-active" data-v-3a00cd39><!--[-->7. Save your work<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-3a00cd39 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z"/></svg></a></h2><p data-v-3dd08768><!--[-->The last thing we want to do is to reset the index of our dataframe and save its clean version for later use.<!--]--></p><p data-v-3dd08768><!--[-->We can use pandas method <code class="" data-v-d83432f1><!--[-->.reset_index()<!--]--></code> to reset the index. Notice the <code class="" data-v-d83432f1><!--[-->drop=True<!--]--></code>, if we do not make this parameter equal to True, pandas will assign the old index to a new column.<!--]--></p><p data-v-3dd08768><!--[-->The next method we will use is <code class="" data-v-d83432f1><!--[-->.to_csv()<!--]--></code>. By applying this method to a dataframe, all we need to do is to give the data a name (in quotation marks), and pass in the <code class="" data-v-d83432f1><!--[-->index=False<!--]--></code> parameter if we don&#39;t want the index to be added as a new column.<!--]--></p><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df_ready = df_clean1.reset_index(drop=True).copy()
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>df_ready.to_csv(&#39;weather_ready.csv&#39;, index=False)
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><div class="highlight-python prose-code" meta data-v-e0eae3fb><!----><!--[--><pre class="language-python shiki shiki-themes github-dark github-light" style=""><!--[--><code><span class="line" line="1"><span>!head -n 5 weather_ready.csv
</span></span></code><!--]--></pre><!--]--><button class="copy-button" data-v-e0eae3fb data-v-333de9a2><span class="sr-only" data-v-333de9a2>Copy to clipboard</span><span class="icon-wrapper" data-v-333de9a2><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-333de9a2 style="" width="18px" height="18px" viewBox="0 0 256 256" data-v-a6937c2d><path fill="currentColor" d="M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z"/></svg></span></button></div><p data-v-3dd08768><!--[--><img src="https://i.chzbgr.com/full/1898496256/h42C0CC42/panda-cleaning-instructions" alt="pandas_tools" data-v-2da0c6e8><!--]--></p><h1 id="awesome-work-we-will-continued-to-clean-more-dataset-but-for-now-on-to-dataviz" data-v-b293a8e3><a aria-current="page" href="/data-engineering/data_cleaning#awesome-work-we-will-continued-to-clean-more-dataset-but-for-now-on-to-dataviz" class="router-link-active router-link-exact-active" data-v-b293a8e3><!--[-->Awesome Work! We will continued to clean more dataset but for now, on to DataViz<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-b293a8e3 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m13.172 12l-4.95-4.95l1.414-1.413L16 12l-6.364 6.364l-1.414-1.415z"/></svg></a></h1><h2 id="_8-summary" data-v-3a00cd39><a aria-current="page" href="/data-engineering/data_cleaning#_8-summary" class="router-link-active router-link-exact-active" data-v-3a00cd39><!--[-->8. Summary<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-3a00cd39 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z"/></svg></a></h2><p data-v-3dd08768><!--[-->In this lesson we have covered pandas in great lenght, and still, we have yet to scratch the surface of what this powerful tool can do. Some keypoints to take away:<!--]--></p><ul data-v-b0218224><!--[--><li data-v-f93bd10c><!--[-->pandas provides two fantastic data structures for data analysis, the DataFrame and the Series<!--]--></li><li data-v-f93bd10c><!--[-->We can slice and dice these data structures to our hearts content all while keeping in mind the inconsistencies that we might find in different datasets<!--]--></li><li data-v-f93bd10c><!--[-->We should always begin by inspecting our data immediately after loading it into our session. pandas provides methods such as info, describe, and isna that work very well and allow us to see what we have the data<!--]--></li><li data-v-f93bd10c><!--[-->When cleaning data, missing values need to be treated carefully as the reasons behind them might differ from one variable to the next.<!--]--></li><li data-v-f93bd10c><!--[-->Always keep in mind to
<ul data-v-b0218224><!--[--><li data-v-f93bd10c><!--[-->Check for duplicates<!--]--></li><li data-v-f93bd10c><!--[-->Normalise columns<!--]--></li><li data-v-f93bd10c><!--[-->Deal with missing values, preferably with stakeholders or subject matter experts if the amount of missing values is vast<!--]--></li><li data-v-f93bd10c><!--[-->Use dates to your advantage<!--]--></li><!--]--></ul><!--]--></li><li data-v-f93bd10c><!--[-->Don&#39;t try to learn all the tools inside pandas but rather explore the ones you need as the need arises, or, explore them slowly and build an intuition for them<!--]--></li><!--]--></ul><h2 id="references" data-v-3a00cd39><a aria-current="page" href="/data-engineering/data_cleaning#references" class="router-link-active router-link-exact-active" data-v-3a00cd39><!--[-->References<!--]--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-3a00cd39 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z"/></svg></a></h2><p data-v-3dd08768><!--[-->Sweigart, Al. <em data-v-101ea33c><!--[-->Automate the Boring Stuff with Python: Practical Programming for Total Beginners<!--]--></em>. No Starch Press, 2020.<!--]--></p><p data-v-3dd08768><!--[-->VanderPlas, Jake. <em data-v-101ea33c><!--[-->A Whirlwind Tour of Python<!--]--></em>. O&#39;Reilly, 2016.<!--]--></p><p data-v-3dd08768><!--[-->VanderPlas, Jake. <em data-v-101ea33c><!--[-->Python Data Science Handbook<!--]--></em>. O&#39;Reilly, 2017.<!--]--></p><p data-v-3dd08768><!--[-->McKinney, Wes. <em data-v-101ea33c><!--[-->Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython<!--]--></em>. OReilly, 2018.<!--]--></p><style>html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}</style></div><!--]--><!--]--><!--[--><div class="docs-page-bottom" data-v-ba22cf1e data-v-bca27376><div class="edit-link" data-v-bca27376><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-bca27376 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="M21 12a1 1 0 0 0-1 1v6a1 1 0 0 1-1 1H5a1 1 0 0 1-1-1V5a1 1 0 0 1 1-1h6a1 1 0 0 0 0-2H5a3 3 0 0 0-3 3v14a3 3 0 0 0 3 3h14a3 3 0 0 0 3-3v-6a1 1 0 0 0-1-1m-15 .76V17a1 1 0 0 0 1 1h4.24a1 1 0 0 0 .71-.29l6.92-6.93L21.71 8a1 1 0 0 0 0-1.42l-4.24-4.29a1 1 0 0 0-1.42 0l-2.82 2.83l-6.94 6.93a1 1 0 0 0-.29.71m10.76-8.35l2.83 2.83l-1.42 1.42l-2.83-2.83ZM8 13.17l5.93-5.93l2.83 2.83L10.83 16H8Z"/></svg><!--[--><a href="https://github.com/ramonpzg/edu_content/edit/main/.starters/default/content/3.data-engineering/2.data_cleaning.md" rel="noopener noreferrer" data-v-bca27376 data-v-d1c581be><!--[--><span data-v-bca27376> Edit this page on GitHub </span><!--]--></a><!--]--></div><!----></div><div class="docs-prev-next" data-v-ba22cf1e data-v-b1d5f4ad><a href="/data-engineering/getting_data" class="prev" data-v-b1d5f4ad><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-b1d5f4ad style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m11 17l-5-5m0 0l5-5m-5 5h12"/></svg><div class="wrapper" data-v-b1d5f4ad><span class="directory" data-v-b1d5f4ad>Data Engineering</span><span class="title" data-v-b1d5f4ad>Getting Data as DataFrames</span></div></a><a href="/data-engineering/etl_pipes" class="next" data-v-b1d5f4ad><div class="wrapper" data-v-b1d5f4ad><span class="directory" data-v-b1d5f4ad>Data Engineering</span><span class="title" data-v-b1d5f4ad>01 ETL Pipelines</span></div><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-b1d5f4ad style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m13 7l5 5m0 0l-5 5m5-5H6"/></svg></a></div><!--]--></article><div class="toc" data-v-ba22cf1e><div class="toc-wrapper" data-v-ba22cf1e><button data-v-ba22cf1e><span class="title" data-v-ba22cf1e>Table of Contents</span><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-ba22cf1e style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m9 5l7 7l-7 7"/></svg></button><div class="docs-toc-wrapper" data-v-ba22cf1e><div class="docs-toc" data-v-ba22cf1e data-v-ea8b373f><!--[--><div class="docs-toc-title" data-v-ea8b373f><span data-v-ea8b373f>Table of Contents</span></div><ul class="docs-toc-links" data-v-ea8b373f data-v-8eeb45b0><!--[--><li class="depth-2" data-v-8eeb45b0><a href="#notebook-structure" class="" data-v-8eeb45b0>Notebook Structure</a><!----></li><li class="depth-2" data-v-8eeb45b0><a href="#_1-structured-vs-unstructured-data" class="" data-v-8eeb45b0>1. Structured vs Unstructured Data</a><!----></li><li class="depth-2" data-v-8eeb45b0><a href="#_2-what-is-a-data-cleaning" class="" data-v-8eeb45b0>2. What is a Data Cleaning?</a><!----></li><li class="depth-2" data-v-8eeb45b0><a href="#_3-the-data" class="" data-v-8eeb45b0>3. The Data</a><!----></li><li class="depth-2" data-v-8eeb45b0><a href="#_4-data-loading" class="" data-v-8eeb45b0>4. Data Loading</a><!----></li><li class="depth-2" data-v-8eeb45b0><a href="#_5-data-inspection" class="" data-v-8eeb45b0>5. Data Inspection</a><!----></li><li class="depth-2" data-v-8eeb45b0><a href="#_6-cleaning-preparation" class="" data-v-8eeb45b0>6. Cleaning &amp; Preparation</a><ul class="docs-toc-links" data-v-8eeb45b0 data-v-8eeb45b0><!--[--><li class="depth-3" data-v-8eeb45b0><a href="#_61-dealing-with-missing-values" class="" data-v-8eeb45b0>6.1 Dealing with Missing Values</a><!----></li><!--]--></ul></li><li class="depth-2" data-v-8eeb45b0><a href="#exercise-1" class="" data-v-8eeb45b0>Exercise 1</a><!----></li><li class="depth-2" data-v-8eeb45b0><a href="#exercise-2" class="" data-v-8eeb45b0>Exercise 2</a><!----></li><li class="depth-2" data-v-8eeb45b0><a href="#exercise-3" class="" data-v-8eeb45b0>Exercise 3</a><!----></li><li class="depth-2" data-v-8eeb45b0><a href="#exercise-4" class="" data-v-8eeb45b0>Exercise 4</a><!----></li><li class="depth-2" data-v-8eeb45b0><a href="#exercise-5" class="" data-v-8eeb45b0>Exercise 5</a><!----></li><li class="depth-2" data-v-8eeb45b0><a href="#_7-save-your-work" class="" data-v-8eeb45b0>7. Save your work</a><!----></li><li class="depth-2" data-v-8eeb45b0><a href="#_8-summary" class="" data-v-8eeb45b0>8. Summary</a><!----></li><li class="depth-2" data-v-8eeb45b0><a href="#references" class="" data-v-8eeb45b0>References</a><!----></li><!--]--></ul><!--]--></div></div></div></div><!--]--></div></div><!--]--></main><footer data-v-5518b344 data-v-e014242d><div class="container pv-FwUXly pc-BGUg4u footer-container" data-v-e014242d data-v-f95e3fe1><!--[--><div class="left" data-v-e014242d><a href="ramonpzg.github.io" rel="noopener" target="_blank" data-v-e014242d><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon left-icon" data-v-e014242d style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z"/></svg><p data-v-e014242d>With â¤ï¸ from the DR ðŸ‡©ðŸ‡´</p></a></div><div class="center" data-v-e014242d><!--[--><!--]--></div><div class="right" data-v-e014242d><!--[--><!--]--><!--[--><a href="https://github.com/ramonpzg/edu_content" rel="noopener noreferrer" target="_blank" title="ramonpzg/edu_content" aria-label="ramonpzg/edu_content" data-v-ab03fb65><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-ab03fb65 style="" width="1em" height="1em" viewBox="0 0 496 512" data-v-a6937c2d><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6c-3.3.3-5.6-1.3-5.6-3.6c0-2 2.3-3.6 5.2-3.6c3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9c2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9c.3 2 2.9 3.3 5.9 2.6c2.9-.7 4.9-2.6 4.6-4.6c-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2c12.8 2.3 17.3-5.6 17.3-12.1c0-6.2-.3-40.4-.3-61.4c0 0-70 15-84.7-29.8c0 0-11.4-29.1-27.8-36.6c0 0-22.9-15.7 1.6-15.4c0 0 24.9 2 38.6 25.8c21.9 38.6 58.6 27.5 72.9 20.9c2.3-16 8.8-27.1 16-33.7c-55.9-6.2-112.3-14.3-112.3-110.5c0-27.5 7.6-41.3 23.6-58.9c-2.6-6.5-11.1-33.3 2.6-67.9c20.9-6.5 69 27 69 27c20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27c13.7 34.7 5.2 61.4 2.6 67.9c16 17.7 25.8 31.5 25.8 58.9c0 96.5-58.9 104.2-114.8 110.5c9.2 7.9 17 22.9 17 46.4c0 33.7-.3 75.4-.3 83.6c0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252C496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2c1.6 1.6 3.9 2.3 5.2 1c1.3-1 1-3.3-.7-5.2c-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9c1.6 1 3.6.7 4.3-.7c.7-1.3-.3-2.9-2.3-3.9c-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2c2.3 2.3 5.2 2.6 6.5 1c1.3-1.3.7-4.3-1.3-6.2c-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2c-1.4-2.3-4-3.3-5.6-2"/></svg></a><a href="https://nuxt.com" rel="noopener noreferrer" target="_blank" title="Nuxt" aria-label="Nuxt" data-v-ab03fb65><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="icon" data-v-ab03fb65 style="" width="1em" height="1em" viewBox="0 0 24 24" data-v-a6937c2d><path fill="currentColor" d="M13.464 19.83h8.922c.283 0 .562-.073.807-.21a1.6 1.6 0 0 0 .591-.574a1.53 1.53 0 0 0 .216-.783a1.53 1.53 0 0 0-.217-.782L17.792 7.414a1.6 1.6 0 0 0-.591-.573a1.65 1.65 0 0 0-.807-.21c-.283 0-.562.073-.807.21a1.6 1.6 0 0 0-.59.573L13.463 9.99L10.47 4.953a1.6 1.6 0 0 0-.591-.573a1.65 1.65 0 0 0-.807-.21c-.284 0-.562.073-.807.21a1.6 1.6 0 0 0-.591.573L.216 17.481a1.53 1.53 0 0 0-.217.782c0 .275.074.545.216.783a1.6 1.6 0 0 0 .59.574c.246.137.525.21.808.21h5.6c2.22 0 3.856-.946 4.982-2.79l2.733-4.593l1.464-2.457l4.395 7.382h-5.859Zm-6.341-2.46l-3.908-.002l5.858-9.842l2.923 4.921l-1.957 3.29c-.748 1.196-1.597 1.632-2.916 1.632"/></svg></a><!--]--></div><!--]--></div></footer></div></div><div id="teleports"></div><script type="application/json" id="__NUXT_DATA__" data-ssr="true" data-src="/data-engineering/data_cleaning/_payload.json">[{"state":1,"once":2838,"_errors":2840,"serverRendered":788,"path":7,"prerenderedAt":2843},["Reactive",2],{"$sdd-pages":3,"$sdd-surrounds":2685,"$sdd-globals":2699,"$scolor-mode":2701,"$sdd-navigation":2703,"$sicons":2782,"$sasideScroll":2829,"$sdocus-docs-aside-collapse-map-/":2830,"$sdocus-docs-aside-collapse-map-/introduction":2831,"$sdocus-docs-aside-collapse-map-/programming":2832,"$sdocus-docs-aside-collapse-map-/programming/terminal":2833,"$sdocus-docs-aside-collapse-map-/analytics":2834,"$sdocus-docs-aside-collapse-map-/data-engineering":2835,"$sdocus-docs-aside-collapse-map-/data-science":2836,"$sdocus-docs-aside-collapse-map-/ml-engineering":2837},["ShallowRef",4],["ShallowReactive",5],{"/data-engineering/data_cleaning":6},{"_path":7,"_dir":8,"_draft":9,"_partial":9,"_locale":10,"title":11,"description":10,"body":12,"_type":2679,"_id":2680,"_source":2681,"_file":2682,"_extension":2683,"layout":2684},"/data-engineering/data_cleaning","data-engineering",false,"","Data Cleaning",{"type":13,"children":14,"toc":2660},"root",[15,23,33,41,71,78,123,129,148,158,166,176,184,190,212,225,238,243,346,365,378,383,388,396,415,421,426,448,470,478,601,606,617,622,628,689,694,724,747,759,801,806,829,850,864,887,901,907,912,986,1009,1032,1054,1077,1098,1112,1126,1131,1145,1165,1179,1184,1215,1229,1243,1248,1262,1275,1298,1312,1317,1340,1346,1358,1363,1376,1390,1420,1427,1435,1440,1521,1526,1531,1536,1556,1570,1593,1613,1626,1683,1697,1711,1732,1746,1760,1798,1851,1863,1877,1882,1896,1901,1914,1919,1933,1968,1991,1996,2001,2024,2055,2060,2073,2078,2107,2121,2152,2158,2170,2183,2189,2201,2214,2220,2232,2245,2251,2263,2276,2282,2294,2307,2320,2340,2363,2425,2431,2436,2457,2478,2492,2506,2520,2528,2534,2540,2545,2601,2607,2619,2631,2642,2654],{"type":16,"tag":17,"props":18,"children":20},"element","h1",{"id":19},"data-cleaning",[21],{"type":22,"value":11},"text",{"type":16,"tag":24,"props":25,"children":26},"blockquote",{},[27],{"type":16,"tag":28,"props":29,"children":30},"p",{},[31],{"type":22,"value":32},"\"There are only two forces in the world, the sword dirty data and the spirit clean data. In the long run the sword dirty data will (not) always be conquered by the spirit clean data.\" ~ Napoleon CleanYourData",{"type":16,"tag":24,"props":34,"children":35},{},[36],{"type":16,"tag":28,"props":37,"children":38},{},[39],{"type":22,"value":40},"â€œErrors using inadequate data are much less than those using no data at all.â€ ~ Charles Babbage",{"type":16,"tag":28,"props":42,"children":43},{},[44,50,54,60,62],{"type":16,"tag":45,"props":46,"children":49},"img",{"alt":47,"src":48},"cleaning","https://mir-s3-cdn-cf.behance.net/project_modules/2800_opt_1/26735b30602051.562a428b6a89f.jpg",[],{"type":16,"tag":51,"props":52,"children":53},"br",{},[],{"type":16,"tag":55,"props":56,"children":57},"strong",{},[58],{"type":22,"value":59},"Source:",{"type":22,"value":61}," ",{"type":16,"tag":63,"props":64,"children":68},"a",{"href":65,"rel":66},"https://www.behance.net/Tchiniss",[67],"nofollow",[69],{"type":22,"value":70},"Matthieu Bogaert",{"type":16,"tag":72,"props":73,"children":75},"h2",{"id":74},"notebook-structure",[76],{"type":22,"value":77},"Notebook Structure",{"type":16,"tag":79,"props":80,"children":81},"ol",{},[82,88,93,98,103,108,113,118],{"type":16,"tag":83,"props":84,"children":85},"li",{},[86],{"type":22,"value":87},"Structure vs Unstructured Data",{"type":16,"tag":83,"props":89,"children":90},{},[91],{"type":22,"value":92},"What is Data Cleaning?",{"type":16,"tag":83,"props":94,"children":95},{},[96],{"type":22,"value":97},"The Data",{"type":16,"tag":83,"props":99,"children":100},{},[101],{"type":22,"value":102},"Data Loading",{"type":16,"tag":83,"props":104,"children":105},{},[106],{"type":22,"value":107},"Data Inspection",{"type":16,"tag":83,"props":109,"children":110},{},[111],{"type":22,"value":112},"Cleaning & Preparation",{"type":16,"tag":83,"props":114,"children":115},{},[116],{"type":22,"value":117},"Save your work",{"type":16,"tag":83,"props":119,"children":120},{},[121],{"type":22,"value":122},"Summary",{"type":16,"tag":72,"props":124,"children":126},{"id":125},"_1-structured-vs-unstructured-data",[127],{"type":22,"value":128},"1. Structured vs Unstructured Data",{"type":16,"tag":28,"props":130,"children":131},{},[132,134,139,141,146],{"type":22,"value":133},"Data can be found in mainly two ways in this day and age, as ",{"type":16,"tag":55,"props":135,"children":136},{},[137],{"type":22,"value":138},"structured",{"type":22,"value":140}," and ",{"type":16,"tag":55,"props":142,"children":143},{},[144],{"type":22,"value":145},"unstructured",{"type":22,"value":147},".",{"type":16,"tag":28,"props":149,"children":150},{},[151,156],{"type":16,"tag":55,"props":152,"children":153},{},[154],{"type":22,"value":155},"Structured data",{"type":22,"value":157}," is the one we find \"neatly\" organized in databases as rows and columns. Data in databases are organized in a two-dimensional, tabular format (think of it as the data you see on a grid or matrix-like spreadsheet) where every data point, unit of measure or observation can be found in the rows with a unique identifier attached to it, and where the characteristics (also called variables or features) of each one of these observations can be found in the columns.",{"type":16,"tag":28,"props":159,"children":160},{},[161],{"type":16,"tag":45,"props":162,"children":165},{"alt":163,"src":164},"structure","https://cdn.architecturendesign.net/wp-content/uploads/2015/09/AD-The-Coolest-New-Buildings-On-The-Planet-23.jpg",[],{"type":16,"tag":28,"props":167,"children":168},{},[169,174],{"type":16,"tag":55,"props":170,"children":171},{},[172],{"type":22,"value":173},"Unstructured data",{"type":22,"value":175},", on the other hand, is more difficult to acquire, format, and manipulate as it is not often found neatly organized in a database. Unstructured data is often heavily composed of an entangled combination of text, numbers, dates, and other formats of data that are found in the wild (e.g. documents, emails, pictures, etc.).",{"type":16,"tag":28,"props":177,"children":178},{},[179],{"type":16,"tag":45,"props":180,"children":183},{"alt":181,"src":182},"unstructure","https://ghotchkiss.files.wordpress.com/2015/04/messymarketing.jpeg",[],{"type":16,"tag":72,"props":185,"children":187},{"id":186},"_2-what-is-a-data-cleaning",[188],{"type":22,"value":189},"2. What is a Data Cleaning?",{"type":16,"tag":28,"props":191,"children":192},{},[193,198,201,205,206],{"type":16,"tag":45,"props":194,"children":197},{"alt":195,"src":196},"data_mess","http://brewminate.com/wp-content/uploads/2018/02/022518-32-Information-Philosophy.png",[],{"type":16,"tag":51,"props":199,"children":200},{},[],{"type":16,"tag":55,"props":202,"children":203},{},[204],{"type":22,"value":59},{"type":22,"value":61},{"type":16,"tag":63,"props":207,"children":210},{"href":208,"rel":209},"https://brewminate.com/",[67],[211],{"type":22,"value":208},{"type":16,"tag":28,"props":213,"children":214},{},[215,217,223],{"type":22,"value":216},"Wikipedia has a beatiful definition of data cleaning, which was in turned modified from a paper from Shaomin Wu titled, ",{"type":16,"tag":218,"props":219,"children":220},"em",{},[221],{"type":22,"value":222},"\"A Review on Coarse Warranty Data and Analysis\"",{"type":22,"value":224}," (see citation below).",{"type":16,"tag":24,"props":226,"children":227},{},[228],{"type":16,"tag":28,"props":229,"children":230},{},[231,236],{"type":16,"tag":218,"props":232,"children":233},{},[234],{"type":22,"value":235},"\"Data cleansing or data cleaning is the process of detecting and correcting (or removing) corrupt or inaccurate records from a record set, table, or database and refers to identifying incomplete, incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying, or deleting the dirty or coarse data.\"",{"type":22,"value":237}," ~ Wikipedia & Shaomin Wu",{"type":16,"tag":28,"props":239,"children":240},{},[241],{"type":22,"value":242},"When we first encounter messy data, we usually start by going through a non-exhaustive checklist and/or use some rules of thumbs to identify, tackle, and repeat, each mess from the messy pile of data we have. Some of the items in our checklist might be:",{"type":16,"tag":244,"props":245,"children":246},"ul",{},[247,252,257,280,285,290,295,318,336,341],{"type":16,"tag":83,"props":248,"children":249},{},[250],{"type":22,"value":251},"Do we have column names? If so,",{"type":16,"tag":83,"props":253,"children":254},{},[255],{"type":22,"value":256},"Are the column names normalised? (e.g. lower case, spaces or no spaces, numbers only as names)",{"type":16,"tag":83,"props":258,"children":259},{},[260,262],{"type":22,"value":261},"Do we have dates? If so,\n",{"type":16,"tag":244,"props":263,"children":264},{},[265,270,275],{"type":16,"tag":83,"props":266,"children":267},{},[268],{"type":22,"value":269},"how are these represented?",{"type":16,"tag":83,"props":271,"children":272},{},[273],{"type":22,"value":274},"Do we have different formats in different rows? (e.g. 31-Oct-2020, October 31st 2020, ...)",{"type":16,"tag":83,"props":276,"children":277},{},[278],{"type":22,"value":279},"Do they have the time in them or is this in a separate column?",{"type":16,"tag":83,"props":281,"children":282},{},[283],{"type":22,"value":284},"Are there different data structures within an element of an observation? (e.g. do we have lists with lists in them inside the value of a row and column combinantion)",{"type":16,"tag":83,"props":286,"children":287},{},[288],{"type":22,"value":289},"If we have numerical data points representing a monetary value, which denomination are these in?",{"type":16,"tag":83,"props":291,"children":292},{},[293],{"type":22,"value":294},"How was the data generated?",{"type":16,"tag":83,"props":296,"children":297},{},[298,300],{"type":22,"value":299},"Do we have any missing values? if so,\n",{"type":16,"tag":244,"props":301,"children":302},{},[303,308,313],{"type":16,"tag":83,"props":304,"children":305},{},[306],{"type":22,"value":307},"Are they missing at random?",{"type":16,"tag":83,"props":309,"children":310},{},[311],{"type":22,"value":312},"Are they missing by accident? (e.g. was it due to an error during the data collection process)",{"type":16,"tag":83,"props":314,"children":315},{},[316],{"type":22,"value":317},"Are they intentionally empty? (e.g. think of a conditional question in a survey, if the participant answered yes to the previous question, use this one next, if not, skip the next 3 questions)",{"type":16,"tag":83,"props":319,"children":320},{},[321,323],{"type":22,"value":322},"Are there any outliers in our dataset? if so,\n",{"type":16,"tag":244,"props":324,"children":325},{},[326,331],{"type":16,"tag":83,"props":327,"children":328},{},[329],{"type":22,"value":330},"Are these true outliers? (e.g. finding the salary of Jeff Bezos in a list with the income of all of the people from the state of Washington)",{"type":16,"tag":83,"props":332,"children":333},{},[334],{"type":22,"value":335},"Are these mistakes we need to take care of? (e.g. finding negative prices for the price of bread, that doesn't sound right)",{"type":16,"tag":83,"props":337,"children":338},{},[339],{"type":22,"value":340},"Are there any duplicate observations/samples in our dataset?",{"type":16,"tag":83,"props":342,"children":343},{},[344],{"type":22,"value":345},"Is the format in which the data is stored the best one available or should we use a different one?",{"type":16,"tag":28,"props":347,"children":348},{},[349,351,356,358,363],{"type":22,"value":350},"All of this questions get tackled in a data format described by Hadley Wickham in a paper by the same name as the data format called, ",{"type":16,"tag":218,"props":352,"children":353},{},[354],{"type":22,"value":355},"\"Tidy Data\"",{"type":22,"value":357},". In his paper, Hadley describes ",{"type":16,"tag":218,"props":359,"children":360},{},[361],{"type":22,"value":362},"Tidy Data",{"type":22,"value":364}," as:",{"type":16,"tag":24,"props":366,"children":367},{},[368],{"type":16,"tag":28,"props":369,"children":370},{},[371,376],{"type":16,"tag":218,"props":372,"children":373},{},[374],{"type":22,"value":375},"\"Tidy datasets are easy to manipulate, model and visualise, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table.\"",{"type":22,"value":377}," ~ Hadley Wickham",{"type":16,"tag":28,"props":379,"children":380},{},[381],{"type":22,"value":382},"While our datasets might not contain all of the issues described in Tidy Data that might come un in messy datasets, the strategies and concepts outlined in it will prove useful in many cases you might encounter throughout your career, so I highly recommend that you read it at some point.",{"type":16,"tag":28,"props":384,"children":385},{},[386],{"type":22,"value":387},"One last thing about data cleaning, it is not a one time thing inside the data analytics cycle but quite the opposite, you might find yourself going back to the data cleaning process 2 or more times as your understanding of the data increases during the same project.",{"type":16,"tag":28,"props":389,"children":390},{},[391],{"type":16,"tag":55,"props":392,"children":393},{},[394],{"type":22,"value":395},"Sources",{"type":16,"tag":244,"props":397,"children":398},{},[399,404],{"type":16,"tag":83,"props":400,"children":401},{},[402],{"type":22,"value":403},"Wu, Shaomin (2013) A Review on Coarse Warranty Data and Analysis. Reliability Engineering and System Safety, 114 . pp. 1-11. ISSN 0951-8320.",{"type":16,"tag":83,"props":405,"children":406},{},[407,409],{"type":22,"value":408},"Wickham, Hadley (2014) Tidy data. The Journal of Statistical Software, vol. 59, 2014. 10. ",{"type":16,"tag":63,"props":410,"children":413},{"href":411,"rel":412},"http://www.jstatsoft.org/v59/i10/",[67],[414],{"type":22,"value":411},{"type":16,"tag":72,"props":416,"children":418},{"id":417},"_3-the-data",[419],{"type":22,"value":420},"3. The Data",{"type":16,"tag":28,"props":422,"children":423},{},[424],{"type":22,"value":425},"For this lesson, we will be working with a dataset containing weather data for Australia from 2007 to 2017. The nice thing about this dataset is that, although it has been pre-processed and it is quite clean, there is still a fair amount work to do regarding missing values, outliers and the like. Once you are out in the real world, you will encounter a plethora of datasets with different data types per column, incomprehensible data structures and, not to scare you, many other issues such as different formats within different elements inside different structures. In other words, data that might look like this:",{"type":16,"tag":28,"props":427,"children":428},{},[429,434,437,441,442],{"type":16,"tag":45,"props":430,"children":433},{"alt":431,"src":432},"spaghetti","https://media.giphy.com/media/dZRlFW1sbFEpG/giphy.gif",[],{"type":16,"tag":51,"props":435,"children":436},{},[],{"type":16,"tag":55,"props":438,"children":439},{},[440],{"type":22,"value":59},{"type":22,"value":61},{"type":16,"tag":63,"props":443,"children":446},{"href":444,"rel":445},"https://foodbinge.tumblr.com/post/26122779310",[67],[447],{"type":22,"value":444},{"type":16,"tag":28,"props":449,"children":450},{},[451,456,459,461,468],{"type":16,"tag":55,"props":452,"children":453},{},[454],{"type":22,"value":455},"About the data:",{"type":16,"tag":51,"props":457,"children":458},{},[],{"type":22,"value":460},"\nThis dataset contains weather information from many of the weather stations around Australia. For most weather stations, we have about 365 observations for the years 2007 to 2017. More information about the dataset can be found in the ",{"type":16,"tag":63,"props":462,"children":465},{"href":463,"rel":464},"http://www.bom.gov.au/climate/dwo/",[67],[466],{"type":22,"value":467},"Australian Bureau of Meteorology website",{"type":22,"value":469},", and below you can find a short description of the variables in the dataset.",{"type":16,"tag":28,"props":471,"children":472},{},[473],{"type":16,"tag":55,"props":474,"children":475},{},[476],{"type":22,"value":477},"Variables info:",{"type":16,"tag":244,"props":479,"children":480},{},[481,486,491,496,501,506,511,516,521,526,531,536,541,546,551,556,561,566,571,576,581,586,591,596],{"type":16,"tag":83,"props":482,"children":483},{},[484],{"type":22,"value":485},"Date --> day, month, and year of the observation, each weather station has its own",{"type":16,"tag":83,"props":487,"children":488},{},[489],{"type":22,"value":490},"Location --> location of the weather station",{"type":16,"tag":83,"props":492,"children":493},{},[494],{"type":22,"value":495},"MinTemp --> minimum temperature for that day",{"type":16,"tag":83,"props":497,"children":498},{},[499],{"type":22,"value":500},"MaxTemp --> maximum temperature for that day",{"type":16,"tag":83,"props":502,"children":503},{},[504],{"type":22,"value":505},"Rainfall --> the amount of rainfall recorded for the day in mm",{"type":16,"tag":83,"props":507,"children":508},{},[509],{"type":22,"value":510},"Evaporation --> the so-called Class A pan evaporation (mm) in the 24 hours to 9am",{"type":16,"tag":83,"props":512,"children":513},{},[514],{"type":22,"value":515},"Sunshine --> the number of hours of bright sunshine in the day",{"type":16,"tag":83,"props":517,"children":518},{},[519],{"type":22,"value":520},"WindGustDir --> the direction of the strongest wind gust in the 24 hours to midnight",{"type":16,"tag":83,"props":522,"children":523},{},[524],{"type":22,"value":525},"WindGustSpeed --> the speed (km/h) of the strongest wind gust in the 24 hours to midnight",{"type":16,"tag":83,"props":527,"children":528},{},[529],{"type":22,"value":530},"WindDir9am --> direction of the wind at 9am",{"type":16,"tag":83,"props":532,"children":533},{},[534],{"type":22,"value":535},"WindDir3pm --> direction of the wind at 3pm",{"type":16,"tag":83,"props":537,"children":538},{},[539],{"type":22,"value":540},"WindSpeed9am --> wind speed (km/hr) averaged over 10 minutes prior to 9am",{"type":16,"tag":83,"props":542,"children":543},{},[544],{"type":22,"value":545},"WindSpeed3pm --> wind speed (km/hr) averaged over 10 minutes prior to 3pm",{"type":16,"tag":83,"props":547,"children":548},{},[549],{"type":22,"value":550},"Humidity9am --> humidity (percent) at 9am",{"type":16,"tag":83,"props":552,"children":553},{},[554],{"type":22,"value":555},"Humidity3pm --> humidity (percent) at 3pm",{"type":16,"tag":83,"props":557,"children":558},{},[559],{"type":22,"value":560},"Pressure9am --> atmospheric pressure (hpa) reduced to mean sea level at 9am",{"type":16,"tag":83,"props":562,"children":563},{},[564],{"type":22,"value":565},"Pressure3pm --> atmospheric pressure (hpa) reduced to mean sea level at 3pm",{"type":16,"tag":83,"props":567,"children":568},{},[569],{"type":22,"value":570},"Cloud9am --> fraction of sky obscured by cloud at 9am. This is measured in \"oktas\", which are a unit of eigths. It records how many",{"type":16,"tag":83,"props":572,"children":573},{},[574],{"type":22,"value":575},"Cloud3pm --> fraction of sky obscured by cloud (in \"oktas\": eighths) at 3pm. See Cload9am for a description of the values",{"type":16,"tag":83,"props":577,"children":578},{},[579],{"type":22,"value":580},"Temp9am --> temperature (degrees C) at 9am",{"type":16,"tag":83,"props":582,"children":583},{},[584],{"type":22,"value":585},"Temp3pm --> temperature (degrees C) at 3pm",{"type":16,"tag":83,"props":587,"children":588},{},[589],{"type":22,"value":590},"RainToday --> boolean: 1 if precipitation (mm) in the 24 hours to 9am exceeds 1mm, otherwise 0",{"type":16,"tag":83,"props":592,"children":593},{},[594],{"type":22,"value":595},"RISK_MM --> the amount of next day rain in mm. Used to create response variable RainTomorrow. A kind of measure of the \"risk\".",{"type":16,"tag":83,"props":597,"children":598},{},[599],{"type":22,"value":600},"RainTomorrow --> did it rain the following day?",{"type":16,"tag":28,"props":602,"children":603},{},[604],{"type":22,"value":605},"The dataset and the information for the variables was taken from Kaggle, and you can find out more about the dataset either using the link above or the one below, and about Kaggle using the link below as well.",{"type":16,"tag":28,"props":607,"children":608},{},[609,611],{"type":22,"value":610},"Link --> ",{"type":16,"tag":63,"props":612,"children":615},{"href":613,"rel":614},"https://www.kaggle.com/jsphyg/weather-dataset-rattle-package",[67],[616],{"type":22,"value":613},{"type":16,"tag":28,"props":618,"children":619},{},[620],{"type":22,"value":621},"Now, let's get to loading, inspecting, and preparing our dataset.",{"type":16,"tag":72,"props":623,"children":625},{"id":624},"_4-data-loading",[626],{"type":22,"value":627},"4. Data Loading",{"type":16,"tag":28,"props":629,"children":630},{},[631,633,640,642,648,650,656,658,664,666,672,674,680,682,687],{"type":22,"value":632},"We will be loading the dataset using the ",{"type":16,"tag":634,"props":635,"children":637},"code",{"className":636},[],[638],{"type":22,"value":639},"pd.read_csv()",{"type":22,"value":641}," method we learned about during the last lesson, but before we load the data, we will see if we can figure inspect the first few rows of it with a helpful command line script called ",{"type":16,"tag":634,"props":643,"children":645},{"className":644},[],[646],{"type":22,"value":647},"head",{"type":22,"value":649}," (*nix users) or ",{"type":16,"tag":634,"props":651,"children":653},{"className":652},[],[654],{"type":22,"value":655},"type",{"type":22,"value":657}," (Windows users). You might be wondering if these method resemble the ",{"type":16,"tag":634,"props":659,"children":661},{"className":660},[],[662],{"type":22,"value":663},"df.head()",{"type":22,"value":665}," method we learned in the last lesson, and the answer is yes. By passing a second parameter ",{"type":16,"tag":634,"props":667,"children":669},{"className":668},[],[670],{"type":22,"value":671},"-n",{"type":22,"value":673},", then a number ",{"type":16,"tag":634,"props":675,"children":677},{"className":676},[],[678],{"type":22,"value":679},"-n 5",{"type":22,"value":681},", and then the path to the file, we can print the amount of rows we specified to the console. This same command will run smoothly in Git Bash or with the ",{"type":16,"tag":634,"props":683,"children":685},{"className":684},[],[686],{"type":22,"value":655},{"type":22,"value":688}," command below for Windows users.",{"type":16,"tag":28,"props":690,"children":691},{},[692],{"type":22,"value":693},"Let's try it out.",{"type":16,"tag":695,"props":696,"children":700},"pre",{"className":697,"code":698,"language":699,"meta":10,"style":10},"language-python shiki shiki-themes github-dark github-light","# for windows users\n!type datasets\\files\\weatherAUS.csv -Head 5\n","python",[701],{"type":16,"tag":634,"props":702,"children":703},{"__ignoreMap":10},[704,715],{"type":16,"tag":705,"props":706,"children":709},"span",{"class":707,"line":708},"line",1,[710],{"type":16,"tag":705,"props":711,"children":712},{},[713],{"type":22,"value":714},"# for windows users\n",{"type":16,"tag":705,"props":716,"children":718},{"class":707,"line":717},2,[719],{"type":16,"tag":705,"props":720,"children":721},{},[722],{"type":22,"value":723},"!type datasets\\files\\weatherAUS.csv -Head 5\n",{"type":16,"tag":695,"props":725,"children":727},{"className":697,"code":726,"language":699,"meta":10,"style":10},"# for mac users or windows users with Git Bash\n!head -n 5 ../datasets/files/weatherAUS.csv\n",[728],{"type":16,"tag":634,"props":729,"children":730},{"__ignoreMap":10},[731,739],{"type":16,"tag":705,"props":732,"children":733},{"class":707,"line":708},[734],{"type":16,"tag":705,"props":735,"children":736},{},[737],{"type":22,"value":738},"# for mac users or windows users with Git Bash\n",{"type":16,"tag":705,"props":740,"children":741},{"class":707,"line":717},[742],{"type":16,"tag":705,"props":743,"children":744},{},[745],{"type":22,"value":746},"!head -n 5 ../datasets/files/weatherAUS.csv\n",{"type":16,"tag":28,"props":748,"children":749},{},[750,752,758],{"type":22,"value":751},"Although we described the variables above, we can see that we have a date variable that we can parse as date type while reading the data into memory to save us some time. Let's go ahead and read in the data after we import our packages. We will assign our data to the variable ",{"type":16,"tag":634,"props":753,"children":755},{"className":754},[],[756],{"type":22,"value":757},"df",{"type":22,"value":147},{"type":16,"tag":695,"props":760,"children":762},{"className":697,"code":761,"language":699,"meta":10,"style":10},"import pandas as pd\nimport numpy as np\n\npd.set_option('display.max_columns', None)\n",[763],{"type":16,"tag":634,"props":764,"children":765},{"__ignoreMap":10},[766,774,782,792],{"type":16,"tag":705,"props":767,"children":768},{"class":707,"line":708},[769],{"type":16,"tag":705,"props":770,"children":771},{},[772],{"type":22,"value":773},"import pandas as pd\n",{"type":16,"tag":705,"props":775,"children":776},{"class":707,"line":717},[777],{"type":16,"tag":705,"props":778,"children":779},{},[780],{"type":22,"value":781},"import numpy as np\n",{"type":16,"tag":705,"props":783,"children":785},{"class":707,"line":784},3,[786],{"type":16,"tag":705,"props":787,"children":789},{"emptyLinePlaceholder":788},true,[790],{"type":22,"value":791},"\n",{"type":16,"tag":705,"props":793,"children":795},{"class":707,"line":794},4,[796],{"type":16,"tag":705,"props":797,"children":798},{},[799],{"type":22,"value":800},"pd.set_option('display.max_columns', None)\n",{"type":16,"tag":28,"props":802,"children":803},{},[804],{"type":22,"value":805},"Note that we changed a global option of pandas so that if we print our dataframe, examine its head or tail, we can see all columns printed and not just the first and last 5, which is pandas default.",{"type":16,"tag":695,"props":807,"children":809},{"className":697,"code":808,"language":699,"meta":10,"style":10},"# Should you need a quick refresher on pd.read_csv(), run this cell : )\npd.read_csv??\n",[810],{"type":16,"tag":634,"props":811,"children":812},{"__ignoreMap":10},[813,821],{"type":16,"tag":705,"props":814,"children":815},{"class":707,"line":708},[816],{"type":16,"tag":705,"props":817,"children":818},{},[819],{"type":22,"value":820},"# Should you need a quick refresher on pd.read_csv(), run this cell : )\n",{"type":16,"tag":705,"props":822,"children":823},{"class":707,"line":717},[824],{"type":16,"tag":705,"props":825,"children":826},{},[827],{"type":22,"value":828},"pd.read_csv??\n",{"type":16,"tag":28,"props":830,"children":831},{},[832,834,840,842,848],{"type":22,"value":833},"If you are a windows user, please don't forget to to use back slashes ",{"type":16,"tag":634,"props":835,"children":837},{"className":836},[],[838],{"type":22,"value":839},"\\",{"type":22,"value":841}," as opposed to forward ones ",{"type":16,"tag":634,"props":843,"children":845},{"className":844},[],[846],{"type":22,"value":847},"/",{"type":22,"value":849}," when raeding or saving the data.",{"type":16,"tag":695,"props":851,"children":853},{"className":697,"code":852,"language":699,"meta":10,"style":10},"df = pd.read_csv(\"../datasets/files/weatherAUS.csv\", parse_dates=['Date'])\n",[854],{"type":16,"tag":634,"props":855,"children":856},{"__ignoreMap":10},[857],{"type":16,"tag":705,"props":858,"children":859},{"class":707,"line":708},[860],{"type":16,"tag":705,"props":861,"children":862},{},[863],{"type":22,"value":852},{"type":16,"tag":695,"props":865,"children":867},{"className":697,"code":866,"language":699,"meta":10,"style":10},"# we have a dataframe\ntype(df)\n",[868],{"type":16,"tag":634,"props":869,"children":870},{"__ignoreMap":10},[871,879],{"type":16,"tag":705,"props":872,"children":873},{"class":707,"line":708},[874],{"type":16,"tag":705,"props":875,"children":876},{},[877],{"type":22,"value":878},"# we have a dataframe\n",{"type":16,"tag":705,"props":880,"children":881},{"class":707,"line":717},[882],{"type":16,"tag":705,"props":883,"children":884},{},[885],{"type":22,"value":886},"type(df)\n",{"type":16,"tag":695,"props":888,"children":890},{"className":697,"code":889,"language":699,"meta":10,"style":10},"df.head()\n",[891],{"type":16,"tag":634,"props":892,"children":893},{"__ignoreMap":10},[894],{"type":16,"tag":705,"props":895,"children":896},{"class":707,"line":708},[897],{"type":16,"tag":705,"props":898,"children":899},{},[900],{"type":22,"value":889},{"type":16,"tag":72,"props":902,"children":904},{"id":903},"_5-data-inspection",[905],{"type":22,"value":906},"5. Data Inspection",{"type":16,"tag":28,"props":908,"children":909},{},[910],{"type":22,"value":911},"The first thing we want to do as soon as we get the data is to examine its content not only to see the kind of data we have but also to see if we can spot any inconsistencies that need to be dealt with from the start. Here are a few very useful methods available in pandas.",{"type":16,"tag":244,"props":913,"children":914},{},[915,925,936,947,958,969],{"type":16,"tag":83,"props":916,"children":917},{},[918,923],{"type":16,"tag":634,"props":919,"children":921},{"className":920},[],[922],{"type":22,"value":663},{"type":22,"value":924}," --> shows the first 5 rows of a DataFrame or Series",{"type":16,"tag":83,"props":926,"children":927},{},[928,934],{"type":16,"tag":634,"props":929,"children":931},{"className":930},[],[932],{"type":22,"value":933},"df.tail()",{"type":22,"value":935}," --> shows the last 5 rows of a DataFrame or Series",{"type":16,"tag":83,"props":937,"children":938},{},[939,945],{"type":16,"tag":634,"props":940,"children":942},{"className":941},[],[943],{"type":22,"value":944},"df.info()",{"type":22,"value":946}," --> provides information about the DataFrame or Series",{"type":16,"tag":83,"props":948,"children":949},{},[950,956],{"type":16,"tag":634,"props":951,"children":953},{"className":952},[],[954],{"type":22,"value":955},"df.describe()",{"type":22,"value":957}," --> provides descriptive statistics of the numerical variables in a DataFrame",{"type":16,"tag":83,"props":959,"children":960},{},[961,967],{"type":16,"tag":634,"props":962,"children":964},{"className":963},[],[965],{"type":22,"value":966},"df.isna()",{"type":22,"value":968}," --> returns True for every element that is NaN and False for every element that isn't",{"type":16,"tag":83,"props":970,"children":971},{},[972,978,980],{"type":16,"tag":634,"props":973,"children":975},{"className":974},[],[976],{"type":22,"value":977},"df.notna()",{"type":22,"value":979}," --> does the opposite of ",{"type":16,"tag":634,"props":981,"children":983},{"className":982},[],[984],{"type":22,"value":985},".isna()",{"type":16,"tag":695,"props":987,"children":989},{"className":697,"code":988,"language":699,"meta":10,"style":10},"# Let's look at the number of rows and columns we have in our dataset\ndf.shape\n",[990],{"type":16,"tag":634,"props":991,"children":992},{"__ignoreMap":10},[993,1001],{"type":16,"tag":705,"props":994,"children":995},{"class":707,"line":708},[996],{"type":16,"tag":705,"props":997,"children":998},{},[999],{"type":22,"value":1000},"# Let's look at the number of rows and columns we have in our dataset\n",{"type":16,"tag":705,"props":1002,"children":1003},{"class":707,"line":717},[1004],{"type":16,"tag":705,"props":1005,"children":1006},{},[1007],{"type":22,"value":1008},"df.shape\n",{"type":16,"tag":695,"props":1010,"children":1012},{"className":697,"code":1011,"language":699,"meta":10,"style":10},"# let's now see how our columns are represented\ndf.columns\n",[1013],{"type":16,"tag":634,"props":1014,"children":1015},{"__ignoreMap":10},[1016,1024],{"type":16,"tag":705,"props":1017,"children":1018},{"class":707,"line":708},[1019],{"type":16,"tag":705,"props":1020,"children":1021},{},[1022],{"type":22,"value":1023},"# let's now see how our columns are represented\n",{"type":16,"tag":705,"props":1025,"children":1026},{"class":707,"line":717},[1027],{"type":16,"tag":705,"props":1028,"children":1029},{},[1030],{"type":22,"value":1031},"df.columns\n",{"type":16,"tag":695,"props":1033,"children":1035},{"className":697,"code":1034,"language":699,"meta":10,"style":10},"# let's look at some of the rows at the begining of our dataset\ndf.head()\n",[1036],{"type":16,"tag":634,"props":1037,"children":1038},{"__ignoreMap":10},[1039,1047],{"type":16,"tag":705,"props":1040,"children":1041},{"class":707,"line":708},[1042],{"type":16,"tag":705,"props":1043,"children":1044},{},[1045],{"type":22,"value":1046},"# let's look at some of the rows at the begining of our dataset\n",{"type":16,"tag":705,"props":1048,"children":1049},{"class":707,"line":717},[1050],{"type":16,"tag":705,"props":1051,"children":1052},{},[1053],{"type":22,"value":889},{"type":16,"tag":695,"props":1055,"children":1057},{"className":697,"code":1056,"language":699,"meta":10,"style":10},"# let's look at some of the rows at the end of our dataset\ndf.tail()\n",[1058],{"type":16,"tag":634,"props":1059,"children":1060},{"__ignoreMap":10},[1061,1069],{"type":16,"tag":705,"props":1062,"children":1063},{"class":707,"line":708},[1064],{"type":16,"tag":705,"props":1065,"children":1066},{},[1067],{"type":22,"value":1068},"# let's look at some of the rows at the end of our dataset\n",{"type":16,"tag":705,"props":1070,"children":1071},{"class":707,"line":717},[1072],{"type":16,"tag":705,"props":1073,"children":1074},{},[1075],{"type":22,"value":1076},"df.tail()\n",{"type":16,"tag":28,"props":1078,"children":1079},{},[1080,1082,1088,1090,1096],{"type":22,"value":1081},"The ",{"type":16,"tag":634,"props":1083,"children":1085},{"className":1084},[],[1086],{"type":22,"value":1087},".info()",{"type":22,"value":1089}," method is a very useful method of pandas that gives use all of the information available in the dataset, plus the memory our dataset is occupying in our computers. To get the size of the dataset we can use the argument ",{"type":16,"tag":634,"props":1091,"children":1093},{"className":1092},[],[1094],{"type":22,"value":1095},"memory_usage='deep'",{"type":22,"value":1097},". Keep in mind though that this parameter can take quite a while to run if it the dataset is too large.",{"type":16,"tag":695,"props":1099,"children":1101},{"className":697,"code":1100,"language":699,"meta":10,"style":10},"df.info()\n",[1102],{"type":16,"tag":634,"props":1103,"children":1104},{"__ignoreMap":10},[1105],{"type":16,"tag":705,"props":1106,"children":1107},{"class":707,"line":708},[1108],{"type":16,"tag":705,"props":1109,"children":1110},{},[1111],{"type":22,"value":1100},{"type":16,"tag":695,"props":1113,"children":1115},{"className":697,"code":1114,"language":699,"meta":10,"style":10},"df.info(memory_usage='deep')\n",[1116],{"type":16,"tag":634,"props":1117,"children":1118},{"__ignoreMap":10},[1119],{"type":16,"tag":705,"props":1120,"children":1121},{"class":707,"line":708},[1122],{"type":16,"tag":705,"props":1123,"children":1124},{},[1125],{"type":22,"value":1114},{"type":16,"tag":28,"props":1127,"children":1128},{},[1129],{"type":22,"value":1130},"Nice, we have a lot of numerical values and also know that our dataset takes up about 70MB of memory in our computer. Let's examine the unique weather locations for which we have data.",{"type":16,"tag":695,"props":1132,"children":1134},{"className":697,"code":1133,"language":699,"meta":10,"style":10},"len(df['Location'].unique()), df['Location'].unique()\n",[1135],{"type":16,"tag":634,"props":1136,"children":1137},{"__ignoreMap":10},[1138],{"type":16,"tag":705,"props":1139,"children":1140},{"class":707,"line":708},[1141],{"type":16,"tag":705,"props":1142,"children":1143},{},[1144],{"type":22,"value":1133},{"type":16,"tag":28,"props":1146,"children":1147},{},[1148,1150,1155,1157,1163],{"type":22,"value":1149},"Australia collects, or the dataset contains, information from 49 weather stations around the country. Let's see how many missing values do we have in this dataset. To do this, we can chain the ",{"type":16,"tag":634,"props":1151,"children":1153},{"className":1152},[],[1154],{"type":22,"value":985},{"type":22,"value":1156}," method with the ",{"type":16,"tag":634,"props":1158,"children":1160},{"className":1159},[],[1161],{"type":22,"value":1162},".sum()",{"type":22,"value":1164}," method, to get the total count of the instances where a value is missing, for each of the columns.",{"type":16,"tag":695,"props":1166,"children":1168},{"className":697,"code":1167,"language":699,"meta":10,"style":10},"df.isna().sum()\n",[1169],{"type":16,"tag":634,"props":1170,"children":1171},{"__ignoreMap":10},[1172],{"type":16,"tag":705,"props":1173,"children":1174},{"class":707,"line":708},[1175],{"type":16,"tag":705,"props":1176,"children":1177},{},[1178],{"type":22,"value":1167},{"type":16,"tag":28,"props":1180,"children":1181},{},[1182],{"type":22,"value":1183},"If we would like to see the percentage of missing values per column, we could divide each column by the total amount of rows in the dataset, and then multiply by 100.",{"type":16,"tag":695,"props":1185,"children":1187},{"className":697,"code":1186,"language":699,"meta":10,"style":10},"# if we would like to see the percentage of missing values per row, we could use\nmissing_values = (df.isna().sum() / df.shape[0]) * 100\nmissing_values\n",[1188],{"type":16,"tag":634,"props":1189,"children":1190},{"__ignoreMap":10},[1191,1199,1207],{"type":16,"tag":705,"props":1192,"children":1193},{"class":707,"line":708},[1194],{"type":16,"tag":705,"props":1195,"children":1196},{},[1197],{"type":22,"value":1198},"# if we would like to see the percentage of missing values per row, we could use\n",{"type":16,"tag":705,"props":1200,"children":1201},{"class":707,"line":717},[1202],{"type":16,"tag":705,"props":1203,"children":1204},{},[1205],{"type":22,"value":1206},"missing_values = (df.isna().sum() / df.shape[0]) * 100\n",{"type":16,"tag":705,"props":1208,"children":1209},{"class":707,"line":784},[1210],{"type":16,"tag":705,"props":1211,"children":1212},{},[1213],{"type":22,"value":1214},"missing_values\n",{"type":16,"tag":695,"props":1216,"children":1218},{"className":697,"code":1217,"language":699,"meta":10,"style":10},"df.describe() # describe excludes all missing data by default and shows us the descriptive stats of our numerical variables\n",[1219],{"type":16,"tag":634,"props":1220,"children":1221},{"__ignoreMap":10},[1222],{"type":16,"tag":705,"props":1223,"children":1224},{"class":707,"line":708},[1225],{"type":16,"tag":705,"props":1226,"children":1227},{},[1228],{"type":22,"value":1217},{"type":16,"tag":695,"props":1230,"children":1232},{"className":697,"code":1231,"language":699,"meta":10,"style":10},"df.describe().T # remember the .T method to transpose arrays?\n",[1233],{"type":16,"tag":634,"props":1234,"children":1235},{"__ignoreMap":10},[1236],{"type":16,"tag":705,"props":1237,"children":1238},{"class":707,"line":708},[1239],{"type":16,"tag":705,"props":1240,"children":1241},{},[1242],{"type":22,"value":1231},{"type":16,"tag":28,"props":1244,"children":1245},{},[1246],{"type":22,"value":1247},"Let's double check the years we have data for, and how many values do we have per year.",{"type":16,"tag":695,"props":1249,"children":1251},{"className":697,"code":1250,"language":699,"meta":10,"style":10},"df['Date'].dt.year.value_counts()\n",[1252],{"type":16,"tag":634,"props":1253,"children":1254},{"__ignoreMap":10},[1255],{"type":16,"tag":705,"props":1256,"children":1257},{"class":707,"line":708},[1258],{"type":16,"tag":705,"props":1259,"children":1260},{},[1261],{"type":22,"value":1250},{"type":16,"tag":28,"props":1263,"children":1264},{},[1265,1267,1273],{"type":22,"value":1266},"We could also look at how much data do we have per city for all of the years. For this we can select the specific location we want, say Sydney, pass this selection as a boolean condition to our dataframe while selecting the Date column, and the use a very covenient pandas method called ",{"type":16,"tag":634,"props":1268,"children":1270},{"className":1269},[],[1271],{"type":22,"value":1272},".value_counts()",{"type":22,"value":1274},". This method counts the instances of every category selected and returns the total number in descending order.",{"type":16,"tag":695,"props":1276,"children":1278},{"className":697,"code":1277,"language":699,"meta":10,"style":10},"melbourne = df['Location'] == 'Melbourne'\nmelbourne.head()\n",[1279],{"type":16,"tag":634,"props":1280,"children":1281},{"__ignoreMap":10},[1282,1290],{"type":16,"tag":705,"props":1283,"children":1284},{"class":707,"line":708},[1285],{"type":16,"tag":705,"props":1286,"children":1287},{},[1288],{"type":22,"value":1289},"melbourne = df['Location'] == 'Melbourne'\n",{"type":16,"tag":705,"props":1291,"children":1292},{"class":707,"line":717},[1293],{"type":16,"tag":705,"props":1294,"children":1295},{},[1296],{"type":22,"value":1297},"melbourne.head()\n",{"type":16,"tag":695,"props":1299,"children":1301},{"className":697,"code":1300,"language":699,"meta":10,"style":10},"sorted(df.loc[df['Location'] == 'Sydney', 'Date'].dt.year.value_counts())\n",[1302],{"type":16,"tag":634,"props":1303,"children":1304},{"__ignoreMap":10},[1305],{"type":16,"tag":705,"props":1306,"children":1307},{"class":707,"line":708},[1308],{"type":16,"tag":705,"props":1309,"children":1310},{},[1311],{"type":22,"value":1300},{"type":16,"tag":28,"props":1313,"children":1314},{},[1315],{"type":22,"value":1316},"Some of the things we found were:",{"type":16,"tag":244,"props":1318,"children":1319},{},[1320,1325,1330,1335],{"type":16,"tag":83,"props":1321,"children":1322},{},[1323],{"type":22,"value":1324},"Most variables have missing data below 10% of the sample and only a handful have more than 35% of missing values",{"type":16,"tag":83,"props":1326,"children":1327},{},[1328],{"type":22,"value":1329},"Most variables are numerical",{"type":16,"tag":83,"props":1331,"children":1332},{},[1333],{"type":22,"value":1334},"The columns could be made to lower case",{"type":16,"tag":83,"props":1336,"children":1337},{},[1338],{"type":22,"value":1339},"We need to figure out why the data is missing where it is missing",{"type":16,"tag":72,"props":1341,"children":1343},{"id":1342},"_6-cleaning-preparation",[1344],{"type":22,"value":1345},"6. Cleaning & Preparation",{"type":16,"tag":28,"props":1347,"children":1348},{},[1349,1351,1356],{"type":22,"value":1350},"Cleaning and prepraring our data for analysis is one of the most crucial step of the data analytics cycle, and a non-perfect one as well. You will often find yourself coming up with different ways of reshaping and structuring the data, and thus, coming back to the ",{"type":16,"tag":55,"props":1352,"children":1353},{},[1354],{"type":22,"value":1355},"Clean & Prepare",{"type":22,"value":1357}," stage of the process. This is completely normal and somewhat rewarding, especially since a lot of the times, insights come out when you least expect them, and even while you are working with different data.",{"type":16,"tag":28,"props":1359,"children":1360},{},[1361],{"type":22,"value":1362},"Let's begin by normalising our columns so that they have no spaces and are all lowercase. This is never a necessity but rather a preference.",{"type":16,"tag":695,"props":1364,"children":1365},{"className":697,"code":1031,"language":699,"meta":10,"style":10},[1366],{"type":16,"tag":634,"props":1367,"children":1368},{"__ignoreMap":10},[1369],{"type":16,"tag":705,"props":1370,"children":1371},{"class":707,"line":708},[1372],{"type":16,"tag":705,"props":1373,"children":1374},{},[1375],{"type":22,"value":1031},{"type":16,"tag":695,"props":1377,"children":1379},{"className":697,"code":1378,"language":699,"meta":10,"style":10},"[col.lower() for col in df.columns]\n",[1380],{"type":16,"tag":634,"props":1381,"children":1382},{"__ignoreMap":10},[1383],{"type":16,"tag":705,"props":1384,"children":1385},{"class":707,"line":708},[1386],{"type":16,"tag":705,"props":1387,"children":1388},{},[1389],{"type":22,"value":1378},{"type":16,"tag":695,"props":1391,"children":1393},{"className":697,"code":1392,"language":699,"meta":10,"style":10},"# Let's normalise the columns\ndf.columns = [col.lower() for col in df.columns]\ndf.columns\n",[1394],{"type":16,"tag":634,"props":1395,"children":1396},{"__ignoreMap":10},[1397,1405,1413],{"type":16,"tag":705,"props":1398,"children":1399},{"class":707,"line":708},[1400],{"type":16,"tag":705,"props":1401,"children":1402},{},[1403],{"type":22,"value":1404},"# Let's normalise the columns\n",{"type":16,"tag":705,"props":1406,"children":1407},{"class":707,"line":717},[1408],{"type":16,"tag":705,"props":1409,"children":1410},{},[1411],{"type":22,"value":1412},"df.columns = [col.lower() for col in df.columns]\n",{"type":16,"tag":705,"props":1414,"children":1415},{"class":707,"line":784},[1416],{"type":16,"tag":705,"props":1417,"children":1418},{},[1419],{"type":22,"value":1031},{"type":16,"tag":1421,"props":1422,"children":1424},"h3",{"id":1423},"_61-dealing-with-missing-values",[1425],{"type":22,"value":1426},"6.1 Dealing with Missing Values",{"type":16,"tag":28,"props":1428,"children":1429},{},[1430],{"type":16,"tag":45,"props":1431,"children":1434},{"alt":1432,"src":1433},"missing","https://media.giphy.com/media/26n6WywJyh39n1pBu/giphy.gif",[],{"type":16,"tag":28,"props":1436,"children":1437},{},[1438],{"type":22,"value":1439},"In the last section we realised that we have quite a few missing values in some of the columns, and we should deal with them carefully. pandas provides a couple of great tools for dealing with missing values, and here are some of the most important ones dropping and detecting missing values.",{"type":16,"tag":244,"props":1441,"children":1442},{},[1443,1454,1464,1479,1495,1510],{"type":16,"tag":83,"props":1444,"children":1445},{},[1446,1452],{"type":16,"tag":634,"props":1447,"children":1449},{"className":1448},[],[1450],{"type":22,"value":1451},".dropna()",{"type":22,"value":1453}," --> drops all or some missing values by column or row. Default is row",{"type":16,"tag":83,"props":1455,"children":1456},{},[1457,1462],{"type":16,"tag":634,"props":1458,"children":1460},{"className":1459},[],[1461],{"type":22,"value":985},{"type":22,"value":1463}," --> returns a boolean Series or DataFrame with a True for NaN values",{"type":16,"tag":83,"props":1465,"children":1466},{},[1467,1473,1474],{"type":16,"tag":634,"props":1468,"children":1470},{"className":1469},[],[1471],{"type":22,"value":1472},".notna()",{"type":22,"value":979},{"type":16,"tag":634,"props":1475,"children":1477},{"className":1476},[],[1478],{"type":22,"value":985},{"type":16,"tag":83,"props":1480,"children":1481},{},[1482,1488,1490],{"type":16,"tag":634,"props":1483,"children":1485},{"className":1484},[],[1486],{"type":22,"value":1487},".isnull()",{"type":22,"value":1489}," --> same as ",{"type":16,"tag":634,"props":1491,"children":1493},{"className":1492},[],[1494],{"type":22,"value":985},{"type":16,"tag":83,"props":1496,"children":1497},{},[1498,1504,1505],{"type":16,"tag":634,"props":1499,"children":1501},{"className":1500},[],[1502],{"type":22,"value":1503},".notnull()",{"type":22,"value":1489},{"type":16,"tag":634,"props":1506,"children":1508},{"className":1507},[],[1509],{"type":22,"value":1472},{"type":16,"tag":83,"props":1511,"children":1512},{},[1513,1519],{"type":16,"tag":634,"props":1514,"children":1516},{"className":1515},[],[1517],{"type":22,"value":1518},".fillna()",{"type":22,"value":1520}," --> allows you to fill missing values given a criterion",{"type":16,"tag":28,"props":1522,"children":1523},{},[1524],{"type":22,"value":1525},"When we encounter NaN values, our default action should never be to drop them immediate. We should first figure out why these values might be missing by thoroughly inspecting the data, and by looking at the documentation of how the data was gathered/acquired, should one exist and have enough details of the data collection process, of course. If you come up with a project where you scraped the data you needed, documentation might be a bit trickier.",{"type":16,"tag":28,"props":1527,"children":1528},{},[1529],{"type":22,"value":1530},"One of the reasons we don't want to get rid of missing data immediately is that we might not be able to tell, upon first inspection, whether the missing values are due to an error with data collection or simply an instance that doesn't exist. For example, imagine you own a retail store that sells clothes for all kinds of weather and that you have a general survey that you send out to all of your customers. If you were to ask a customer in Latin America about whether they like to wear fluffy coats or regular coats whenever is winter season, they will probably leave that section blank because they don't experience a change of weather significant enough to buy that type of clothing. Hence, the missing value is not due to an error but rather an accurate representation of the answers provided by the respondents.",{"type":16,"tag":28,"props":1532,"children":1533},{},[1534],{"type":22,"value":1535},"We do, however, might want to get rid of columns with too many missing values and/or rows with too few. And this is, in fact, what we will do first by dropping the rows with less than 10% of missing values.",{"type":16,"tag":28,"props":1537,"children":1538},{},[1539,1541,1547,1549,1554],{"type":22,"value":1540},"We can accomplish this by first creating a condition with our ",{"type":16,"tag":634,"props":1542,"children":1544},{"className":1543},[],[1545],{"type":22,"value":1546},"missing_values",{"type":22,"value":1548}," values var where we filter out the columns with 10% or more missing values, and leave the ones with less so that we can remove the missing rows from them using the method ",{"type":16,"tag":634,"props":1550,"children":1552},{"className":1551},[],[1553],{"type":22,"value":1451},{"type":22,"value":1555}," of pandas. Before getting rid of the missing values though, we will first check if there are any duplicate rows in our dataset that might be inflating the number of missing values.",{"type":16,"tag":695,"props":1557,"children":1559},{"className":697,"code":1558,"language":699,"meta":10,"style":10},"df.duplicated().head()\n",[1560],{"type":16,"tag":634,"props":1561,"children":1562},{"__ignoreMap":10},[1563],{"type":16,"tag":705,"props":1564,"children":1565},{"class":707,"line":708},[1566],{"type":16,"tag":705,"props":1567,"children":1568},{},[1569],{"type":22,"value":1558},{"type":16,"tag":695,"props":1571,"children":1573},{"className":697,"code":1572,"language":699,"meta":10,"style":10},"# We use the .sum() method to add up the instances where the values are indeed duplicated\ndf.duplicated().sum()\n",[1574],{"type":16,"tag":634,"props":1575,"children":1576},{"__ignoreMap":10},[1577,1585],{"type":16,"tag":705,"props":1578,"children":1579},{"class":707,"line":708},[1580],{"type":16,"tag":705,"props":1581,"children":1582},{},[1583],{"type":22,"value":1584},"# We use the .sum() method to add up the instances where the values are indeed duplicated\n",{"type":16,"tag":705,"props":1586,"children":1587},{"class":707,"line":717},[1588],{"type":16,"tag":705,"props":1589,"children":1590},{},[1591],{"type":22,"value":1592},"df.duplicated().sum()\n",{"type":16,"tag":28,"props":1594,"children":1595},{},[1596,1598,1604,1606,1611],{"type":22,"value":1597},"Since we detected no duplicates, we will do one last step before removing rows with missing values, and that is to fill in any of the categorical variables with the word ",{"type":16,"tag":634,"props":1599,"children":1601},{"className":1600},[],[1602],{"type":22,"value":1603},"Unkown",{"type":22,"value":1605}," as a placeholder. We will do so by first creating a dictionary and then passing that dictionary into the ",{"type":16,"tag":634,"props":1607,"children":1609},{"className":1608},[],[1610],{"type":22,"value":1518},{"type":22,"value":1612}," pandas method.",{"type":16,"tag":695,"props":1614,"children":1615},{"className":697,"code":889,"language":699,"meta":10,"style":10},[1616],{"type":16,"tag":634,"props":1617,"children":1618},{"__ignoreMap":10},[1619],{"type":16,"tag":705,"props":1620,"children":1621},{"class":707,"line":708},[1622],{"type":16,"tag":705,"props":1623,"children":1624},{},[1625],{"type":22,"value":889},{"type":16,"tag":695,"props":1627,"children":1629},{"className":697,"code":1628,"language":699,"meta":10,"style":10},"categorical_vars = {\n    'windgustdir': 'Unknown',\n    'windgustspeed': 'Unknown',\n    'winddir9am': 'Unknown',\n    'winddir3pm': 'Unknown'\n}\n",[1630],{"type":16,"tag":634,"props":1631,"children":1632},{"__ignoreMap":10},[1633,1641,1649,1657,1665,1674],{"type":16,"tag":705,"props":1634,"children":1635},{"class":707,"line":708},[1636],{"type":16,"tag":705,"props":1637,"children":1638},{},[1639],{"type":22,"value":1640},"categorical_vars = {\n",{"type":16,"tag":705,"props":1642,"children":1643},{"class":707,"line":717},[1644],{"type":16,"tag":705,"props":1645,"children":1646},{},[1647],{"type":22,"value":1648},"    'windgustdir': 'Unknown',\n",{"type":16,"tag":705,"props":1650,"children":1651},{"class":707,"line":784},[1652],{"type":16,"tag":705,"props":1653,"children":1654},{},[1655],{"type":22,"value":1656},"    'windgustspeed': 'Unknown',\n",{"type":16,"tag":705,"props":1658,"children":1659},{"class":707,"line":794},[1660],{"type":16,"tag":705,"props":1661,"children":1662},{},[1663],{"type":22,"value":1664},"    'winddir9am': 'Unknown',\n",{"type":16,"tag":705,"props":1666,"children":1668},{"class":707,"line":1667},5,[1669],{"type":16,"tag":705,"props":1670,"children":1671},{},[1672],{"type":22,"value":1673},"    'winddir3pm': 'Unknown'\n",{"type":16,"tag":705,"props":1675,"children":1677},{"class":707,"line":1676},6,[1678],{"type":16,"tag":705,"props":1679,"children":1680},{},[1681],{"type":22,"value":1682},"}\n",{"type":16,"tag":695,"props":1684,"children":1686},{"className":697,"code":1685,"language":699,"meta":10,"style":10},"df[categorical_vars.keys()].head()\n",[1687],{"type":16,"tag":634,"props":1688,"children":1689},{"__ignoreMap":10},[1690],{"type":16,"tag":705,"props":1691,"children":1692},{"class":707,"line":708},[1693],{"type":16,"tag":705,"props":1694,"children":1695},{},[1696],{"type":22,"value":1685},{"type":16,"tag":695,"props":1698,"children":1700},{"className":697,"code":1699,"language":699,"meta":10,"style":10},"df.fillna(categorical_vars, inplace=True)\n",[1701],{"type":16,"tag":634,"props":1702,"children":1703},{"__ignoreMap":10},[1704],{"type":16,"tag":705,"props":1705,"children":1706},{"class":707,"line":708},[1707],{"type":16,"tag":705,"props":1708,"children":1709},{},[1710],{"type":22,"value":1699},{"type":16,"tag":695,"props":1712,"children":1714},{"className":697,"code":1713,"language":699,"meta":10,"style":10},"missing_values = (df.isna().sum() / df.shape[0]) * 100\nmissing_values\n",[1715],{"type":16,"tag":634,"props":1716,"children":1717},{"__ignoreMap":10},[1718,1725],{"type":16,"tag":705,"props":1719,"children":1720},{"class":707,"line":708},[1721],{"type":16,"tag":705,"props":1722,"children":1723},{},[1724],{"type":22,"value":1206},{"type":16,"tag":705,"props":1726,"children":1727},{"class":707,"line":717},[1728],{"type":16,"tag":705,"props":1729,"children":1730},{},[1731],{"type":22,"value":1214},{"type":16,"tag":695,"props":1733,"children":1735},{"className":697,"code":1734,"language":699,"meta":10,"style":10},"type(missing_values)\n",[1736],{"type":16,"tag":634,"props":1737,"children":1738},{"__ignoreMap":10},[1739],{"type":16,"tag":705,"props":1740,"children":1741},{"class":707,"line":708},[1742],{"type":16,"tag":705,"props":1743,"children":1744},{},[1745],{"type":22,"value":1734},{"type":16,"tag":695,"props":1747,"children":1749},{"className":697,"code":1748,"language":699,"meta":10,"style":10},"missing_values[(missing_values \u003C= 10) & (missing_values > 0)].index\n",[1750],{"type":16,"tag":634,"props":1751,"children":1752},{"__ignoreMap":10},[1753],{"type":16,"tag":705,"props":1754,"children":1755},{"class":707,"line":708},[1756],{"type":16,"tag":705,"props":1757,"children":1758},{},[1759],{"type":22,"value":1748},{"type":16,"tag":695,"props":1761,"children":1763},{"className":697,"code":1762,"language":699,"meta":10,"style":10},"mask_of_rows_to_drop = (missing_values \u003C= 10) & (missing_values > 0)\n\nrows_to_drop = list(missing_values[mask_of_rows_to_drop].index)\nrows_to_drop\n",[1764],{"type":16,"tag":634,"props":1765,"children":1766},{"__ignoreMap":10},[1767,1775,1782,1790],{"type":16,"tag":705,"props":1768,"children":1769},{"class":707,"line":708},[1770],{"type":16,"tag":705,"props":1771,"children":1772},{},[1773],{"type":22,"value":1774},"mask_of_rows_to_drop = (missing_values \u003C= 10) & (missing_values > 0)\n",{"type":16,"tag":705,"props":1776,"children":1777},{"class":707,"line":717},[1778],{"type":16,"tag":705,"props":1779,"children":1780},{"emptyLinePlaceholder":788},[1781],{"type":22,"value":791},{"type":16,"tag":705,"props":1783,"children":1784},{"class":707,"line":784},[1785],{"type":16,"tag":705,"props":1786,"children":1787},{},[1788],{"type":22,"value":1789},"rows_to_drop = list(missing_values[mask_of_rows_to_drop].index)\n",{"type":16,"tag":705,"props":1791,"children":1792},{"class":707,"line":794},[1793],{"type":16,"tag":705,"props":1794,"children":1795},{},[1796],{"type":22,"value":1797},"rows_to_drop\n",{"type":16,"tag":695,"props":1799,"children":1801},{"className":697,"code":1800,"language":699,"meta":10,"style":10},"# we will assign the new dataframe to a new variable\n\ndf_clean1 = df.dropna(subset=rows_to_drop, axis=0).copy()\n\n# and then check if there was a significant change\n(df_clean1.isna().sum() / df_clean1.shape[0]) * 100\n",[1802],{"type":16,"tag":634,"props":1803,"children":1804},{"__ignoreMap":10},[1805,1813,1820,1828,1835,1843],{"type":16,"tag":705,"props":1806,"children":1807},{"class":707,"line":708},[1808],{"type":16,"tag":705,"props":1809,"children":1810},{},[1811],{"type":22,"value":1812},"# we will assign the new dataframe to a new variable\n",{"type":16,"tag":705,"props":1814,"children":1815},{"class":707,"line":717},[1816],{"type":16,"tag":705,"props":1817,"children":1818},{"emptyLinePlaceholder":788},[1819],{"type":22,"value":791},{"type":16,"tag":705,"props":1821,"children":1822},{"class":707,"line":784},[1823],{"type":16,"tag":705,"props":1824,"children":1825},{},[1826],{"type":22,"value":1827},"df_clean1 = df.dropna(subset=rows_to_drop, axis=0).copy()\n",{"type":16,"tag":705,"props":1829,"children":1830},{"class":707,"line":794},[1831],{"type":16,"tag":705,"props":1832,"children":1833},{"emptyLinePlaceholder":788},[1834],{"type":22,"value":791},{"type":16,"tag":705,"props":1836,"children":1837},{"class":707,"line":1667},[1838],{"type":16,"tag":705,"props":1839,"children":1840},{},[1841],{"type":22,"value":1842},"# and then check if there was a significant change\n",{"type":16,"tag":705,"props":1844,"children":1845},{"class":707,"line":1676},[1846],{"type":16,"tag":705,"props":1847,"children":1848},{},[1849],{"type":22,"value":1850},"(df_clean1.isna().sum() / df_clean1.shape[0]) * 100\n",{"type":16,"tag":28,"props":1852,"children":1853},{},[1854,1856,1862],{"type":22,"value":1855},"The following subtraction will tell us how many rows were deleted by the previous action. Remember that shape gives us back a tuple with ",{"type":16,"tag":634,"props":1857,"children":1859},{"className":1858},[],[1860],{"type":22,"value":1861},"(rows_length, col_lenght)",{"type":22,"value":147},{"type":16,"tag":695,"props":1864,"children":1866},{"className":697,"code":1865,"language":699,"meta":10,"style":10},"df.shape[0] - df_clean1.shape[0]\n",[1867],{"type":16,"tag":634,"props":1868,"children":1869},{"__ignoreMap":10},[1870],{"type":16,"tag":705,"props":1871,"children":1872},{"class":707,"line":708},[1873],{"type":16,"tag":705,"props":1874,"children":1875},{},[1876],{"type":22,"value":1865},{"type":16,"tag":28,"props":1878,"children":1879},{},[1880],{"type":22,"value":1881},"It is important to note that we not always want to pick such a high number like 10 to drop rows with missing values since we might be sacrificing way too much information. We instead, should work with stakeholders to figure out reasons and/or solutions for missing values. Ideally, dropping rows with 5% or less would be okay for any given dataset but again, it is best to deal with them alongside the subject-matter experts to tackle the issue as best as possible.",{"type":16,"tag":695,"props":1883,"children":1885},{"className":697,"code":1884,"language":699,"meta":10,"style":10},"df_clean1.info()\n",[1886],{"type":16,"tag":634,"props":1887,"children":1888},{"__ignoreMap":10},[1889],{"type":16,"tag":705,"props":1890,"children":1891},{"class":707,"line":708},[1892],{"type":16,"tag":705,"props":1893,"children":1894},{},[1895],{"type":22,"value":1884},{"type":16,"tag":28,"props":1897,"children":1898},{},[1899],{"type":22,"value":1900},"Our next step would be to either drop the columns that have more than a third of their values missing or, to pick a value that makes sense to fill in the missing values. For example, we might want to use the mean or the median of the values of a column to fill in the missing values. If our data was orderd, i.e. time series, we might use methods such as forward and backward fill which take the previous and following available value, respectively, and fill in the missing ones with these.",{"type":16,"tag":28,"props":1902,"children":1903},{},[1904,1906,1912],{"type":22,"value":1905},"We also need to keep in mind that there may be a few outliers in our columns with missing values, and if so, the mean would give us an unrealistic representation of the missing values. We could deal with these missing values in two ways, for the numerical values we will use the median, which is robust against outliers, and for the categorical variables we will use forward or backward fill or we could fill in the missing instance with the word ",{"type":16,"tag":634,"props":1907,"children":1909},{"className":1908},[],[1910],{"type":22,"value":1911},"Unknown",{"type":22,"value":1913}," as a placeholder, as done previously, and carry on with cleaning and analysing the data.",{"type":16,"tag":28,"props":1915,"children":1916},{},[1917],{"type":22,"value":1918},"Let's examine the columns we have left with missing values.",{"type":16,"tag":695,"props":1920,"children":1922},{"className":697,"code":1921,"language":699,"meta":10,"style":10},"df_clean1[['evaporation', 'sunshine', 'cloud9am', 'cloud3pm']].describe()\n",[1923],{"type":16,"tag":634,"props":1924,"children":1925},{"__ignoreMap":10},[1926],{"type":16,"tag":705,"props":1927,"children":1928},{"class":707,"line":708},[1929],{"type":16,"tag":705,"props":1930,"children":1931},{},[1932],{"type":22,"value":1921},{"type":16,"tag":28,"props":1934,"children":1935},{},[1936,1938,1944,1945,1951,1953,1959,1961,1966],{"type":22,"value":1937},"Notice that the minimum value for ",{"type":16,"tag":634,"props":1939,"children":1941},{"className":1940},[],[1942],{"type":22,"value":1943},"cloud9am",{"type":22,"value":140},{"type":16,"tag":634,"props":1946,"children":1948},{"className":1947},[],[1949],{"type":22,"value":1950},"cloud3pm",{"type":22,"value":1952}," is ",{"type":16,"tag":634,"props":1954,"children":1956},{"className":1955},[],[1957],{"type":22,"value":1958},"0",{"type":22,"value":1960},". This means that it could be that there are days with no clouds in the sky. Hence, it might be more realistic to fill in the missing value of our cloudy days with a 0 rather than the mean or the median. Let's do this with the ",{"type":16,"tag":634,"props":1962,"children":1964},{"className":1963},[],[1965],{"type":22,"value":1518},{"type":22,"value":1967}," method.",{"type":16,"tag":695,"props":1969,"children":1971},{"className":697,"code":1970,"language":699,"meta":10,"style":10},"df_clean1[['cloud9am', 'cloud3pm']] = df_clean1[['cloud9am', 'cloud3pm']].fillna(0)\ndf_clean1.isna().sum()\n",[1972],{"type":16,"tag":634,"props":1973,"children":1974},{"__ignoreMap":10},[1975,1983],{"type":16,"tag":705,"props":1976,"children":1977},{"class":707,"line":708},[1978],{"type":16,"tag":705,"props":1979,"children":1980},{},[1981],{"type":22,"value":1982},"df_clean1[['cloud9am', 'cloud3pm']] = df_clean1[['cloud9am', 'cloud3pm']].fillna(0)\n",{"type":16,"tag":705,"props":1984,"children":1985},{"class":707,"line":717},[1986],{"type":16,"tag":705,"props":1987,"children":1988},{},[1989],{"type":22,"value":1990},"df_clean1.isna().sum()\n",{"type":16,"tag":28,"props":1992,"children":1993},{},[1994],{"type":22,"value":1995},"Lastly, evaporation and sunshine both have their mean and medians quite close to each other so we could, potentially, favor either option but there is one more caveat, the standard deviation. The standard deviation is a measure of dispertion that tells us how far, up or down, the fluctuations from the mean might be. To err on the safer side, let's use the median to fill in our missing values.",{"type":16,"tag":28,"props":1997,"children":1998},{},[1999],{"type":22,"value":2000},"We will use a loop to do this.",{"type":16,"tag":79,"props":2002,"children":2003},{},[2004,2009,2014,2019],{"type":16,"tag":83,"props":2005,"children":2006},{},[2007],{"type":22,"value":2008},"we will iterate over the columns",{"type":16,"tag":83,"props":2010,"children":2011},{},[2012],{"type":22,"value":2013},"use the column name to iterate over the dataframe",{"type":16,"tag":83,"props":2015,"children":2016},{},[2017],{"type":22,"value":2018},"check for whether a column has missing values",{"type":16,"tag":83,"props":2020,"children":2021},{},[2022],{"type":22,"value":2023},"if so, we will use the median of that same column to fill in its missing values",{"type":16,"tag":695,"props":2025,"children":2027},{"className":697,"code":2026,"language":699,"meta":10,"style":10},"for col in df_clean1.columns:\n    if df_clean1[col].isna().any():\n        df_clean1[col].fillna(value=df_clean1[col].median(), axis=0, inplace=True)\n",[2028],{"type":16,"tag":634,"props":2029,"children":2030},{"__ignoreMap":10},[2031,2039,2047],{"type":16,"tag":705,"props":2032,"children":2033},{"class":707,"line":708},[2034],{"type":16,"tag":705,"props":2035,"children":2036},{},[2037],{"type":22,"value":2038},"for col in df_clean1.columns:\n",{"type":16,"tag":705,"props":2040,"children":2041},{"class":707,"line":717},[2042],{"type":16,"tag":705,"props":2043,"children":2044},{},[2045],{"type":22,"value":2046},"    if df_clean1[col].isna().any():\n",{"type":16,"tag":705,"props":2048,"children":2049},{"class":707,"line":784},[2050],{"type":16,"tag":705,"props":2051,"children":2052},{},[2053],{"type":22,"value":2054},"        df_clean1[col].fillna(value=df_clean1[col].median(), axis=0, inplace=True)\n",{"type":16,"tag":28,"props":2056,"children":2057},{},[2058],{"type":22,"value":2059},"Let's check if there are any remaining missing values.",{"type":16,"tag":695,"props":2061,"children":2062},{"className":697,"code":1990,"language":699,"meta":10,"style":10},[2063],{"type":16,"tag":634,"props":2064,"children":2065},{"__ignoreMap":10},[2066],{"type":16,"tag":705,"props":2067,"children":2068},{"class":707,"line":708},[2069],{"type":16,"tag":705,"props":2070,"children":2071},{},[2072],{"type":22,"value":1990},{"type":16,"tag":28,"props":2074,"children":2075},{},[2076],{"type":22,"value":2077},"Nice work! Let's now get a few additional variables before we move on to saving our cleaned dataset.",{"type":16,"tag":28,"props":2079,"children":2080},{},[2081,2083,2089,2091,2097,2099,2106],{"type":22,"value":2082},"Since the weather is time series data (e.g. data gathered over time), we will create additional date variables for visualisation purposes. When we have a date column of data type ",{"type":16,"tag":634,"props":2084,"children":2086},{"className":2085},[],[2087],{"type":22,"value":2088},"datetime",{"type":22,"value":2090},", we can access all of the attributes available in our date column using the ",{"type":16,"tag":634,"props":2092,"children":2094},{"className":2093},[],[2095],{"type":22,"value":2096},"dt",{"type":22,"value":2098}," attribute followed by the subattribute we would like to access. You can find out more about the additional subattributes in the ",{"type":16,"tag":63,"props":2100,"children":2103},{"href":2101,"rel":2102},"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.html",[67],[2104],{"type":22,"value":2105},"documentation of pandas here",{"type":22,"value":147},{"type":16,"tag":695,"props":2108,"children":2110},{"className":697,"code":2109,"language":699,"meta":10,"style":10},"df_clean1['date'].dt.weekday.head(15)\n",[2111],{"type":16,"tag":634,"props":2112,"children":2113},{"__ignoreMap":10},[2114],{"type":16,"tag":705,"props":2115,"children":2116},{"class":707,"line":708},[2117],{"type":16,"tag":705,"props":2118,"children":2119},{},[2120],{"type":22,"value":2109},{"type":16,"tag":695,"props":2122,"children":2124},{"className":697,"code":2123,"language":699,"meta":10,"style":10},"df_clean1['month'] = df_clean1['date'].dt.month\ndf_clean1['year'] = df_clean1['date'].dt.year\ndf_clean1.head()\n",[2125],{"type":16,"tag":634,"props":2126,"children":2127},{"__ignoreMap":10},[2128,2136,2144],{"type":16,"tag":705,"props":2129,"children":2130},{"class":707,"line":708},[2131],{"type":16,"tag":705,"props":2132,"children":2133},{},[2134],{"type":22,"value":2135},"df_clean1['month'] = df_clean1['date'].dt.month\n",{"type":16,"tag":705,"props":2137,"children":2138},{"class":707,"line":717},[2139],{"type":16,"tag":705,"props":2140,"children":2141},{},[2142],{"type":22,"value":2143},"df_clean1['year'] = df_clean1['date'].dt.year\n",{"type":16,"tag":705,"props":2145,"children":2146},{"class":707,"line":784},[2147],{"type":16,"tag":705,"props":2148,"children":2149},{},[2150],{"type":22,"value":2151},"df_clean1.head()\n",{"type":16,"tag":72,"props":2153,"children":2155},{"id":2154},"exercise-1",[2156],{"type":22,"value":2157},"Exercise 1",{"type":16,"tag":28,"props":2159,"children":2160},{},[2161,2163,2169],{"type":22,"value":2162},"Add a new column to the dataset that contains the week of the year. Call the new column, ",{"type":16,"tag":634,"props":2164,"children":2166},{"className":2165},[],[2167],{"type":22,"value":2168},"week",{"type":22,"value":147},{"type":16,"tag":695,"props":2171,"children":2172},{"className":697,"code":10,"language":699,"meta":10,"style":10},[2173],{"type":16,"tag":634,"props":2174,"children":2175},{"__ignoreMap":10},[2176],{"type":16,"tag":705,"props":2177,"children":2178},{"class":707,"line":708},[2179],{"type":16,"tag":705,"props":2180,"children":2181},{},[2182],{"type":22,"value":10},{"type":16,"tag":72,"props":2184,"children":2186},{"id":2185},"exercise-2",[2187],{"type":22,"value":2188},"Exercise 2",{"type":16,"tag":28,"props":2190,"children":2191},{},[2192,2194,2200],{"type":22,"value":2193},"Add a new column to the dataset that contains the weekday in numbers (e.g. 0 == Monday, 1==Tuesday, or something similar). Call the new column, ",{"type":16,"tag":634,"props":2195,"children":2197},{"className":2196},[],[2198],{"type":22,"value":2199},"weekday",{"type":22,"value":147},{"type":16,"tag":695,"props":2202,"children":2203},{"className":697,"code":10,"language":699,"meta":10,"style":10},[2204],{"type":16,"tag":634,"props":2205,"children":2206},{"__ignoreMap":10},[2207],{"type":16,"tag":705,"props":2208,"children":2209},{"class":707,"line":708},[2210],{"type":16,"tag":705,"props":2211,"children":2212},{},[2213],{"type":22,"value":10},{"type":16,"tag":72,"props":2215,"children":2217},{"id":2216},"exercise-3",[2218],{"type":22,"value":2219},"Exercise 3",{"type":16,"tag":28,"props":2221,"children":2222},{},[2223,2225,2231],{"type":22,"value":2224},"Add a new column to the dataset that contains the quarter of the year. Call the new column, ",{"type":16,"tag":634,"props":2226,"children":2228},{"className":2227},[],[2229],{"type":22,"value":2230},"quarter",{"type":22,"value":147},{"type":16,"tag":695,"props":2233,"children":2234},{"className":697,"code":10,"language":699,"meta":10,"style":10},[2235],{"type":16,"tag":634,"props":2236,"children":2237},{"__ignoreMap":10},[2238],{"type":16,"tag":705,"props":2239,"children":2240},{"class":707,"line":708},[2241],{"type":16,"tag":705,"props":2242,"children":2243},{},[2244],{"type":22,"value":10},{"type":16,"tag":72,"props":2246,"children":2248},{"id":2247},"exercise-4",[2249],{"type":22,"value":2250},"Exercise 4",{"type":16,"tag":28,"props":2252,"children":2253},{},[2254,2256,2262],{"type":22,"value":2255},"Add a new column to the dataset that contains the name of the day of a week (e.g. Monday, Tuesday, etc.). Call the new column, ",{"type":16,"tag":634,"props":2257,"children":2259},{"className":2258},[],[2260],{"type":22,"value":2261},"day_of_week",{"type":22,"value":147},{"type":16,"tag":695,"props":2264,"children":2265},{"className":697,"code":10,"language":699,"meta":10,"style":10},[2266],{"type":16,"tag":634,"props":2267,"children":2268},{"__ignoreMap":10},[2269],{"type":16,"tag":705,"props":2270,"children":2271},{"class":707,"line":708},[2272],{"type":16,"tag":705,"props":2273,"children":2274},{},[2275],{"type":22,"value":10},{"type":16,"tag":72,"props":2277,"children":2279},{"id":2278},"exercise-5",[2280],{"type":22,"value":2281},"Exercise 5",{"type":16,"tag":28,"props":2283,"children":2284},{},[2285,2287,2293],{"type":22,"value":2286},"Add a new column to the dataset that says whether it is a weekday or the weekend. Call the new column, ",{"type":16,"tag":634,"props":2288,"children":2290},{"className":2289},[],[2291],{"type":22,"value":2292},"week_or_end",{"type":22,"value":147},{"type":16,"tag":695,"props":2295,"children":2296},{"className":697,"code":10,"language":699,"meta":10,"style":10},[2297],{"type":16,"tag":634,"props":2298,"children":2299},{"__ignoreMap":10},[2300],{"type":16,"tag":705,"props":2301,"children":2302},{"class":707,"line":708},[2303],{"type":16,"tag":705,"props":2304,"children":2305},{},[2306],{"type":22,"value":10},{"type":16,"tag":695,"props":2308,"children":2309},{"className":697,"code":10,"language":699,"meta":10,"style":10},[2310],{"type":16,"tag":634,"props":2311,"children":2312},{"__ignoreMap":10},[2313],{"type":16,"tag":705,"props":2314,"children":2315},{"class":707,"line":708},[2316],{"type":16,"tag":705,"props":2317,"children":2318},{},[2319],{"type":22,"value":10},{"type":16,"tag":28,"props":2321,"children":2322},{},[2323,2325,2331,2333,2339],{"type":22,"value":2324},"We might want to represent the quarter variable as a category later on, so we will create a dictionary with the values we would like to change, and pass it to our Python's ",{"type":16,"tag":634,"props":2326,"children":2328},{"className":2327},[],[2329],{"type":22,"value":2330},".map()",{"type":22,"value":2332}," function. A very useful fuction to map a function to an array of values, to a column or other data structure. We will assign the result to a new column called ",{"type":16,"tag":634,"props":2334,"children":2336},{"className":2335},[],[2337],{"type":22,"value":2338},"qrt_cate",{"type":22,"value":147},{"type":16,"tag":695,"props":2341,"children":2343},{"className":697,"code":2342,"language":699,"meta":10,"style":10},"# for more info on how map works, please run this cell\nmap?\n",[2344],{"type":16,"tag":634,"props":2345,"children":2346},{"__ignoreMap":10},[2347,2355],{"type":16,"tag":705,"props":2348,"children":2349},{"class":707,"line":708},[2350],{"type":16,"tag":705,"props":2351,"children":2352},{},[2353],{"type":22,"value":2354},"# for more info on how map works, please run this cell\n",{"type":16,"tag":705,"props":2356,"children":2357},{"class":707,"line":717},[2358],{"type":16,"tag":705,"props":2359,"children":2360},{},[2361],{"type":22,"value":2362},"map?\n",{"type":16,"tag":695,"props":2364,"children":2366},{"className":697,"code":2365,"language":699,"meta":10,"style":10},"mapping = {1:'first_Q',\n           2:'second_Q',\n           3:'third_Q',\n           4:'fourth_Q'}\n\n\ndf_clean1['qtr_cate'] = df_clean1['quarter'].map(mapping)\n",[2367],{"type":16,"tag":634,"props":2368,"children":2369},{"__ignoreMap":10},[2370,2378,2386,2394,2402,2409,2416],{"type":16,"tag":705,"props":2371,"children":2372},{"class":707,"line":708},[2373],{"type":16,"tag":705,"props":2374,"children":2375},{},[2376],{"type":22,"value":2377},"mapping = {1:'first_Q',\n",{"type":16,"tag":705,"props":2379,"children":2380},{"class":707,"line":717},[2381],{"type":16,"tag":705,"props":2382,"children":2383},{},[2384],{"type":22,"value":2385},"           2:'second_Q',\n",{"type":16,"tag":705,"props":2387,"children":2388},{"class":707,"line":784},[2389],{"type":16,"tag":705,"props":2390,"children":2391},{},[2392],{"type":22,"value":2393},"           3:'third_Q',\n",{"type":16,"tag":705,"props":2395,"children":2396},{"class":707,"line":794},[2397],{"type":16,"tag":705,"props":2398,"children":2399},{},[2400],{"type":22,"value":2401},"           4:'fourth_Q'}\n",{"type":16,"tag":705,"props":2403,"children":2404},{"class":707,"line":1667},[2405],{"type":16,"tag":705,"props":2406,"children":2407},{"emptyLinePlaceholder":788},[2408],{"type":22,"value":791},{"type":16,"tag":705,"props":2410,"children":2411},{"class":707,"line":1676},[2412],{"type":16,"tag":705,"props":2413,"children":2414},{"emptyLinePlaceholder":788},[2415],{"type":22,"value":791},{"type":16,"tag":705,"props":2417,"children":2419},{"class":707,"line":2418},7,[2420],{"type":16,"tag":705,"props":2421,"children":2422},{},[2423],{"type":22,"value":2424},"df_clean1['qtr_cate'] = df_clean1['quarter'].map(mapping)\n",{"type":16,"tag":72,"props":2426,"children":2428},{"id":2427},"_7-save-your-work",[2429],{"type":22,"value":2430},"7. Save your work",{"type":16,"tag":28,"props":2432,"children":2433},{},[2434],{"type":22,"value":2435},"The last thing we want to do is to reset the index of our dataframe and save its clean version for later use.",{"type":16,"tag":28,"props":2437,"children":2438},{},[2439,2441,2447,2449,2455],{"type":22,"value":2440},"We can use pandas method ",{"type":16,"tag":634,"props":2442,"children":2444},{"className":2443},[],[2445],{"type":22,"value":2446},".reset_index()",{"type":22,"value":2448}," to reset the index. Notice the ",{"type":16,"tag":634,"props":2450,"children":2452},{"className":2451},[],[2453],{"type":22,"value":2454},"drop=True",{"type":22,"value":2456},", if we do not make this parameter equal to True, pandas will assign the old index to a new column.",{"type":16,"tag":28,"props":2458,"children":2459},{},[2460,2462,2468,2470,2476],{"type":22,"value":2461},"The next method we will use is ",{"type":16,"tag":634,"props":2463,"children":2465},{"className":2464},[],[2466],{"type":22,"value":2467},".to_csv()",{"type":22,"value":2469},". By applying this method to a dataframe, all we need to do is to give the data a name (in quotation marks), and pass in the ",{"type":16,"tag":634,"props":2471,"children":2473},{"className":2472},[],[2474],{"type":22,"value":2475},"index=False",{"type":22,"value":2477}," parameter if we don't want the index to be added as a new column.",{"type":16,"tag":695,"props":2479,"children":2481},{"className":697,"code":2480,"language":699,"meta":10,"style":10},"df_ready = df_clean1.reset_index(drop=True).copy()\n",[2482],{"type":16,"tag":634,"props":2483,"children":2484},{"__ignoreMap":10},[2485],{"type":16,"tag":705,"props":2486,"children":2487},{"class":707,"line":708},[2488],{"type":16,"tag":705,"props":2489,"children":2490},{},[2491],{"type":22,"value":2480},{"type":16,"tag":695,"props":2493,"children":2495},{"className":697,"code":2494,"language":699,"meta":10,"style":10},"df_ready.to_csv('weather_ready.csv', index=False)\n",[2496],{"type":16,"tag":634,"props":2497,"children":2498},{"__ignoreMap":10},[2499],{"type":16,"tag":705,"props":2500,"children":2501},{"class":707,"line":708},[2502],{"type":16,"tag":705,"props":2503,"children":2504},{},[2505],{"type":22,"value":2494},{"type":16,"tag":695,"props":2507,"children":2509},{"className":697,"code":2508,"language":699,"meta":10,"style":10},"!head -n 5 weather_ready.csv\n",[2510],{"type":16,"tag":634,"props":2511,"children":2512},{"__ignoreMap":10},[2513],{"type":16,"tag":705,"props":2514,"children":2515},{"class":707,"line":708},[2516],{"type":16,"tag":705,"props":2517,"children":2518},{},[2519],{"type":22,"value":2508},{"type":16,"tag":28,"props":2521,"children":2522},{},[2523],{"type":16,"tag":45,"props":2524,"children":2527},{"alt":2525,"src":2526},"pandas_tools","https://i.chzbgr.com/full/1898496256/h42C0CC42/panda-cleaning-instructions",[],{"type":16,"tag":17,"props":2529,"children":2531},{"id":2530},"awesome-work-we-will-continued-to-clean-more-dataset-but-for-now-on-to-dataviz",[2532],{"type":22,"value":2533},"Awesome Work! We will continued to clean more dataset but for now, on to DataViz",{"type":16,"tag":72,"props":2535,"children":2537},{"id":2536},"_8-summary",[2538],{"type":22,"value":2539},"8. Summary",{"type":16,"tag":28,"props":2541,"children":2542},{},[2543],{"type":22,"value":2544},"In this lesson we have covered pandas in great lenght, and still, we have yet to scratch the surface of what this powerful tool can do. Some keypoints to take away:",{"type":16,"tag":244,"props":2546,"children":2547},{},[2548,2553,2558,2563,2568,2596],{"type":16,"tag":83,"props":2549,"children":2550},{},[2551],{"type":22,"value":2552},"pandas provides two fantastic data structures for data analysis, the DataFrame and the Series",{"type":16,"tag":83,"props":2554,"children":2555},{},[2556],{"type":22,"value":2557},"We can slice and dice these data structures to our hearts content all while keeping in mind the inconsistencies that we might find in different datasets",{"type":16,"tag":83,"props":2559,"children":2560},{},[2561],{"type":22,"value":2562},"We should always begin by inspecting our data immediately after loading it into our session. pandas provides methods such as info, describe, and isna that work very well and allow us to see what we have the data",{"type":16,"tag":83,"props":2564,"children":2565},{},[2566],{"type":22,"value":2567},"When cleaning data, missing values need to be treated carefully as the reasons behind them might differ from one variable to the next.",{"type":16,"tag":83,"props":2569,"children":2570},{},[2571,2573],{"type":22,"value":2572},"Always keep in mind to\n",{"type":16,"tag":244,"props":2574,"children":2575},{},[2576,2581,2586,2591],{"type":16,"tag":83,"props":2577,"children":2578},{},[2579],{"type":22,"value":2580},"Check for duplicates",{"type":16,"tag":83,"props":2582,"children":2583},{},[2584],{"type":22,"value":2585},"Normalise columns",{"type":16,"tag":83,"props":2587,"children":2588},{},[2589],{"type":22,"value":2590},"Deal with missing values, preferably with stakeholders or subject matter experts if the amount of missing values is vast",{"type":16,"tag":83,"props":2592,"children":2593},{},[2594],{"type":22,"value":2595},"Use dates to your advantage",{"type":16,"tag":83,"props":2597,"children":2598},{},[2599],{"type":22,"value":2600},"Don't try to learn all the tools inside pandas but rather explore the ones you need as the need arises, or, explore them slowly and build an intuition for them",{"type":16,"tag":72,"props":2602,"children":2604},{"id":2603},"references",[2605],{"type":22,"value":2606},"References",{"type":16,"tag":28,"props":2608,"children":2609},{},[2610,2612,2617],{"type":22,"value":2611},"Sweigart, Al. ",{"type":16,"tag":218,"props":2613,"children":2614},{},[2615],{"type":22,"value":2616},"Automate the Boring Stuff with Python: Practical Programming for Total Beginners",{"type":22,"value":2618},". No Starch Press, 2020.",{"type":16,"tag":28,"props":2620,"children":2621},{},[2622,2624,2629],{"type":22,"value":2623},"VanderPlas, Jake. ",{"type":16,"tag":218,"props":2625,"children":2626},{},[2627],{"type":22,"value":2628},"A Whirlwind Tour of Python",{"type":22,"value":2630},". O'Reilly, 2016.",{"type":16,"tag":28,"props":2632,"children":2633},{},[2634,2635,2640],{"type":22,"value":2623},{"type":16,"tag":218,"props":2636,"children":2637},{},[2638],{"type":22,"value":2639},"Python Data Science Handbook",{"type":22,"value":2641},". O'Reilly, 2017.",{"type":16,"tag":28,"props":2643,"children":2644},{},[2645,2647,2652],{"type":22,"value":2646},"McKinney, Wes. ",{"type":16,"tag":218,"props":2648,"children":2649},{},[2650],{"type":22,"value":2651},"Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython",{"type":22,"value":2653},". OReilly, 2018.",{"type":16,"tag":2655,"props":2656,"children":2657},"style",{},[2658],{"type":22,"value":2659},"html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"title":10,"searchDepth":717,"depth":717,"links":2661},[2662,2663,2664,2665,2666,2667,2668,2671,2672,2673,2674,2675,2676,2677,2678],{"id":74,"depth":717,"text":77},{"id":125,"depth":717,"text":128},{"id":186,"depth":717,"text":189},{"id":417,"depth":717,"text":420},{"id":624,"depth":717,"text":627},{"id":903,"depth":717,"text":906},{"id":1342,"depth":717,"text":1345,"children":2669},[2670],{"id":1423,"depth":784,"text":1426},{"id":2154,"depth":717,"text":2157},{"id":2185,"depth":717,"text":2188},{"id":2216,"depth":717,"text":2219},{"id":2247,"depth":717,"text":2250},{"id":2278,"depth":717,"text":2281},{"id":2427,"depth":717,"text":2430},{"id":2536,"depth":717,"text":2539},{"id":2603,"depth":717,"text":2606},"markdown","content:3.data-engineering:2.data_cleaning.md","content","3.data-engineering/2.data_cleaning.md","md","default",["ShallowRef",2686],["ShallowReactive",2687],{"/data-engineering/data_cleaning":2688},[2689,2694],{"_path":2690,"_dir":8,"_draft":9,"_partial":9,"_locale":10,"title":2691,"description":10,"_type":2679,"_id":2692,"_source":2681,"_file":2693,"_extension":2683},"/data-engineering/getting_data","Getting Data as DataFrames","content:3.data-engineering:1.getting_data.md","3.data-engineering/1.getting_data.md",{"_path":2695,"_dir":8,"_draft":9,"_partial":9,"_locale":10,"title":2696,"description":10,"_type":2679,"_id":2697,"_source":2681,"_file":2698,"_extension":2683},"/data-engineering/etl_pipes","01 ETL Pipelines","content:3.data-engineering:3.etl_pipes.md","3.data-engineering/3.etl_pipes.md",["ShallowRef",2700],{},{"preference":2702,"value":2702,"unknown":788,"forced":9},"system",[2704,2720,2734,2756,2768,2775],{"title":2705,"_path":2706,"children":2707,"icon":2719},"Set Up","/introduction",[2708,2710,2713,2716],{"title":2709,"_path":2706},"Introduction",{"title":2711,"_path":2712},"Python Installation","/introduction/python_installation",{"title":2714,"_path":2715},"Git Installation","/introduction/git_installation",{"title":2717,"_path":2718},"Jupyter Lab & Notebooks Intro","/introduction/jupyter_intro","ph:star-duotone",{"title":2721,"_path":2722,"children":2723,"icon":2733},"Programming","/programming",[2724,2726],{"title":2725,"_path":2722},"Programming Tutorials",{"title":2727,"_path":2728,"children":2729},"Terminal","/programming/terminal",[2730],{"title":2731,"_path":2732},"Intro to the Terminal","/programming/terminal/shell_intro","heroicons-outline:bookmark-alt",{"title":2735,"_path":2736,"children":2737,"icon":2755},"Analytics","/analytics",[2738,2740,2743,2746,2749,2752],{"title":2739,"_path":2736},"Data Analytics",{"title":2741,"_path":2742},"Numerical Computing","/analytics/numerical_computing",{"title":2744,"_path":2745},"Intro to pandas","/analytics/structured_data",{"title":2747,"_path":2748},"Intro to Statistics","/analytics/stats_intro",{"title":2750,"_path":2751},"Describing Data","/analytics/describing_data",{"title":2753,"_path":2754},"Exploratory Data Analysis","/analytics/eda","ri:line-chart-line",{"title":2757,"_path":2758,"children":2759,"icon":2767},"Data Engineering","/data-engineering",[2760,2763,2764,2765,2766],{"title":2761,"_path":2762},"Data Pipelines From Scratch","/data-engineering/data_pipelines_getting_started",{"title":2691,"_path":2690},{"title":11,"_path":7},{"title":2696,"_path":2695},{"title":2761,"_path":2762},"ri:settings-2-line",{"title":2769,"_path":2770,"children":2771,"icon":2774},"Data Science","/data-science",[2772],{"title":2773,"_path":2770},"Intro to DS","ri:magic-line",{"title":2776,"_path":2777,"children":2778,"icon":2781},"Machine Learning Engineering","/ml-engineering",[2779],{"title":2780,"_path":2777},"Intro to MLE","ri:robot-2-line",{"heroicons-outline:menu":2783,"fa-brands:github":2787,"simple-icons:nuxtdotjs":2791,"ri:arrow-right-double-fill":2793,"ph:star-duotone":2795,"lucide:chevrons-down-up":2798,"heroicons-outline:bookmark-alt":2800,"lucide:chevrons-up-down":2802,"ri:line-chart-line":2804,"ri:settings-2-line":2806,"ri:magic-line":2808,"ri:robot-2-line":2810,"uil:edit":2812,"heroicons-outline:arrow-sm-right":2814,"heroicons-outline:search":2816,"ri:arrow-right-s-line":2818,"ri:arrow-right-double-line":2820,"heroicons-outline:arrow-sm-left":2821,"heroicons-outline:chevron-right":2823,"ph:copy":2825,"ri:arrow-right-s-fill":2827},{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2786},0,24,"\u003Cpath fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M4 6h16M4 12h16M4 18h16\"/>",{"left":2784,"top":2784,"width":2788,"height":2789,"rotate":2784,"vFlip":9,"hFlip":9,"body":2790},496,512,"\u003Cpath fill=\"currentColor\" d=\"M165.9 397.4c0 2-2.3 3.6-5.2 3.6c-3.3.3-5.6-1.3-5.6-3.6c0-2 2.3-3.6 5.2-3.6c3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9c2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9c.3 2 2.9 3.3 5.9 2.6c2.9-.7 4.9-2.6 4.6-4.6c-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2c12.8 2.3 17.3-5.6 17.3-12.1c0-6.2-.3-40.4-.3-61.4c0 0-70 15-84.7-29.8c0 0-11.4-29.1-27.8-36.6c0 0-22.9-15.7 1.6-15.4c0 0 24.9 2 38.6 25.8c21.9 38.6 58.6 27.5 72.9 20.9c2.3-16 8.8-27.1 16-33.7c-55.9-6.2-112.3-14.3-112.3-110.5c0-27.5 7.6-41.3 23.6-58.9c-2.6-6.5-11.1-33.3 2.6-67.9c20.9-6.5 69 27 69 27c20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27c13.7 34.7 5.2 61.4 2.6 67.9c16 17.7 25.8 31.5 25.8 58.9c0 96.5-58.9 104.2-114.8 110.5c9.2 7.9 17 22.9 17 46.4c0 33.7-.3 75.4-.3 83.6c0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252C496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2c1.6 1.6 3.9 2.3 5.2 1c1.3-1 1-3.3-.7-5.2c-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9c1.6 1 3.6.7 4.3-.7c.7-1.3-.3-2.9-2.3-3.9c-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2c2.3 2.3 5.2 2.6 6.5 1c1.3-1.3.7-4.3-1.3-6.2c-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2c-1.4-2.3-4-3.3-5.6-2\"/>",{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2792},"\u003Cpath fill=\"currentColor\" d=\"M13.464 19.83h8.922c.283 0 .562-.073.807-.21a1.6 1.6 0 0 0 .591-.574a1.53 1.53 0 0 0 .216-.783a1.53 1.53 0 0 0-.217-.782L17.792 7.414a1.6 1.6 0 0 0-.591-.573a1.65 1.65 0 0 0-.807-.21c-.283 0-.562.073-.807.21a1.6 1.6 0 0 0-.59.573L13.463 9.99L10.47 4.953a1.6 1.6 0 0 0-.591-.573a1.65 1.65 0 0 0-.807-.21c-.284 0-.562.073-.807.21a1.6 1.6 0 0 0-.591.573L.216 17.481a1.53 1.53 0 0 0-.217.782c0 .275.074.545.216.783a1.6 1.6 0 0 0 .59.574c.246.137.525.21.808.21h5.6c2.22 0 3.856-.946 4.982-2.79l2.733-4.593l1.464-2.457l4.395 7.382h-5.859Zm-6.341-2.46l-3.908-.002l5.858-9.842l2.923 4.921l-1.957 3.29c-.748 1.196-1.597 1.632-2.916 1.632\"/>",{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2794},"\u003Cpath fill=\"currentColor\" d=\"m19.164 12l-6.207-6.207l-1.414 1.414L16.336 12l-4.793 4.793l1.414 1.414zm-5.65 0L7.307 5.793L5.893 7.207L10.686 12l-4.793 4.793l1.414 1.414z\"/>",{"left":2784,"top":2784,"width":2796,"height":2796,"rotate":2784,"vFlip":9,"hFlip":9,"body":2797},256,"\u003Cg fill=\"currentColor\">\u003Cpath d=\"m229.06 108.79l-48.7 42l14.88 62.79a8.4 8.4 0 0 1-12.52 9.17L128 189.09l-54.72 33.65a8.4 8.4 0 0 1-12.52-9.17l14.88-62.79l-48.7-42A8.46 8.46 0 0 1 31.73 94l63.91-5.2l24.62-59.6a8.36 8.36 0 0 1 15.48 0l24.62 59.6l63.91 5.2a8.46 8.46 0 0 1 4.79 14.79\" opacity=\".2\"/>\u003Cpath d=\"M239.18 97.26A16.38 16.38 0 0 0 224.92 86l-59-4.76l-22.78-55.09a16.36 16.36 0 0 0-30.27 0L90.11 81.23L31.08 86a16.46 16.46 0 0 0-9.37 28.86l45 38.83L53 211.75a16.38 16.38 0 0 0 24.5 17.82l50.5-31.08l50.53 31.08A16.4 16.4 0 0 0 203 211.75l-13.76-58.07l45-38.83a16.43 16.43 0 0 0 4.94-17.59m-15.34 5.47l-48.7 42a8 8 0 0 0-2.56 7.91l14.88 62.8a.37.37 0 0 1-.17.48c-.18.14-.23.11-.38 0l-54.72-33.65a8 8 0 0 0-8.38 0l-54.72 33.67c-.15.09-.19.12-.38 0a.37.37 0 0 1-.17-.48l14.88-62.8a8 8 0 0 0-2.56-7.91l-48.7-42c-.12-.1-.23-.19-.13-.5s.18-.27.33-.29l63.92-5.16a8 8 0 0 0 6.72-4.94l24.62-59.61c.08-.17.11-.25.35-.25s.27.08.35.25L153 91.86a8 8 0 0 0 6.75 4.92l63.92 5.16c.15 0 .24 0 .33.29s0 .4-.16.5\"/>\u003C/g>",{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2799},"\u003Cpath fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"m7 20l5-5l5 5M7 4l5 5l5-5\"/>",{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2801},"\u003Cpath fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M16 4v12l-4-2l-4 2V4M6 20h12a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2H6a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2\"/>",{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2803},"\u003Cpath fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"m7 15l5 5l5-5M7 9l5-5l5 5\"/>",{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2805},"\u003Cpath fill=\"currentColor\" d=\"M5 3v16h16v2H3V3zm15.293 3.293l1.414 1.414L16 13.414l-3-2.999l-4.293 4.292l-1.414-1.414L13 7.586l3 2.999z\"/>",{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2807},"\u003Cpath fill=\"currentColor\" d=\"m8.686 4l2.607-2.607a1 1 0 0 1 1.414 0L15.314 4H19a1 1 0 0 1 1 1v3.686l2.607 2.607a1 1 0 0 1 0 1.414L20 15.314V19a1 1 0 0 1-1 1h-3.686l-2.607 2.607a1 1 0 0 1-1.414 0L8.686 20H5a1 1 0 0 1-1-1v-3.686l-2.607-2.607a1 1 0 0 1 0-1.414L4 8.686V5a1 1 0 0 1 1-1zM6 6v3.515L3.515 12L6 14.485V18h3.515L12 20.485L14.485 18H18v-3.515L20.485 12L18 9.515V6h-3.515L12 3.515L9.515 6zm6 10a4 4 0 1 1 0-8a4 4 0 0 1 0 8m0-2a2 2 0 1 0 0-4a2 2 0 0 0 0 4\"/>",{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2809},"\u003Cpath fill=\"currentColor\" d=\"M15.199 9.944a2.6 2.6 0 0 1-.79-1.55l-.403-3.083l-2.731 1.486a2.6 2.6 0 0 1-1.719.272L6.5 6.5l.57 3.056a2.6 2.6 0 0 1-.273 1.72l-1.486 2.73l3.083.403a2.6 2.6 0 0 1 1.55.79l2.138 2.257l1.336-2.807a2.6 2.6 0 0 1 1.23-1.231l2.808-1.336zm.025 5.564l-2.213 4.65a.6.6 0 0 1-.977.155l-3.542-3.739a.6.6 0 0 0-.358-.182l-5.106-.668a.6.6 0 0 1-.45-.881l2.462-4.524a.6.6 0 0 0 .063-.396L4.16 4.86a.6.6 0 0 1 .7-.7l5.062.943a.6.6 0 0 0 .397-.063l4.523-2.46a.6.6 0 0 1 .882.448l.668 5.107a.6.6 0 0 0 .182.357l3.739 3.542a.6.6 0 0 1-.155.977l-4.65 2.213a.6.6 0 0 0-.284.284m.797 1.927l1.414-1.414l4.243 4.242l-1.415 1.415z\"/>",{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2811},"\u003Cpath fill=\"currentColor\" d=\"M13.5 2c0 .444-.193.843-.5 1.118V5h5a3 3 0 0 1 3 3v10a3 3 0 0 1-3 3H6a3 3 0 0 1-3-3V8a3 3 0 0 1 3-3h5V3.118A1.5 1.5 0 1 1 13.5 2M6 7a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V8a1 1 0 0 0-1-1zm-4 3H0v6h2zm20 0h2v6h-2zM9 14.5a1.5 1.5 0 1 0 0-3a1.5 1.5 0 0 0 0 3m6 0a1.5 1.5 0 1 0 0-3a1.5 1.5 0 0 0 0 3\"/>",{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2813},"\u003Cpath fill=\"currentColor\" d=\"M21 12a1 1 0 0 0-1 1v6a1 1 0 0 1-1 1H5a1 1 0 0 1-1-1V5a1 1 0 0 1 1-1h6a1 1 0 0 0 0-2H5a3 3 0 0 0-3 3v14a3 3 0 0 0 3 3h14a3 3 0 0 0 3-3v-6a1 1 0 0 0-1-1m-15 .76V17a1 1 0 0 0 1 1h4.24a1 1 0 0 0 .71-.29l6.92-6.93L21.71 8a1 1 0 0 0 0-1.42l-4.24-4.29a1 1 0 0 0-1.42 0l-2.82 2.83l-6.94 6.93a1 1 0 0 0-.29.71m10.76-8.35l2.83 2.83l-1.42 1.42l-2.83-2.83ZM8 13.17l5.93-5.93l2.83 2.83L10.83 16H8Z\"/>",{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2815},"\u003Cpath fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"m13 7l5 5m0 0l-5 5m5-5H6\"/>",{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2817},"\u003Cpath fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"m21 21l-6-6m2-5a7 7 0 1 1-14 0a7 7 0 0 1 14 0\"/>",{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2819},"\u003Cpath fill=\"currentColor\" d=\"m13.172 12l-4.95-4.95l1.414-1.413L16 12l-6.364 6.364l-1.414-1.415z\"/>",{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2794},{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2822},"\u003Cpath fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"m11 17l-5-5m0 0l5-5m-5 5h12\"/>",{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2824},"\u003Cpath fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"m9 5l7 7l-7 7\"/>",{"left":2784,"top":2784,"width":2796,"height":2796,"rotate":2784,"vFlip":9,"hFlip":9,"body":2826},"\u003Cpath fill=\"currentColor\" d=\"M216 32H88a8 8 0 0 0-8 8v40H40a8 8 0 0 0-8 8v128a8 8 0 0 0 8 8h128a8 8 0 0 0 8-8v-40h40a8 8 0 0 0 8-8V40a8 8 0 0 0-8-8m-56 176H48V96h112Zm48-48h-32V88a8 8 0 0 0-8-8H96V48h112Z\"/>",{"left":2784,"top":2784,"width":2785,"height":2785,"rotate":2784,"vFlip":9,"hFlip":9,"body":2828},"\u003Cpath fill=\"currentColor\" d=\"m16 12l-6 6V6z\"/>",{"parentPath":2758,"scrollTop":2784},{},{},{"/programming/terminal":788},{},{},{},{},{},["Reactive",2839],["Set"],["Reactive",2841],{"search-api":2842},null,1733708749135]</script>
<script>window.__NUXT__={};window.__NUXT__.config={public:{plausible:{hashMode:false,trackLocalhost:false,domain:"",apiHost:"https://plausible.io",autoPageviews:true,autoOutboundTracking:false},studio:{apiURL:"https://api.nuxt.studio",iframeMessagingAllowedOrigins:""},mdc:{components:{prose:true,map:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"ProseCodeInline",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"}},headings:{anchorLinks:{h1:false,h2:true,h3:true,h4:true,h5:false,h6:false}}},content:{locales:[],defaultLocale:"",integrity:1733708717391,experimental:{stripQueryParameters:false,advanceQuery:false,clientDB:false},respectPathCase:false,api:{baseURL:"/api/_content"},navigation:{fields:["icon","titleTemplate","header","main","aside","footer","layout"]},tags:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"ProseCodeInline",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"},highlight:{theme:{dark:"github-dark",default:"github-light"},preload:["json","js","ts","html","css","vue","diff","shell","markdown","yaml","bash","ini"],highlighter:"shiki",langs:["js","jsx","json","ts","tsx","vue","css","html","vue","bash","md","mdc","yaml","json","js","ts","html","css","vue","diff","shell","markdown","yaml","bash","ini"]},wsUrl:"",documentDriven:{page:true,navigation:true,surround:true,globals:{},layoutFallbacks:["theme"],injectPage:true},host:"",trailingSlash:false,search:"",contentHead:true,anchorLinks:{depth:4,exclude:[1]}}},app:{baseURL:"/",buildAssetsDir:"/_nuxt/",cdnURL:""}}</script></body></html>